{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"CONCORD: COntrastive learNing for Cross-dOmain Reconciliation and Discovery","text":""},{"location":"#description","title":"Description","text":"<p>Resolving the intricate structure of the cellular state landscape from single-cell RNA sequencing (scRNAseq) experiments remains an outstanding challenge, compounded by technical noise and systematic discrepancies\u2014often referred to as batch effects\u2014across experimental systems and replicate. To address this, we introduce CONCORD (COntrastive learNing for Cross-dOmain Reconciliation and Discovery), a self-supervised contrastive learning framework designed for robust dimensionality reduction and data integration in single-cell analysis. The core innovation of CONCORD lies in its probabilistic, dataset- and neighborhood-aware sampling strategy, which enhances contrastive learning by simultaneously improving the resolution of cell states and mitigating batch artifacts. Operated in a fully unsupervised manner, CONCORD generates denoised cell encodings that faithfully preserve key biological structures, from fine-grained distinctions among closely related cell states to large-scale topological organizations. The resulting high-resolution cell atlas seamlessly integrates data across experimental batches, technologies, and species. Additionally, CONCORD\u2019s latent space capture biologically meaningful gene programs, enabling the exploration of regulatory mechanisms underlying cell state transitions and subpopulation heterogeneity. We demonstrate the utility of CONCORD on a range of topological structures and biological contexts, underscoring its potential to extract meaningful insights from both existing and future single-cell datasets.</p>"},{"location":"#installation","title":"Installation","text":""},{"location":"#1-clone-the-concord-repository-and-set-up-environment","title":"1. Clone the Concord repository and set up environment:","text":"<pre><code>git clone git@github.com:Gartner-Lab/Concord.git\n</code></pre> <p>It is recommended to use conda (https://conda.io/projects/conda/en/latest/user-guide/install/index.html) to create and set up a virtual environment for Concord.</p>"},{"location":"#2-install-pytorch","title":"2. Install PyTorch:","text":"<p>You must install the correct version of PyTorch based on your system's CUDA setup. Please follow the instructions on the official PyTorch website to install the appropriate version of PyTorch for CUDA or CPU.</p> <p>Example (for CPU version): <pre><code>pip install torch torchvision torchaudio\n</code></pre></p>"},{"location":"#3-install-dependencies","title":"3. Install dependencies:","text":"<p>Navigate to the Concord directory and install the required dependencies:</p> <pre><code>cd path_to_Concord\npip install -r requirements.txt\n</code></pre>"},{"location":"#4-install-concord","title":"4. Install Concord:","text":"<p>Build and install Concord:</p> <pre><code>python -m build\npip install dist/Concord-0.9.0-py3-none-any.whl\n</code></pre>"},{"location":"#5-optional-install-faiss-for-accelerated-knn-search-not-recommended-for-mac","title":"5. (Optional) Install FAISS for accelerated KNN search (not recommended for Mac):","text":"<p>Install FAISS for fast nearest-neighbor searches for large datasets. Note if you are using Mac, you should turn faiss off by specifying <code>cur_ccd = ccd.Concord(adata=adata, input_feature=feature_list, use_faiss=False, device=device)</code> when running Concord, unless you are certain faiss runs with no problem.</p> <ul> <li>FAISS with GPU:   <pre><code>pip install faiss_gpu\n</code></pre></li> <li>FAISS with CPU:   <pre><code>pip install faiss_cpu\n</code></pre></li> </ul>"},{"location":"#6-optional-install-optional-dependencies","title":"6. (Optional) Install optional dependencies:","text":"<p>Concord offers additional functionality through optional dependencies. You can install them via: <pre><code>pip install -r requirements_optional.txt\n</code></pre></p>"},{"location":"#7-optional-integration-with-viscello","title":"7. (Optional) Integration with VisCello:","text":"<p>Concord integrates with VisCello, a tool for interactive visualization. To explore results interactively, visit VisCello GitHub and refer to the full documentation for more information.</p> <p>You will also need the rpy2 package installed via: <pre><code>pip install rpy2\n</code></pre></p>"},{"location":"#getting-started","title":"Getting Started","text":"<p>Concord integrates seamlessly with <code>anndata</code> objects.  Single-cell datasets, such as 10x Genomics outputs, can easily be loaded into an <code>annData</code> object using the <code>Scanpy</code> package. If you're using R and have data in a <code>Seurat</code> object, you can convert it to <code>anndata</code> format by following this tutorial.  In this quick-start example, we'll demonstrate CONCORD using the <code>pbmc3k</code> dataset provided by the <code>scanpy</code> package.</p>"},{"location":"#load-package-and-data","title":"Load package and data","text":"<pre><code># Load required packages\nimport Concord as ccd\nimport scanpy as sc\nimport torch\n# Load and prepare example data\nadata = sc.datasets.pbmc3k_processed()\nadata = adata.raw.to_adata()  # Store raw counts in adata.X, by default Concord will run standard total count normalization and log transformation internally, not necessary if you want to use your normalized data in adata.X, if so, specify 'X' in cur_ccd.encode_adata(input_layer_key='X', output_key='Concord')\n</code></pre>"},{"location":"#run-concord","title":"Run CONCORD:","text":"<pre><code># Set device to cpu or to gpu (if your torch has been set up correctly to use GPU), for mac you can use either torch.device('mps') or torch.device('cpu')\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\n# (Optional) Select top variably expressed/accessible features for analysis (other methods besides seurat_v3 available)\nfeature_list = ccd.ul.select_features(adata, n_top_features=5000, flavor='seurat_v3')\n\n# Initialize Concord with an AnnData object, skip input_feature to use all features\ncur_ccd = ccd.Concord(adata=adata, input_feature=feature_list, device=device) \n\n# If integrating data across batch, simply add the domain_key argument to indicate the batch key in adata.obs\n# cur_ccd = ccd.Concord(adata=adata, input_feature=feature_list, domain_key='batch', device=device) \n\n# Encode data, saving the latent embedding in adata.obsm['Concord']\ncur_ccd.encode_adata(output_key='Concord')\n</code></pre>"},{"location":"#visualization","title":"Visualization:","text":"<p>CONCORD latent embeddings can be directly used for downstream analyses such as visualization with UMAP and t-SNE or constructing k-nearest neighbor (kNN) graphs. Unlike PCA, it is important to utilize the full CONCORD latent embedding in downstream analyses, as each dimension is designed to capture meaningful and complementary aspects of the underlying data structure.</p> <pre><code>ccd.ul.run_umap(adata, source_key='Concord', result_key='Concord_UMAP', n_components=2, n_neighbors=15, min_dist=0.1, metric='euclidean')\n\n# Plot the UMAP embeddings\ncolor_by = ['n_genes', 'louvain'] # Choose which variables you want to visualize\nccd.pl.plot_embedding(\n    adata, basis='Concord_UMAP', color_by=color_by, figsize=(10, 5), dpi=600, ncols=2, font_size=6, point_size=10, legend_loc='on data',\n    save_path='Concord_UMAP.png'\n)\n</code></pre> <p>The latent space produced by CONCORD often capture complex biological structures that may not be fully visualized in 2D projections. We recommend exploring the latent space using a 3D UMAP to more effectively capture and examine the intricacies of the data. For example:</p> <pre><code>ccd.ul.run_umap(adata, source_key='Concord', result_key='Concord_UMAP_3D', n_components=3, n_neighbors=15, min_dist=0.1, metric='euclidean')\n\n# Plot the 3D UMAP embeddings\ncol = 'louvain'\nfig = ccd.pl.plot_embedding_3d(\n    adata, basis='Concord_UMAP_3D', color_by=col, \n    save_path='Concord_UMAP_3D.html',\n    point_size=3, opacity=0.8, width=1500, height=1000\n)\n</code></pre>"},{"location":"#citation","title":"Citation","text":"<p>Please cite the preprint here: [Insert citation link].</p>"},{"location":"LICENSE/","title":"License","text":"<p>Attribution 4.0 International</p> <p>=======================================================================</p> <p>Creative Commons Corporation (\"Creative Commons\") is not a law firm and does not provide legal services or legal advice. Distribution of Creative Commons public licenses does not create a lawyer-client or other relationship. Creative Commons makes its licenses and related information available on an \"as-is\" basis. Creative Commons gives no warranties regarding its licenses, any material licensed under their terms and conditions, or any related information. Creative Commons disclaims all liability for damages resulting from their use to the fullest extent possible.</p> <p>Using Creative Commons Public Licenses</p> <p>Creative Commons public licenses provide a standard set of terms and conditions that creators and other rights holders may use to share original works of authorship and other material subject to copyright and certain other rights specified in the public license below. The following considerations are for informational purposes only, are not exhaustive, and do not form part of our licenses.</p> <pre><code> Considerations for licensors: Our public licenses are\n intended for use by those authorized to give the public\n permission to use material in ways otherwise restricted by\n copyright and certain other rights. Our licenses are\n irrevocable. Licensors should read and understand the terms\n and conditions of the license they choose before applying it.\n Licensors should also secure all rights necessary before\n applying our licenses so that the public can reuse the\n material as expected. Licensors should clearly mark any\n material not subject to the license. This includes other CC-\n licensed material, or material used under an exception or\n limitation to copyright. More considerations for licensors:\nwiki.creativecommons.org/Considerations_for_licensors\n\n Considerations for the public: By using one of our public\n licenses, a licensor grants the public permission to use the\n licensed material under specified terms and conditions. If\n the licensor's permission is not necessary for any reason--for\n example, because of any applicable exception or limitation to\n copyright--then that use is not regulated by the license. Our\n licenses grant only permissions under copyright and certain\n other rights that a licensor has authority to grant. Use of\n the licensed material may still be restricted for other\n reasons, including because others have copyright or other\n rights in the material. A licensor may make special requests,\n such as asking that all changes be marked or described.\n Although not required by our licenses, you are encouraged to\n respect those requests where reasonable. More considerations\n for the public: \nwiki.creativecommons.org/Considerations_for_licensees\n</code></pre> <p>=======================================================================</p> <p>Creative Commons Attribution 4.0 International Public License</p> <p>By exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution 4.0 International Public License (\"Public License\"). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.</p> <p>Section 1 -- Definitions.</p> <p>a. Adapted Material means material subject to Copyright and Similar      Rights that is derived from or based upon the Licensed Material      and in which the Licensed Material is translated, altered,      arranged, transformed, or otherwise modified in a manner requiring      permission under the Copyright and Similar Rights held by the      Licensor. For purposes of this Public License, where the Licensed      Material is a musical work, performance, or sound recording,      Adapted Material is always produced where the Licensed Material is      synched in timed relation with a moving image.</p> <p>b. Adapter's License means the license You apply to Your Copyright      and Similar Rights in Your contributions to Adapted Material in      accordance with the terms and conditions of this Public License.</p> <p>c. Copyright and Similar Rights means copyright and/or similar rights      closely related to copyright including, without limitation,      performance, broadcast, sound recording, and Sui Generis Database      Rights, without regard to how the rights are labeled or      categorized. For purposes of this Public License, the rights      specified in Section 2(b)(1)-(2) are not Copyright and Similar      Rights.</p> <p>d. Effective Technological Measures means those measures that, in the      absence of proper authority, may not be circumvented under laws      fulfilling obligations under Article 11 of the WIPO Copyright      Treaty adopted on December 20, 1996, and/or similar international      agreements.</p> <p>e. Exceptions and Limitations means fair use, fair dealing, and/or      any other exception or limitation to Copyright and Similar Rights      that applies to Your use of the Licensed Material.</p> <p>f. Licensed Material means the artistic or literary work, database,      or other material to which the Licensor applied this Public      License.</p> <p>g. Licensed Rights means the rights granted to You subject to the      terms and conditions of this Public License, which are limited to      all Copyright and Similar Rights that apply to Your use of the      Licensed Material and that the Licensor has authority to license.</p> <p>h. Licensor means the individual(s) or entity(ies) granting rights      under this Public License.</p> <p>i. Share means to provide material to the public by any means or      process that requires permission under the Licensed Rights, such      as reproduction, public display, public performance, distribution,      dissemination, communication, or importation, and to make material      available to the public including in ways that members of the      public may access the material from a place and at a time      individually chosen by them.</p> <p>j. Sui Generis Database Rights means rights other than copyright      resulting from Directive 96/9/EC of the European Parliament and of      the Council of 11 March 1996 on the legal protection of databases,      as amended and/or succeeded, as well as other essentially      equivalent rights anywhere in the world.</p> <p>k. You means the individual or entity exercising the Licensed Rights      under this Public License. Your has a corresponding meaning.</p> <p>Section 2 -- Scope.</p> <p>a. License grant.</p> <pre><code>   1. Subject to the terms and conditions of this Public License,\n      the Licensor hereby grants You a worldwide, royalty-free,\n      non-sublicensable, non-exclusive, irrevocable license to\n      exercise the Licensed Rights in the Licensed Material to:\n\n        a. reproduce and Share the Licensed Material, in whole or\n           in part; and\n\n        b. produce, reproduce, and Share Adapted Material.\n\n   2. Exceptions and Limitations. For the avoidance of doubt, where\n      Exceptions and Limitations apply to Your use, this Public\n      License does not apply, and You do not need to comply with\n      its terms and conditions.\n\n   3. Term. The term of this Public License is specified in Section\n      6(a).\n\n   4. Media and formats; technical modifications allowed. The\n      Licensor authorizes You to exercise the Licensed Rights in\n      all media and formats whether now known or hereafter created,\n      and to make technical modifications necessary to do so. The\n      Licensor waives and/or agrees not to assert any right or\n      authority to forbid You from making technical modifications\n      necessary to exercise the Licensed Rights, including\n      technical modifications necessary to circumvent Effective\n      Technological Measures. For purposes of this Public License,\n      simply making modifications authorized by this Section 2(a)\n      (4) never produces Adapted Material.\n\n   5. Downstream recipients.\n\n        a. Offer from the Licensor -- Licensed Material. Every\n           recipient of the Licensed Material automatically\n           receives an offer from the Licensor to exercise the\n           Licensed Rights under the terms and conditions of this\n           Public License.\n\n        b. No downstream restrictions. You may not offer or impose\n           any additional or different terms or conditions on, or\n           apply any Effective Technological Measures to, the\n           Licensed Material if doing so restricts exercise of the\n           Licensed Rights by any recipient of the Licensed\n           Material.\n\n   6. No endorsement. Nothing in this Public License constitutes or\n      may be construed as permission to assert or imply that You\n      are, or that Your use of the Licensed Material is, connected\n      with, or sponsored, endorsed, or granted official status by,\n      the Licensor or others designated to receive attribution as\n      provided in Section 3(a)(1)(A)(i).\n</code></pre> <p>b. Other rights.</p> <pre><code>   1. Moral rights, such as the right of integrity, are not\n      licensed under this Public License, nor are publicity,\n      privacy, and/or other similar personality rights; however, to\n      the extent possible, the Licensor waives and/or agrees not to\n      assert any such rights held by the Licensor to the limited\n      extent necessary to allow You to exercise the Licensed\n      Rights, but not otherwise.\n\n   2. Patent and trademark rights are not licensed under this\n      Public License.\n\n   3. To the extent possible, the Licensor waives any right to\n      collect royalties from You for the exercise of the Licensed\n      Rights, whether directly or through a collecting society\n      under any voluntary or waivable statutory or compulsory\n      licensing scheme. In all other cases the Licensor expressly\n      reserves any right to collect such royalties.\n</code></pre> <p>Section 3 -- License Conditions.</p> <p>Your exercise of the Licensed Rights is expressly made subject to the following conditions.</p> <p>a. Attribution.</p> <pre><code>   1. If You Share the Licensed Material (including in modified\n      form), You must:\n\n        a. retain the following if it is supplied by the Licensor\n           with the Licensed Material:\n\n             i. identification of the creator(s) of the Licensed\n                Material and any others designated to receive\n                attribution, in any reasonable manner requested by\n                the Licensor (including by pseudonym if\n                designated);\n\n            ii. a copyright notice;\n\n           iii. a notice that refers to this Public License;\n\n            iv. a notice that refers to the disclaimer of\n                warranties;\n\n             v. a URI or hyperlink to the Licensed Material to the\n                extent reasonably practicable;\n\n        b. indicate if You modified the Licensed Material and\n           retain an indication of any previous modifications; and\n\n        c. indicate the Licensed Material is licensed under this\n           Public License, and include the text of, or the URI or\n           hyperlink to, this Public License.\n\n   2. You may satisfy the conditions in Section 3(a)(1) in any\n      reasonable manner based on the medium, means, and context in\n      which You Share the Licensed Material. For example, it may be\n      reasonable to satisfy the conditions by providing a URI or\n      hyperlink to a resource that includes the required\n      information.\n\n   3. If requested by the Licensor, You must remove any of the\n      information required by Section 3(a)(1)(A) to the extent\n      reasonably practicable.\n\n   4. If You Share Adapted Material You produce, the Adapter's\n      License You apply must not prevent recipients of the Adapted\n      Material from complying with this Public License.\n</code></pre> <p>Section 4 -- Sui Generis Database Rights.</p> <p>Where the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:</p> <p>a. for the avoidance of doubt, Section 2(a)(1) grants You the right      to extract, reuse, reproduce, and Share all or a substantial      portion of the contents of the database;</p> <p>b. if You include all or a substantial portion of the database      contents in a database in which You have Sui Generis Database      Rights, then the database in which You have Sui Generis Database      Rights (but not its individual contents) is Adapted Material; and</p> <p>c. You must comply with the conditions in Section 3(a) if You Share      all or a substantial portion of the contents of the database.</p> <p>For the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.</p> <p>Section 5 -- Disclaimer of Warranties and Limitation of Liability.</p> <p>a. UNLESS OTHERWISE SEPARATELY UNDERTAKEN BY THE LICENSOR, TO THE      EXTENT POSSIBLE, THE LICENSOR OFFERS THE LICENSED MATERIAL AS-IS      AND AS-AVAILABLE, AND MAKES NO REPRESENTATIONS OR WARRANTIES OF      ANY KIND CONCERNING THE LICENSED MATERIAL, WHETHER EXPRESS,      IMPLIED, STATUTORY, OR OTHER. THIS INCLUDES, WITHOUT LIMITATION,      WARRANTIES OF TITLE, MERCHANTABILITY, FITNESS FOR A PARTICULAR      PURPOSE, NON-INFRINGEMENT, ABSENCE OF LATENT OR OTHER DEFECTS,      ACCURACY, OR THE PRESENCE OR ABSENCE OF ERRORS, WHETHER OR NOT      KNOWN OR DISCOVERABLE. WHERE DISCLAIMERS OF WARRANTIES ARE NOT      ALLOWED IN FULL OR IN PART, THIS DISCLAIMER MAY NOT APPLY TO YOU.</p> <p>b. TO THE EXTENT POSSIBLE, IN NO EVENT WILL THE LICENSOR BE LIABLE      TO YOU ON ANY LEGAL THEORY (INCLUDING, WITHOUT LIMITATION,      NEGLIGENCE) OR OTHERWISE FOR ANY DIRECT, SPECIAL, INDIRECT,      INCIDENTAL, CONSEQUENTIAL, PUNITIVE, EXEMPLARY, OR OTHER LOSSES,      COSTS, EXPENSES, OR DAMAGES ARISING OUT OF THIS PUBLIC LICENSE OR      USE OF THE LICENSED MATERIAL, EVEN IF THE LICENSOR HAS BEEN      ADVISED OF THE POSSIBILITY OF SUCH LOSSES, COSTS, EXPENSES, OR      DAMAGES. WHERE A LIMITATION OF LIABILITY IS NOT ALLOWED IN FULL OR      IN PART, THIS LIMITATION MAY NOT APPLY TO YOU.</p> <p>c. The disclaimer of warranties and limitation of liability provided      above shall be interpreted in a manner that, to the extent      possible, most closely approximates an absolute disclaimer and      waiver of all liability.</p> <p>Section 6 -- Term and Termination.</p> <p>a. This Public License applies for the term of the Copyright and      Similar Rights licensed here. However, if You fail to comply with      this Public License, then Your rights under this Public License      terminate automatically.</p> <p>b. Where Your right to use the Licensed Material has terminated under      Section 6(a), it reinstates:</p> <pre><code>   1. automatically as of the date the violation is cured, provided\n      it is cured within 30 days of Your discovery of the\n      violation; or\n\n   2. upon express reinstatement by the Licensor.\n\n For the avoidance of doubt, this Section 6(b) does not affect any\n right the Licensor may have to seek remedies for Your violations\n of this Public License.\n</code></pre> <p>c. For the avoidance of doubt, the Licensor may also offer the      Licensed Material under separate terms or conditions or stop      distributing the Licensed Material at any time; however, doing so      will not terminate this Public License.</p> <p>d. Sections 1, 5, 6, 7, and 8 survive termination of this Public      License.</p> <p>Section 7 -- Other Terms and Conditions.</p> <p>a. The Licensor shall not be bound by any additional or different      terms or conditions communicated by You unless expressly agreed.</p> <p>b. Any arrangements, understandings, or agreements regarding the      Licensed Material not stated herein are separate from and      independent of the terms and conditions of this Public License.</p> <p>Section 8 -- Interpretation.</p> <p>a. For the avoidance of doubt, this Public License does not, and      shall not be interpreted to, reduce, limit, restrict, or impose      conditions on any use of the Licensed Material that could lawfully      be made without permission under this Public License.</p> <p>b. To the extent possible, if any provision of this Public License is      deemed unenforceable, it shall be automatically reformed to the      minimum extent necessary to make it enforceable. If the provision      cannot be reformed, it shall be severed from this Public License      without affecting the enforceability of the remaining terms and      conditions.</p> <p>c. No term or condition of this Public License will be waived and no      failure to comply consented to unless expressly agreed to by the      Licensor.</p> <p>d. Nothing in this Public License constitutes or may be interpreted      as a limitation upon, or waiver of, any privileges and immunities      that apply to the Licensor or You, including from the legal      processes of any jurisdiction or authority.</p> <p>=======================================================================</p> <p>Creative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the \u201cLicensor.\u201d The text of the Creative Commons public licenses is dedicated to the public domain under the CC0 Public Domain Dedication. Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark \"Creative Commons\" or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.</p> <p>Creative Commons may be contacted at creativecommons.org.</p>"},{"location":"about/","title":"Citation &amp; Feedback","text":""},{"location":"about/#cite-concord","title":"Cite CONCORD","text":"<p>If you find CONCORD helpful for your research, please consider citing our work:</p> <p>\ud83d\udcc4 CONCORD Paper</p>"},{"location":"about/#feedback-troubleshooting","title":"Feedback &amp; Troubleshooting","text":"<p>We appreciate any feedback on CONCORD! You can reach out via email or GitHub:</p> <p>\ud83d\udce7 General inquiries &amp; feedback: qin.zhu@ucsf.edu \ud83d\udc1b Report issues on GitHub: Gartner-Lab/Concord \ud83d\udce2 Collaborations: zev.gartner@ucsf.edu </p> <p>Feel free to get in touch! \ud83d\ude80</p>"},{"location":"advanced/","title":"Advanced usage","text":""},{"location":"api/main/","title":"CONCORD","text":""},{"location":"api/main/#Concord.Concord","title":"<code>Concord.Concord</code>","text":"<p>A contrastive learning framework for single-cell data analysis.</p> <p>CONCORD performs dimensionality reduction, denoising, and batch correction  in an unsupervised manner while preserving local and global topological structures.</p> <p>Attributes:</p> Name Type Description <code>adata</code> <code>AnnData</code> <p>Input AnnData object.</p> <code>save_dir</code> <code>Path</code> <p>Directory to save outputs and logs.</p> <code>config</code> <code>Config</code> <p>Configuration object storing hyperparameters.</p> <code>model</code> <code>ConcordModel</code> <p>The main contrastive learning model.</p> <code>trainer</code> <code>Trainer</code> <p>Handles model training.</p> <code>loader</code> <code>DataLoaderManager or ChunkLoader</code> <p>Data loading utilities.</p>"},{"location":"api/main/#Concord.Concord.__init__","title":"<code>__init__(adata, save_dir='save/', inplace=True, verbose=False, **kwargs)</code>","text":"<p>Initializes the Concord framework.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>Input single-cell data in AnnData format.</p> required <code>save_dir</code> <code>str</code> <p>Directory to save model outputs. Defaults to 'save/'.</p> <code>'save/'</code> <code>inplace</code> <code>bool</code> <p>If True, modifies <code>adata</code> in place. Defaults to True.</p> <code>True</code> <code>verbose</code> <code>bool</code> <p>Enable verbose logging. Defaults to False.</p> <code>False</code> <code>**kwargs</code> <p>Additional configuration parameters.</p> <code>{}</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>inplace</code> is set to True on a backed AnnData object.</p>"},{"location":"api/main/#Concord.Concord.get_default_params","title":"<code>get_default_params()</code>","text":"<p>Returns the default hyperparameters used in CONCORD.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary containing default configuration values.</p>"},{"location":"api/main/#Concord.Concord.setup_config","title":"<code>setup_config(**kwargs)</code>","text":"<p>Sets up the configuration for training.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Key-value pairs to override default parameters.</p> <code>{}</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid parameter is provided.</p>"},{"location":"api/main/#Concord.Concord.init_model","title":"<code>init_model()</code>","text":"<p>Initializes the CONCORD model and loads a pre-trained model if specified.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the specified pre-trained model file is missing.</p>"},{"location":"api/main/#Concord.Concord.init_trainer","title":"<code>init_trainer()</code>","text":"<p>Initializes the model trainer, setting up loss functions, optimizer, and learning rate scheduler.</p>"},{"location":"api/main/#Concord.Concord.init_dataloader","title":"<code>init_dataloader(input_layer_key='X_log1p', preprocess=True, train_frac=1.0, use_sampler=True)</code>","text":"<p>Initializes the data loader for training and evaluation.</p> <p>Parameters:</p> Name Type Description Default <code>input_layer_key</code> <code>str</code> <p>Key in <code>adata.layers</code> to use as input. Defaults to 'X_log1p'.</p> <code>'X_log1p'</code> <code>preprocess</code> <code>bool</code> <p>Whether to apply preprocessing. Defaults to True.</p> <code>True</code> <code>train_frac</code> <code>float</code> <p>Fraction of data to use for training. Defaults to 1.0.</p> <code>1.0</code> <code>use_sampler</code> <code>bool</code> <p>Whether to use the probabilistic sampler. Defaults to True.</p> <code>True</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>train_frac &lt; 1.0</code> and contrastive loss mode is 'nn'.</p>"},{"location":"api/main/#Concord.Concord.train","title":"<code>train(save_model=True, patience=2)</code>","text":"<p>Trains the model on the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>save_model</code> <code>bool</code> <p>Whether to save the trained model. Defaults to True.</p> <code>True</code> <code>patience</code> <code>int</code> <p>Number of epochs to wait for improvement before early stopping. Defaults to 2.</p> <code>2</code>"},{"location":"api/main/#Concord.Concord.predict","title":"<code>predict(loader, sort_by_indices=False, return_decoded=False, decoder_domain=None, return_latent=False, return_class=True, return_class_prob=True)</code>","text":"<p>Runs inference on a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>loader</code> <code>DataLoader or list</code> <p>Data loader or chunked loader for batch processing.</p> required <code>sort_by_indices</code> <code>bool</code> <p>Whether to return results in original cell order. Defaults to False.</p> <code>False</code> <code>return_decoded</code> <code>bool</code> <p>Whether to return decoded gene expression. Defaults to False.</p> <code>False</code> <code>decoder_domain</code> <code>str</code> <p>Specifies a domain for decoding. Defaults to None.</p> <code>None</code> <code>return_latent</code> <code>bool</code> <p>Whether to return latent variables. Defaults to False.</p> <code>False</code> <code>return_class</code> <code>bool</code> <p>Whether to return predicted class labels. Defaults to True.</p> <code>True</code> <code>return_class_prob</code> <code>bool</code> <p>Whether to return class probabilities. Defaults to True.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>tuple</code> <p>Encoded embeddings, decoded matrix (if requested), class predictions, class probabilities, true labels, and latent variables.</p>"},{"location":"api/main/#Concord.Concord.encode_adata","title":"<code>encode_adata(input_layer_key='X_log1p', output_key='Concord', preprocess=True, return_decoded=False, decoder_domain=None, return_latent=False, return_class=True, return_class_prob=True, save_model=True)</code>","text":"<p>Encodes an AnnData object using the CONCORD model.</p> <p>Parameters:</p> Name Type Description Default <code>input_layer_key</code> <code>str</code> <p>Input layer key. Defaults to 'X_log1p'.</p> <code>'X_log1p'</code> <code>output_key</code> <code>str</code> <p>Output key for storing results in AnnData. Defaults to 'Concord'.</p> <code>'Concord'</code> <code>preprocess</code> <code>bool</code> <p>Whether to apply preprocessing. Defaults to True.</p> <code>True</code> <code>return_decoded</code> <code>bool</code> <p>Whether to return decoded gene expression. Defaults to False.</p> <code>False</code> <code>decoder_domain</code> <code>str</code> <p>Specifies domain for decoding. Defaults to None.</p> <code>None</code> <code>return_latent</code> <code>bool</code> <p>Whether to return latent variables. Defaults to False.</p> <code>False</code> <code>return_class</code> <code>bool</code> <p>Whether to return predicted class labels. Defaults to True.</p> <code>True</code> <code>return_class_prob</code> <code>bool</code> <p>Whether to return class probabilities. Defaults to True.</p> <code>True</code> <code>save_model</code> <code>bool</code> <p>Whether to save the model after training. Defaults to True.</p> <code>True</code>"},{"location":"api/main/#Concord.Concord.get_domain_embeddings","title":"<code>get_domain_embeddings()</code>","text":"<p>Retrieves domain embeddings from the trained model.</p> <p>Returns:</p> Type Description <p>pd.DataFrame: A dataframe containing domain embeddings.</p>"},{"location":"api/main/#Concord.Concord.get_covariate_embeddings","title":"<code>get_covariate_embeddings()</code>","text":"<p>Retrieves covariate embeddings from the trained model.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary of DataFrames, each containing embeddings for a covariate.</p>"},{"location":"api/main/#Concord.Concord.save_model","title":"<code>save_model(model, save_path)</code>","text":"<p>Saves the trained model to a file.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Module</code> <p>The trained model.</p> required <code>save_path</code> <code>str or Path</code> <p>Path to save the model file.</p> required <p>Returns:</p> Type Description <p>None</p>"},{"location":"api/model/","title":"Model","text":"<p><code>model</code> can be replaced with <code>ml</code>, e.g., <code>Concord.model.ConcordModel</code> can be <code>Concord.ml.ConcordModel</code></p>"},{"location":"api/model/#Concord.model.ConcordModel","title":"<code>ConcordModel</code>","text":"<p>               Bases: <code>Module</code></p> <p>A contrastive learning model for domain-aware and covariate-aware latent representations.</p> <p>This model consists of an encoder, decoder, and optional classifier head. It supports  probabilistic augmentation and domain/covariate embeddings.</p> <p>Attributes:</p> Name Type Description <code>domain_embedding_dim</code> <code>int</code> <p>Dimensionality of domain embeddings.</p> <code>input_dim</code> <code>int</code> <p>Input feature dimension.</p> <code>augmentation_mask</code> <code>Dropout</code> <p>Dropout layer for augmentation masking.</p> <code>use_classifier</code> <code>bool</code> <p>Whether to include a classifier head.</p> <code>use_decoder</code> <code>bool</code> <p>Whether to include a decoder head.</p> <code>use_importance_mask</code> <code>bool</code> <p>Whether to include an importance mask for feature selection.</p> <code>encoder</code> <code>Sequential</code> <p>Encoder layers.</p> <code>decoder</code> <code>Sequential</code> <p>Decoder layers.</p> <code>classifier</code> <code>Sequential</code> <p>Classifier head.</p> <code>importance_mask</code> <code>Parameter</code> <p>Learnable importance mask.</p>"},{"location":"api/model/#Concord.model.ConcordModel.__init__","title":"<code>__init__(input_dim, hidden_dim, num_domains, num_classes, domain_embedding_dim=0, covariate_embedding_dims={}, covariate_num_categories={}, encoder_dims=[], decoder_dims=[], augmentation_mask_prob=0.3, dropout_prob=0.1, norm_type='layer_norm', use_decoder=True, decoder_final_activation='leaky_relu', use_classifier=False, use_importance_mask=False)</code>","text":"<p>Initializes the Concord model.</p> <p>Parameters:</p> Name Type Description Default <code>input_dim</code> <code>int</code> <p>Number of input features.</p> required <code>hidden_dim</code> <code>int</code> <p>Latent representation dimensionality.</p> required <code>num_domains</code> <code>int</code> <p>Number of unique domains for embeddings.</p> required <code>num_classes</code> <code>int</code> <p>Number of unique classes for classification.</p> required <code>domain_embedding_dim</code> <code>int</code> <p>Dimensionality of domain embeddings. Defaults to 0.</p> <code>0</code> <code>covariate_embedding_dims</code> <code>dict</code> <p>Dictionary mapping covariate keys to embedding dimensions.</p> <code>{}</code> <code>covariate_num_categories</code> <code>dict</code> <p>Dictionary mapping covariate keys to category counts.</p> <code>{}</code> <code>encoder_dims</code> <code>list</code> <p>List of encoder layer sizes. Defaults to empty list.</p> <code>[]</code> <code>decoder_dims</code> <code>list</code> <p>List of decoder layer sizes. Defaults to empty list.</p> <code>[]</code> <code>augmentation_mask_prob</code> <code>float</code> <p>Dropout probability for augmentation mask. Defaults to 0.3.</p> <code>0.3</code> <code>dropout_prob</code> <code>float</code> <p>Dropout probability for encoder/decoder layers. Defaults to 0.1.</p> <code>0.1</code> <code>norm_type</code> <code>str</code> <p>Normalization type ('layer_norm' or 'batch_norm'). Defaults to 'layer_norm'.</p> <code>'layer_norm'</code> <code>use_decoder</code> <code>bool</code> <p>Whether to include a decoder. Defaults to True.</p> <code>True</code> <code>decoder_final_activation</code> <code>str</code> <p>Activation function for decoder output. Defaults to 'leaky_relu'.</p> <code>'leaky_relu'</code> <code>use_classifier</code> <code>bool</code> <p>Whether to include a classifier head. Defaults to False.</p> <code>False</code> <code>use_importance_mask</code> <code>bool</code> <p>Whether to learn an importance mask for input features. Defaults to False.</p> <code>False</code>"},{"location":"api/model/#Concord.model.ConcordModel._initialize_weights","title":"<code>_initialize_weights()</code>","text":"<p>Initializes model weights using Kaiming normal initialization.</p>"},{"location":"api/model/#Concord.model.ConcordModel.forward","title":"<code>forward(x, domain_labels=None, covariate_tensors=None, return_latent=False)</code>","text":"<p>Performs a forward pass through the model.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Input data.</p> required <code>domain_labels</code> <code>Tensor</code> <p>Domain labels for embedding lookup.</p> <code>None</code> <code>covariate_tensors</code> <code>dict</code> <p>Dictionary of covariate labels.</p> <code>None</code> <code>return_latent</code> <code>bool</code> <p>Whether to return latent layer outputs.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary with encoded representations, decoded outputs (if enabled),    classifier predictions (if enabled), and latent activations (if requested).</p>"},{"location":"api/model/#Concord.model.ConcordModel.freeze_encoder","title":"<code>freeze_encoder()</code>","text":"<p>Freezes encoder weights to prevent updates during training.</p>"},{"location":"api/model/#Concord.model.ConcordModel.get_importance_weights","title":"<code>get_importance_weights()</code>","text":"<p>Retrieves the learned importance weights for input features.</p> <p>Returns:</p> Type Description <p>torch.Tensor: The importance weights.</p>"},{"location":"api/model/#Concord.model.ConcordModel.load_model","title":"<code>load_model(path, device)</code>","text":"<p>Loads a pre-trained model state.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str or Path</code> <p>Path to the saved model checkpoint.</p> required <code>device</code> <code>device</code> <p>Device to load the model onto.</p> required"},{"location":"api/model/#Concord.model.ConcordSampler","title":"<code>ConcordSampler</code>","text":"<p>               Bases: <code>Sampler</code></p> <p>A custom PyTorch sampler that performs probabilistic domain-aware and  neighborhood-aware batch sampling for contrastive learning.</p> <p>This sampler selects samples from both intra-domain and inter-domain  distributions based on configurable probabilities.</p> <p>Attributes:</p> Name Type Description <code>batch_size</code> <code>int</code> <p>Number of samples per batch.</p> <code>p_intra_knn</code> <code>float</code> <p>Probability of selecting samples from k-NN neighborhoods.</p> <code>p_intra_domain_dict</code> <code>dict</code> <p>Dictionary mapping domain indices to intra-domain probabilities.</p> <code>device</code> <code>device</code> <p>Device to store tensors (default: GPU if available).</p> <code>domain_ids</code> <code>Tensor</code> <p>Tensor containing domain labels for each sample.</p> <code>neighborhood</code> <code>Neighborhood</code> <p>Precomputed k-NN index.</p> <code>unique_domains</code> <code>Tensor</code> <p>Unique domain categories.</p> <code>domain_counts</code> <code>Tensor</code> <p>Number of samples per domain.</p> <code>valid_batches</code> <code>list</code> <p>List of precomputed valid batches.</p> <code>min_batch_size</code> <code>int</code> <p>Minimum allowed batch size.</p>"},{"location":"api/model/#Concord.model.ConcordSampler.__init__","title":"<code>__init__(batch_size, domain_ids, neighborhood, p_intra_knn=0.3, p_intra_domain_dict=None, min_batch_size=4, device=None)</code>","text":"<p>Initializes the ConcordSampler.</p> <p>Parameters:</p> Name Type Description Default <code>batch_size</code> <code>int</code> <p>Number of samples per batch.</p> required <code>domain_ids</code> <code>Tensor</code> <p>Tensor of domain labels for each sample.</p> required <code>neighborhood</code> <code>Neighborhood</code> <p>Precomputed k-NN index.</p> required <code>p_intra_knn</code> <code>float</code> <p>Probability of selecting samples from k-NN neighborhoods. Default is 0.3.</p> <code>0.3</code> <code>p_intra_domain_dict</code> <code>dict</code> <p>Dictionary mapping domain indices to intra-domain probabilities. Default is None.</p> <code>None</code> <code>min_batch_size</code> <code>int</code> <p>Minimum allowed batch size. Default is 4.</p> <code>4</code> <code>device</code> <code>device</code> <p>Device to store tensors. Defaults to GPU if available.</p> <code>None</code>"},{"location":"api/model/#Concord.model.ConcordSampler.__iter__","title":"<code>__iter__()</code>","text":"<p>Iterator for sampling batches.</p> <p>Yields:</p> Type Description <p>torch.Tensor: A batch of sample indices.</p>"},{"location":"api/model/#Concord.model.ConcordSampler.__len__","title":"<code>__len__()</code>","text":"<p>Returns the number of batches.</p> <p>Returns:</p> Name Type Description <code>int</code> <p>Number of valid batches.</p>"},{"location":"api/model/#Concord.model.ConcordSampler._generate_batches","title":"<code>_generate_batches()</code>","text":"<p>Generates batches based on intra-domain and intra-neighborhood probabilities.</p> <p>Returns:</p> Name Type Description <code>list</code> <p>A list of valid batches.</p>"},{"location":"api/model/#Concord.model.ConcordSampler.permute_nonneg_and_fill","title":"<code>permute_nonneg_and_fill(x, ncol)</code>  <code>staticmethod</code>","text":"<p>Permutes non-negative values and fills remaining positions with -1.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Input tensor containing indices.</p> required <code>ncol</code> <code>int</code> <p>Number of columns to keep.</p> required <p>Returns:</p> Type Description <p>torch.Tensor: Permuted tensor with -1s filling unused positions.</p>"},{"location":"api/model/#Concord.model.DataLoaderManager","title":"<code>DataLoaderManager</code>","text":"<p>Manages data loading for training and evaluation, including optional sampling.</p> <p>This class handles embedding computation, k-NN graph construction, domain-aware  sampling, and splits data into train/validation sets when needed.</p> <p>Attributes:</p> Name Type Description <code>input_layer_key</code> <code>str</code> <p>Key for input layer in AnnData.</p> <code>domain_key</code> <code>str</code> <p>Key for domain labels in <code>adata.obs</code>.</p> <code>class_key</code> <code>str</code> <p>Key for class labels in <code>adata.obs</code>. Defaults to None.</p> <code>covariate_keys</code> <code>list</code> <p>List of covariate keys in <code>adata.obs</code>. Defaults to None.</p> <code>batch_size</code> <code>int</code> <p>Batch size for data loading.</p> <code>train_frac</code> <code>float</code> <p>Fraction of data used for training.</p> <code>use_sampler</code> <code>bool</code> <p>Whether to use a custom sampler.</p> <code>sampler_emb</code> <code>str</code> <p>Key for embeddings used in sampling.</p> <code>sampler_knn</code> <code>int</code> <p>Number of k-nearest neighbors for sampling.</p> <code>p_intra_knn</code> <code>float</code> <p>Probability of intra-cluster sampling.</p> <code>p_intra_domain</code> <code>float or dict</code> <p>Probability of intra-domain sampling.</p> <code>min_p_intra_domain</code> <code>float</code> <p>Minimum probability for intra-domain sampling.</p> <code>max_p_intra_domain</code> <code>float</code> <p>Maximum probability for intra-domain sampling.</p> <code>clr_mode</code> <code>str</code> <p>Contrastive learning mode.</p> <code>dist_metric</code> <code>str</code> <p>Distance metric for k-NN graph.</p> <code>pca_n_comps</code> <code>int</code> <p>Number of PCA components used in embedding computation.</p> <code>use_faiss</code> <code>bool</code> <p>Whether to use FAISS for fast k-NN computation.</p> <code>use_ivf</code> <code>bool</code> <p>Whether to use IVF indexing for FAISS.</p> <code>ivf_nprobe</code> <code>int</code> <p>Number of probes for IVF-Faiss.</p> <code>preprocess</code> <code>callable</code> <p>Preprocessing function for <code>adata</code>.</p> <code>num_cores</code> <code>int</code> <p>Number of CPU cores for parallel processing.</p> <code>device</code> <code>device</code> <p>Device for computation (CPU or CUDA).</p>"},{"location":"api/model/#Concord.model.DataLoaderManager.__init__","title":"<code>__init__(input_layer_key, domain_key, class_key=None, covariate_keys=None, batch_size=32, train_frac=0.9, use_sampler=True, sampler_emb=None, sampler_knn=300, p_intra_knn=0.3, p_intra_domain=None, min_p_intra_domain=1.0, max_p_intra_domain=1.0, clr_mode='aug', dist_metric='euclidean', pca_n_comps=50, use_faiss=True, use_ivf=False, ivf_nprobe=8, preprocess=None, num_cores=None, device=None)</code>","text":"<p>Initializes the DataLoaderManager.</p> <p>Parameters:</p> Name Type Description Default <code>input_layer_key</code> <code>str</code> <p>Key for input layer in <code>adata</code>.</p> required <code>domain_key</code> <code>str</code> <p>Key for domain labels in <code>adata.obs</code>.</p> required <code>class_key</code> <code>str</code> <p>Key for class labels. Defaults to None.</p> <code>None</code> <code>covariate_keys</code> <code>list</code> <p>List of covariate keys. Defaults to None.</p> <code>None</code> <code>batch_size</code> <code>int</code> <p>Batch size. Defaults to 32.</p> <code>32</code> <code>train_frac</code> <code>float</code> <p>Fraction of data used for training. Defaults to 0.9.</p> <code>0.9</code> <code>use_sampler</code> <code>bool</code> <p>Whether to use the custom sampler. Defaults to True.</p> <code>True</code> <code>sampler_emb</code> <code>str</code> <p>Key for embeddings used in sampling.</p> <code>None</code> <code>sampler_knn</code> <code>int</code> <p>Number of neighbors for k-NN sampling. Defaults to 300.</p> <code>300</code> <code>p_intra_knn</code> <code>float</code> <p>Probability of intra-cluster sampling. Defaults to 0.3.</p> <code>0.3</code> <code>p_intra_domain</code> <code>float or dict</code> <p>Probability of intra-domain sampling.</p> <code>None</code> <code>min_p_intra_domain</code> <code>float</code> <p>Minimum probability for intra-domain sampling. Defaults to 1.0.</p> <code>1.0</code> <code>max_p_intra_domain</code> <code>float</code> <p>Maximum probability for intra-domain sampling. Defaults to 1.0.</p> <code>1.0</code> <code>clr_mode</code> <code>str</code> <p>Contrastive learning mode. Defaults to 'aug'.</p> <code>'aug'</code> <code>dist_metric</code> <code>str</code> <p>Distance metric for k-NN. Defaults to 'euclidean'.</p> <code>'euclidean'</code> <code>pca_n_comps</code> <code>int</code> <p>Number of PCA components. Defaults to 50.</p> <code>50</code> <code>use_faiss</code> <code>bool</code> <p>Whether to use FAISS. Defaults to True.</p> <code>True</code> <code>use_ivf</code> <code>bool</code> <p>Whether to use IVF-Faiss indexing. Defaults to False.</p> <code>False</code> <code>ivf_nprobe</code> <code>int</code> <p>Number of probes for IVF-Faiss. Defaults to 8.</p> <code>8</code> <code>preprocess</code> <code>callable</code> <p>Preprocessing function for <code>adata</code>.</p> <code>None</code> <code>num_cores</code> <code>int</code> <p>Number of CPU cores. Defaults to None.</p> <code>None</code> <code>device</code> <code>device</code> <p>Device for computation. Defaults to None.</p> <code>None</code>"},{"location":"api/model/#Concord.model.DataLoaderManager.anndata_to_dataloader","title":"<code>anndata_to_dataloader(adata)</code>","text":"<p>Converts an AnnData object to PyTorch DataLoader.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>The input AnnData object.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <p>Train DataLoader, validation DataLoader (if <code>train_frac &lt; 1.0</code>), and data structure.</p>"},{"location":"api/model/#Concord.model.DataLoaderManager.compute_embedding_and_knn","title":"<code>compute_embedding_and_knn(emb_key='X_pca')</code>","text":"<p>Constructs a k-NN graph based on existing embedding or PCA (of not exist, compute automatically).</p> <p>Parameters:</p> Name Type Description Default <code>emb_key</code> <code>str</code> <p>Key for embedding basis. Defaults to 'X_pca'.</p> <code>'X_pca'</code>"},{"location":"api/model/#Concord.model.chunkloader.ChunkLoader","title":"<code>ChunkLoader</code>","text":"<p>A class for handling large datasets in chunks for efficient training.</p> <p>This class manages chunk-based data loading for large single-cell datasets,  allowing training in smaller subsets without loading the entire dataset into memory.</p> <p>Attributes:</p> Name Type Description <code>adata</code> <code>AnnData</code> <p>The annotated data matrix.</p> <code>input_layer_key</code> <code>str</code> <p>Key for the input layer in <code>adata</code>.</p> <code>domain_key</code> <code>str</code> <p>Key for domain labels in <code>adata.obs</code>.</p> <code>class_key</code> <code>str</code> <p>Key for class labels in <code>adata.obs</code>.</p> <code>covariate_keys</code> <code>list</code> <p>List of keys for covariates in <code>adata.obs</code>.</p> <code>chunk_size</code> <code>int</code> <p>The number of samples per chunk.</p> <code>batch_size</code> <code>int</code> <p>The batch size used for training.</p> <code>train_frac</code> <code>float</code> <p>Fraction of data to be used for training.</p> <code>sampler_mode</code> <code>str</code> <p>Mode for sampling (e.g., 'domain').</p> <code>sampler_knn</code> <code>int</code> <p>Number of nearest neighbors for k-NN-based sampling.</p> <code>emb_key</code> <code>str</code> <p>Key for embedding space used in sampling.</p> <code>use_faiss</code> <code>bool</code> <p>Whether to use FAISS for k-NN computation.</p> <code>use_ivf</code> <code>bool</code> <p>Whether to use an IVF FAISS index.</p> <code>ivf_nprobe</code> <code>int</code> <p>Number of probes for IVF FAISS index.</p> <code>class_weights</code> <code>dict</code> <p>Weights for balancing class sampling.</p> <code>p_intra_knn</code> <code>float</code> <p>Probability of sampling within k-NN.</p> <code>p_intra_domain</code> <code>float</code> <p>Probability of sampling within the same domain.</p> <code>p_intra_class</code> <code>float</code> <p>Probability of sampling within the same class.</p> <code>drop_last</code> <code>bool</code> <p>Whether to drop the last batch if it is smaller than batch_size.</p> <code>preprocess</code> <code>callable</code> <p>Preprocessing function to apply to the dataset.</p> <code>device</code> <code>device</code> <p>Device on which to load data (CPU or CUDA).</p> <code>total_samples</code> <code>int</code> <p>Total number of samples in the dataset.</p> <code>num_chunks</code> <code>int</code> <p>Number of chunks required to load the full dataset.</p> <code>indices</code> <code>ndarray</code> <p>Array of shuffled indices for chunking.</p> <code>data_structure</code> <code>list</code> <p>Structure of the dataset.</p> <p>Methods:</p> Name Description <code>__len__</code> <p>Returns the number of chunks.</p> <code>_shuffle_indices</code> <p>Randomly shuffles dataset indices.</p> <code>_load_chunk</code> <p>Loads a specific chunk of data.</p> <code>__iter__</code> <p>Initializes the chunk iterator.</p> <code>__next__</code> <p>Retrieves the next chunk of data.</p>"},{"location":"api/model/#Concord.model.chunkloader.ChunkLoader.__init__","title":"<code>__init__(adata, input_layer_key, domain_key, class_key=None, covariate_keys=None, chunk_size=10000, batch_size=32, train_frac=0.9, sampler_mode='domain', emb_key=None, sampler_knn=300, p_intra_knn=0.3, p_intra_domain=1.0, use_faiss=True, use_ivf=False, ivf_nprobe=8, class_weights=None, p_intra_class=0.3, drop_last=True, preprocess=None, device=None)</code>","text":"<p>Initializes the ChunkLoader.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>The annotated data matrix.</p> required <code>input_layer_key</code> <code>str</code> <p>Key for the input layer in <code>adata</code>.</p> required <code>domain_key</code> <code>str</code> <p>Key for domain labels in <code>adata.obs</code>.</p> required <code>class_key</code> <code>str</code> <p>Key for class labels in <code>adata.obs</code>. Default is None.</p> <code>None</code> <code>covariate_keys</code> <code>list</code> <p>List of covariate keys in <code>adata.obs</code>. Default is None.</p> <code>None</code> <code>chunk_size</code> <code>int</code> <p>Number of samples per chunk. Default is 10,000.</p> <code>10000</code> <code>batch_size</code> <code>int</code> <p>Batch size used in training. Default is 32.</p> <code>32</code> <code>train_frac</code> <code>float</code> <p>Fraction of data for training. Default is 0.9.</p> <code>0.9</code> <code>sampler_mode</code> <code>str</code> <p>Sampling mode ('domain', etc.). Default is \"domain\".</p> <code>'domain'</code> <code>emb_key</code> <code>str</code> <p>Key for the embedding space used in sampling. Default is None.</p> <code>None</code> <code>sampler_knn</code> <code>int</code> <p>Number of nearest neighbors for k-NN sampling. Default is 300.</p> <code>300</code> <code>p_intra_knn</code> <code>float</code> <p>Probability of sampling within k-NN. Default is 0.3.</p> <code>0.3</code> <code>p_intra_domain</code> <code>float</code> <p>Probability of sampling within the same domain. Default is 1.0.</p> <code>1.0</code> <code>use_faiss</code> <code>bool</code> <p>Whether to use FAISS for k-NN. Default is True.</p> <code>True</code> <code>use_ivf</code> <code>bool</code> <p>Whether to use an IVF FAISS index. Default is False.</p> <code>False</code> <code>ivf_nprobe</code> <code>int</code> <p>Number of probes for IVF FAISS index. Default is 8.</p> <code>8</code> <code>class_weights</code> <code>dict</code> <p>Dictionary of class weights for balancing. Default is None.</p> <code>None</code> <code>p_intra_class</code> <code>float</code> <p>Probability of sampling within the same class. Default is 0.3.</p> <code>0.3</code> <code>drop_last</code> <code>bool</code> <p>Whether to drop the last batch if it is smaller than <code>batch_size</code>. Default is True.</p> <code>True</code> <code>preprocess</code> <code>callable</code> <p>Function to preprocess the dataset. Default is None.</p> <code>None</code> <code>device</code> <code>device</code> <p>Device on which to load data (CPU/GPU). Default is CUDA if available.</p> <code>None</code>"},{"location":"api/model/#Concord.model.chunkloader.ChunkLoader.__iter__","title":"<code>__iter__()</code>","text":"<p>Initializes the chunk iterator.</p> <p>Returns:</p> Name Type Description <code>ChunkLoader</code> <p>The chunk loader object itself.</p>"},{"location":"api/model/#Concord.model.chunkloader.ChunkLoader.__len__","title":"<code>__len__()</code>","text":"<p>Returns the total number of chunks.</p> <p>Returns:</p> Name Type Description <code>int</code> <p>Number of chunks.</p>"},{"location":"api/model/#Concord.model.chunkloader.ChunkLoader.__next__","title":"<code>__next__()</code>","text":"<p>Retrieves the next chunk of data.</p> <p>Returns:</p> Name Type Description <code>tuple</code> <p>Training DataLoader, Validation DataLoader, and chunk indices.</p> <p>Raises:</p> Type Description <code>StopIteration</code> <p>If all chunks have been iterated over.</p>"},{"location":"api/model/#Concord.model.chunkloader.ChunkLoader._load_chunk","title":"<code>_load_chunk(chunk_idx)</code>","text":"<p>Loads a specific chunk of data.</p> <p>Parameters:</p> Name Type Description Default <code>chunk_idx</code> <code>int</code> <p>Index of the chunk to load.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <p>Training DataLoader, Validation DataLoader, and chunk indices.</p>"},{"location":"api/model/#Concord.model.chunkloader.ChunkLoader._shuffle_indices","title":"<code>_shuffle_indices()</code>","text":"<p>Randomly shuffles dataset indices for chunking.</p>"},{"location":"api/model/#Concord.model.AnnDataset","title":"<code>AnnDataset</code>","text":"<p>               Bases: <code>Dataset</code></p> <p>A PyTorch Dataset class for handling annotated datasets (AnnData).</p> <p>This dataset is designed to work with single-cell RNA-seq data stored in  AnnData objects. It extracts relevant features, domain labels, class labels,  and covariate labels while handling sparse and dense matrices.</p> <p>Attributes:</p> Name Type Description <code>adata</code> <code>AnnData</code> <p>The annotated data matrix.</p> <code>input_layer_key</code> <code>str</code> <p>The key to retrieve input features from <code>adata</code>.</p> <code>domain_key</code> <code>str</code> <p>The key in <code>adata.obs</code> specifying domain labels.</p> <code>class_key</code> <code>str</code> <p>The key in <code>adata.obs</code> specifying class labels.</p> <code>covariate_keys</code> <code>list</code> <p>A list of keys for covariate labels in <code>adata.obs</code>.</p> <code>device</code> <code>device</code> <p>The device to store tensors (GPU or CPU).</p> <code>data</code> <code>Tensor</code> <p>Tensor containing input data.</p> <code>domain_labels</code> <code>Tensor</code> <p>Tensor containing domain labels.</p> <code>class_labels</code> <code>Tensor</code> <p>Tensor containing class labels if provided.</p> <code>covariate_tensors</code> <code>dict</code> <p>A dictionary containing tensors for covariate labels.</p> <code>indices</code> <code>ndarray</code> <p>Array of dataset indices.</p> <code>data_structure</code> <code>list</code> <p>A list describing the dataset structure.</p>"},{"location":"api/model/#Concord.model.AnnDataset.__getitem__","title":"<code>__getitem__(idx)</code>","text":"<p>Retrieves the dataset items for the given index.</p> <p>Parameters:</p> Name Type Description Default <code>idx</code> <code>int or list</code> <p>The sample index.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <p>A tuple containing input data, domain labels, class labels, and covariate tensors.</p>"},{"location":"api/model/#Concord.model.AnnDataset.__init__","title":"<code>__init__(adata, input_layer_key='X', domain_key='domain', class_key=None, covariate_keys=None, device=None)</code>","text":"<p>Initializes the AnnDataset.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>The annotated dataset.</p> required <code>input_layer_key</code> <code>str</code> <p>Key to extract input data. Defaults to 'X'.</p> <code>'X'</code> <code>domain_key</code> <code>str</code> <p>Key for domain labels in <code>adata.obs</code>. Defaults to 'domain'.</p> <code>'domain'</code> <code>class_key</code> <code>str</code> <p>Key for class labels in <code>adata.obs</code>. Defaults to None.</p> <code>None</code> <code>covariate_keys</code> <code>list</code> <p>List of keys for covariate labels in <code>adata.obs</code>. Defaults to None.</p> <code>None</code> <code>device</code> <code>device</code> <p>Device to store tensors (GPU or CPU). Defaults to GPU if available.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If domain or class key is not found in <code>adata.obs</code>.</p>"},{"location":"api/model/#Concord.model.AnnDataset.__len__","title":"<code>__len__()</code>","text":"<p>Returns the number of samples in the dataset.</p> <p>Returns:</p> Name Type Description <code>int</code> <p>The dataset size.</p>"},{"location":"api/model/#Concord.model.AnnDataset._get_data_matrix","title":"<code>_get_data_matrix()</code>","text":"<p>Retrieves the feature matrix from <code>adata</code>.</p> <p>Returns:</p> Type Description <p>np.ndarray: The feature matrix as a NumPy array.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If the specified input layer is not found.</p>"},{"location":"api/model/#Concord.model.AnnDataset._init_data_structure","title":"<code>_init_data_structure()</code>","text":"<p>Initializes the structure of the dataset.</p> <p>Returns:</p> Name Type Description <code>list</code> <p>A list defining the dataset structure.</p>"},{"location":"api/model/#Concord.model.AnnDataset.get_class_labels","title":"<code>get_class_labels(idx)</code>","text":"<p>Retrieves the class labels for a given index.</p> <p>Parameters:</p> Name Type Description Default <code>idx</code> <code>int or list</code> <p>Index or indices to retrieve.</p> required <p>Returns:</p> Type Description <p>torch.Tensor: The class labels.</p>"},{"location":"api/model/#Concord.model.AnnDataset.get_data_structure","title":"<code>get_data_structure()</code>","text":"<p>Returns the data structure of the dataset.</p> <p>Returns:</p> Name Type Description <code>list</code> <p>A list defining the dataset structure.</p>"},{"location":"api/model/#Concord.model.AnnDataset.get_domain_labels","title":"<code>get_domain_labels(idx)</code>","text":"<p>Retrieves the domain labels for a given index.</p> <p>Parameters:</p> Name Type Description Default <code>idx</code> <code>int or list</code> <p>Index or indices to retrieve.</p> required <p>Returns:</p> Type Description <p>torch.Tensor: The domain labels.</p>"},{"location":"api/model/#Concord.model.AnnDataset.get_embedding","title":"<code>get_embedding(embedding_key, idx)</code>","text":"<p>Retrieves embeddings for a given key and index.</p> <p>Parameters:</p> Name Type Description Default <code>embedding_key</code> <code>str</code> <p>The embedding key in <code>adata.obsm</code>.</p> required <code>idx</code> <code>int or list</code> <p>Index or indices to retrieve.</p> required <p>Returns:</p> Type Description <p>np.ndarray: The embedding matrix.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the embedding key is not found.</p>"},{"location":"api/model/#Concord.model.AnnDataset.shuffle_indices","title":"<code>shuffle_indices()</code>","text":"<p>Shuffles dataset indices.</p>"},{"location":"api/model/#Concord.model.AnnDataset.subset","title":"<code>subset(idx)</code>","text":"<p>Creates a subset of the dataset with the given indices.</p> <p>Parameters:</p> Name Type Description Default <code>idx</code> <code>list</code> <p>Indices of the subset.</p> required <p>Returns:</p> Name Type Description <code>AnnDataset</code> <p>A new AnnDataset instance containing only the selected indices.</p>"},{"location":"api/model/#Concord.model.Trainer","title":"<code>Trainer</code>","text":"<p>A trainer class for optimizing the Concord model.</p> <p>This class manages the training and validation of the Concord model,  including contrastive learning, classification, and reconstruction losses.</p> <p>Attributes:</p> Name Type Description <code>model</code> <code>Module</code> <p>The neural network model being trained.</p> <code>data_structure</code> <code>list</code> <p>The structure of the dataset used in training.</p> <code>device</code> <code>device</code> <p>The device on which computations are performed.</p> <code>logger</code> <code>Logger</code> <p>Logger for recording training progress.</p> <code>use_classifier</code> <code>bool</code> <p>Whether to use a classification head.</p> <code>classifier_weight</code> <code>float</code> <p>Weighting factor for classification loss.</p> <code>unique_classes</code> <code>list</code> <p>List of unique class labels.</p> <code>unlabeled_class</code> <code>int or None</code> <p>Label representing unlabeled samples.</p> <code>use_decoder</code> <code>bool</code> <p>Whether to use a decoder for reconstruction loss.</p> <code>decoder_weight</code> <code>float</code> <p>Weighting factor for reconstruction loss.</p> <code>clr_mode</code> <code>str</code> <p>Contrastive learning mode ('aug' or 'nn').</p> <code>use_clr</code> <code>bool</code> <p>Whether contrastive learning is enabled.</p> <code>clr_weight</code> <code>float</code> <p>Weighting factor for contrastive loss.</p> <code>importance_penalty_weight</code> <code>float</code> <p>Weighting for feature importance penalty.</p> <code>importance_penalty_type</code> <code>str</code> <p>Type of regularization for importance penalty.</p> <p>Methods:</p> Name Description <code>forward_pass</code> <p>Computes loss components and model outputs.</p> <code>train_epoch</code> <p>Runs one training epoch.</p> <code>validate_epoch</code> <p>Runs one validation epoch.</p> <code>_run_epoch</code> <p>Handles training or validation for one epoch.</p> <code>_compute_averages</code> <p>Computes average losses over an epoch.</p>"},{"location":"api/model/#Concord.model.Trainer.__init__","title":"<code>__init__(model, data_structure, device, logger, lr, schedule_ratio, use_classifier=False, classifier_weight=1.0, unique_classes=None, unlabeled_class=None, use_decoder=True, decoder_weight=1.0, clr_mode='aug', clr_temperature=0.5, clr_weight=1.0, importance_penalty_weight=0, importance_penalty_type='L1')</code>","text":"<p>Initializes the Trainer.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Module</code> <p>The neural network model to train.</p> required <code>data_structure</code> <code>list</code> <p>List defining the structure of input data.</p> required <code>device</code> <code>device</code> <p>Device on which computations will run.</p> required <code>logger</code> <code>Logger</code> <p>Logger for recording training details.</p> required <code>lr</code> <code>float</code> <p>Learning rate for the optimizer.</p> required <code>schedule_ratio</code> <code>float</code> <p>Learning rate decay factor.</p> required <code>use_classifier</code> <code>bool</code> <p>Whether to use classification. Default is False.</p> <code>False</code> <code>classifier_weight</code> <code>float</code> <p>Weight for classification loss. Default is 1.0.</p> <code>1.0</code> <code>unique_classes</code> <code>list</code> <p>List of unique class labels.</p> <code>None</code> <code>unlabeled_class</code> <code>int or None</code> <p>Label for unlabeled data. Default is None.</p> <code>None</code> <code>use_decoder</code> <code>bool</code> <p>Whether to use a decoder. Default is True.</p> <code>True</code> <code>decoder_weight</code> <code>float</code> <p>Weight for decoder loss. Default is 1.0.</p> <code>1.0</code> <code>clr_mode</code> <code>str</code> <p>Contrastive learning mode ('aug', 'nn'). Default is 'aug'.</p> <code>'aug'</code> <code>clr_temperature</code> <code>float</code> <p>Temperature for contrastive loss. Default is 0.5.</p> <code>0.5</code> <code>clr_weight</code> <code>float</code> <p>Weight for contrastive loss. Default is 1.0.</p> <code>1.0</code> <code>importance_penalty_weight</code> <code>float</code> <p>Weight for importance penalty. Default is 0.</p> <code>0</code> <code>importance_penalty_type</code> <code>str</code> <p>Type of penalty ('L1' or 'L2'). Default is 'L1'.</p> <code>'L1'</code>"},{"location":"api/model/#Concord.model.Trainer.forward_pass","title":"<code>forward_pass(inputs, class_labels, domain_labels, covariate_tensors=None)</code>","text":"<p>Performs a forward pass and computes loss components.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>Tensor</code> <p>Input feature matrix.</p> required <code>class_labels</code> <code>Tensor</code> <p>Class labels for classification loss.</p> required <code>domain_labels</code> <code>Tensor</code> <p>Domain labels for batch normalization.</p> required <code>covariate_tensors</code> <code>dict</code> <p>Dictionary of covariate tensors.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>tuple</code> <p>Loss components (total loss, classification loss, MSE loss, contrastive loss, importance penalty loss).</p>"},{"location":"api/model/#Concord.model.Trainer.train_epoch","title":"<code>train_epoch(epoch, train_dataloader)</code>","text":"<p>Runs one epoch of training.</p> <p>Parameters:</p> Name Type Description Default <code>epoch</code> <code>int</code> <p>Current epoch number.</p> required <code>train_dataloader</code> <code>DataLoader</code> <p>Training data loader.</p> required <p>Returns:</p> Name Type Description <code>float</code> <p>Average training loss.</p>"},{"location":"api/model/#Concord.model.Trainer.validate_epoch","title":"<code>validate_epoch(epoch, val_dataloader)</code>","text":"<p>Runs one epoch of validation.</p> <p>Parameters:</p> Name Type Description Default <code>epoch</code> <code>int</code> <p>Current epoch number.</p> required <code>val_dataloader</code> <code>DataLoader</code> <p>Validation data loader.</p> required <p>Returns:</p> Name Type Description <code>float</code> <p>Average validation loss.</p>"},{"location":"api/model/#Concord.model.Neighborhood","title":"<code>Neighborhood</code>","text":"<p>A class for k-nearest neighbor (k-NN) computation using either FAISS or sklearn.</p> <p>This class constructs a k-NN index, retrieves neighbors, and computes distances between embeddings.</p> <p>Attributes:</p> Name Type Description <code>emb</code> <code>ndarray</code> <p>The embedding matrix (converted to float32).</p> <code>k</code> <code>int</code> <p>Number of nearest neighbors to retrieve.</p> <code>use_faiss</code> <code>bool</code> <p>Whether to use FAISS for k-NN computation.</p> <code>use_ivf</code> <code>bool</code> <p>Whether to use IVF indexing in FAISS.</p> <code>ivf_nprobe</code> <code>int</code> <p>Number of probes for FAISS IVF.</p> <code>metric</code> <code>str</code> <p>Distance metric ('euclidean' or 'cosine').</p>"},{"location":"api/model/#Concord.model.Neighborhood.__init__","title":"<code>__init__(emb, k=10, use_faiss=True, use_ivf=False, ivf_nprobe=10, metric='euclidean')</code>","text":"<p>Initializes the Neighborhood class.</p> <p>Parameters:</p> Name Type Description Default <code>emb</code> <code>ndarray</code> <p>The embedding matrix.</p> required <code>k</code> <code>int</code> <p>Number of nearest neighbors to retrieve. Defaults to 10.</p> <code>10</code> <code>use_faiss</code> <code>bool</code> <p>Whether to use FAISS for k-NN computation. Defaults to True.</p> <code>True</code> <code>use_ivf</code> <code>bool</code> <p>Whether to use IVF FAISS index. Defaults to False.</p> <code>False</code> <code>ivf_nprobe</code> <code>int</code> <p>Number of probes for FAISS IVF. Defaults to 10.</p> <code>10</code> <code>metric</code> <code>str</code> <p>Distance metric ('euclidean' or 'cosine'). Defaults to 'euclidean'.</p> <code>'euclidean'</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If there are NaN values in the embedding or if the metric is invalid.</p>"},{"location":"api/model/#Concord.model.Neighborhood._build_knn_index","title":"<code>_build_knn_index()</code>","text":"<p>Initializes the k-NN index using FAISS or sklearn.</p>"},{"location":"api/model/#Concord.model.Neighborhood.average_knn_distance","title":"<code>average_knn_distance(core_samples, mtx, k=None, distance_metric='euclidean')</code>","text":"<p>Compute the average distance to the k-th nearest neighbor for each sample.</p>"},{"location":"api/model/#Concord.model.Neighborhood.average_knn_distance--parameters","title":"Parameters","text":"<p>core_samples : np.ndarray     The indices of core samples. mtx : np.ndarray     The matrix to compute the distance to. k : int, optional     Number of neighbors to retrieve. If None, uses self.k. distance_metric : str     Distance metric to use: 'euclidean', 'set_diff', or 'drop_diff'.</p>"},{"location":"api/model/#Concord.model.Neighborhood.average_knn_distance--returns","title":"Returns","text":"<p>np.ndarray     The average distance to the k-th nearest neighbor for each sample.</p>"},{"location":"api/model/#Concord.model.Neighborhood.compute_knn_graph","title":"<code>compute_knn_graph(k=None)</code>","text":"<p>Constructs a sparse adjacency matrix for the k-NN graph.</p> <p>Parameters:</p> Name Type Description Default <code>k</code> <code>int</code> <p>Number of neighbors. Defaults to self.k.</p> <code>None</code>"},{"location":"api/model/#Concord.model.Neighborhood.get_knn","title":"<code>get_knn(core_samples, k=None, include_self=True, return_distance=False)</code>","text":"<p>Retrieves the k-nearest neighbors for given samples.</p> <p>Parameters:</p> Name Type Description Default <code>core_samples</code> <code>ndarray or Tensor</code> <p>Indices of samples for which k-NN is retrieved.</p> required <code>k</code> <code>int</code> <p>Number of neighbors. Defaults to self.k.</p> <code>None</code> <code>include_self</code> <code>bool</code> <p>Whether to include the sample itself. Defaults to True.</p> <code>True</code> <code>return_distance</code> <code>bool</code> <p>Whether to return distances. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <p>np.ndarray: Indices of nearest neighbors (and distances if return_distance=True).</p>"},{"location":"api/model/#Concord.model.Neighborhood.get_knn_graph","title":"<code>get_knn_graph()</code>","text":"<p>Returns the precomputed k-NN graph. Computes it if not available.</p> <p>Returns:</p> Type Description <p>scipy.sparse.csr_matrix: Sparse adjacency matrix of shape (n_samples, n_samples).</p>"},{"location":"api/model/#Concord.model.Neighborhood.update_embedding","title":"<code>update_embedding(new_emb)</code>","text":"<p>Updates the embedding matrix and rebuilds the k-NN index.</p> <p>Parameters:</p> Name Type Description Default <code>new_emb</code> <code>ndarray</code> <p>The new embedding matrix.</p> required"},{"location":"api/plotting/","title":"Plotting","text":"<p><code>plotting</code> can be replaced by <code>pl</code>, e.g., <code>Concord.plotting.plot_embedding</code> can be <code>Concord.pl.plot_embedding</code></p>"},{"location":"api/plotting/#Concord.plotting.plot_embedding","title":"<code>Concord.plotting.plot_embedding(adata, basis, color_by=None, pal=None, highlight_indices=None, default_color='lightgrey', highlight_color='black', highlight_size=20, highlight_density=False, density_color='viridis', density_levels=5, density_alpha=0.5, draw_path=False, alpha=0.9, text_alpha=0.5, figsize=(9, 3), dpi=300, ncols=1, ax=None, title=None, xlabel=None, ylabel=None, xticks=True, yticks=True, colorbar_loc='right', vmax_quantile=None, vmax=None, font_size=8, point_size=10, path_width=1, legend_loc='on data', rasterized=True, seed=42, save_path=None)</code>","text":"<p>Plots a 2D embedding (e.g., UMAP, PCA) with optional highlighting and color mapping.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>Single-cell AnnData object containing embeddings and metadata.</p> required <code>basis</code> <code>str</code> <p>The name of the embedding stored in <code>adata.obsm</code> (e.g., <code>'X_umap'</code>).</p> required <code>color_by</code> <code>str | list</code> <p>Column(s) in <code>adata.obs</code> to color the points by. Defaults to None.</p> <code>None</code> <code>pal</code> <code>dict</code> <p>Color palette mapping category values to colors. Defaults to None.</p> <code>None</code> <code>highlight_indices</code> <code>list</code> <p>Indices of points to highlight. Defaults to None.</p> <code>None</code> <code>default_color</code> <code>str</code> <p>Default color for uncolored points. Defaults to \"lightgrey\".</p> <code>'lightgrey'</code> <code>highlight_color</code> <code>str</code> <p>Color for highlighted points. Defaults to \"black\".</p> <code>'black'</code> <code>highlight_size</code> <code>int</code> <p>Size of highlighted points. Defaults to 20.</p> <code>20</code> <code>draw_path</code> <code>bool</code> <p>Whether to draw a path connecting highlighted points. Defaults to False.</p> <code>False</code> <code>alpha</code> <code>float</code> <p>Opacity of points. Defaults to 0.9.</p> <code>0.9</code> <code>text_alpha</code> <code>float</code> <p>Opacity of text labels. Defaults to 0.5.</p> <code>0.5</code> <code>figsize</code> <code>tuple</code> <p>Figure size (width, height). Defaults to (9, 3).</p> <code>(9, 3)</code> <code>dpi</code> <code>int</code> <p>Resolution of the figure. Defaults to 300.</p> <code>300</code> <code>ncols</code> <code>int</code> <p>Number of columns for subplots. Defaults to 1.</p> <code>1</code> <code>ax</code> <code>Axes</code> <p>Axes object for the plot. Defaults to None.</p> <code>None</code> <code>title</code> <code>str</code> <p>Title of the plot. Defaults to None.</p> <code>None</code> <code>xlabel</code> <code>str</code> <p>Label for X-axis. Defaults to None.</p> <code>None</code> <code>ylabel</code> <code>str</code> <p>Label for Y-axis. Defaults to None.</p> <code>None</code> <code>xticks</code> <code>bool</code> <p>Whether to show X-axis ticks. Defaults to True.</p> <code>True</code> <code>yticks</code> <code>bool</code> <p>Whether to show Y-axis ticks. Defaults to True.</p> <code>True</code> <code>colorbar_loc</code> <code>str</code> <p>Location of colorbar (\"right\", \"left\", \"bottom\", etc.). Defaults to \"right\".</p> <code>'right'</code> <code>vmax_quantile</code> <code>float</code> <p>If provided, scales the color range to this quantile. Defaults to None.</p> <code>None</code> <code>vmax</code> <code>float</code> <p>Maximum value for color scaling. Defaults to None.</p> <code>None</code> <code>font_size</code> <code>int</code> <p>Font size for annotations. Defaults to 8.</p> <code>8</code> <code>point_size</code> <code>int</code> <p>Size of scatter plot points. Defaults to 10.</p> <code>10</code> <code>path_width</code> <code>int</code> <p>Width of path lines (if <code>draw_path=True</code>). Defaults to 1.</p> <code>1</code> <code>legend_loc</code> <code>str</code> <p>Location of the legend (\"on data\", \"right margin\", etc.). Defaults to \"on data\".</p> <code>'on data'</code> <code>rasterized</code> <code>bool</code> <p>If True, rasterizes the points for efficient plotting. Defaults to True.</p> <code>True</code> <code>seed</code> <code>int</code> <p>Random seed for reproducibility. Defaults to 42.</p> <code>42</code> <code>save_path</code> <code>str</code> <p>Path to save the figure. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <p>None</p>"},{"location":"api/plotting/#Concord.plotting.plot_all_embeddings","title":"<code>Concord.plotting.plot_all_embeddings(adata, combined_keys, color_bys=['time', 'batch'], basis_types=['PAGA', 'KNN', 'PCA', 'UMAP'], pal={'time': 'viridis', 'batch': 'Set1'}, vmax_quantile=None, k=15, edges_color='grey', edges_width=0.05, layout='kk', threshold=0.1, node_size_scale=0.1, edge_width_scale=0.1, font_size=7, legend_font_size=2, point_size=2.5, alpha=0.8, figsize=(9, 0.9), ncols=11, seed=42, leiden_key='leiden', leiden_resolution=1.0, legend_loc=None, colorbar_loc=None, rasterized=True, save_dir='.', dpi=300, save_format='png', file_suffix='plot', highlight_indices=None, highlight_color='black', highlight_size=20, draw_path=False, path_width=1)</code>","text":"<p>Plots multiple 2D embeddings (PAGA, KNN, PCA, UMAP) with different color mappings.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>Single-cell AnnData object containing embeddings.</p> required <code>combined_keys</code> <code>list</code> <p>List of feature representations (e.g., <code>['X_pca', 'X_umap']</code>).</p> required <code>color_bys</code> <code>tuple</code> <p>List of <code>adata.obs</code> columns to color by. Defaults to <code>(\"time\", \"batch\")</code>.</p> <code>['time', 'batch']</code> <code>basis_types</code> <code>tuple</code> <p>Types of embeddings to plot. Defaults to <code>(\"PAGA\", \"KNN\", \"PCA\", \"UMAP\")</code>.</p> <code>['PAGA', 'KNN', 'PCA', 'UMAP']</code> <code>pal</code> <code>dict</code> <p>Color palettes for each <code>color_by</code> variable. Defaults to <code>{\"time\": \"viridis\", \"batch\": \"Set1\"}</code>.</p> <code>{'time': 'viridis', 'batch': 'Set1'}</code> <code>vmax_quantile</code> <code>float</code> <p>Upper quantile for color scaling in numeric data. Defaults to None.</p> <code>None</code> <code>k</code> <code>int</code> <p>Number of neighbors for KNN and PAGA graphs. Defaults to 15.</p> <code>15</code> <code>edges_color</code> <code>str</code> <p>Color of edges in KNN/PAGA graphs. Defaults to <code>\"grey\"</code>.</p> <code>'grey'</code> <code>edges_width</code> <code>float</code> <p>Width of edges in KNN/PAGA graphs. Defaults to 0.05.</p> <code>0.05</code> <code>layout</code> <code>str</code> <p>Graph layout algorithm for KNN/PAGA. Defaults to <code>\"kk\"</code>.</p> <code>'kk'</code> <code>threshold</code> <code>float</code> <p>Edge threshold for PAGA visualization. Defaults to 0.1.</p> <code>0.1</code> <code>node_size_scale</code> <code>float</code> <p>Scale factor for PAGA node sizes. Defaults to 0.1.</p> <code>0.1</code> <code>edge_width_scale</code> <code>float</code> <p>Scale factor for PAGA edge widths. Defaults to 0.1.</p> <code>0.1</code> <code>font_size</code> <code>int</code> <p>Font size for plot annotations. Defaults to 7.</p> <code>7</code> <code>legend_font_size</code> <code>int</code> <p>Font size for legends. Defaults to 2.</p> <code>2</code> <code>point_size</code> <code>float</code> <p>Size of scatter plot points. Defaults to 2.5.</p> <code>2.5</code> <code>alpha</code> <code>float</code> <p>Transparency of points. Defaults to 0.8.</p> <code>0.8</code> <code>figsize</code> <code>tuple</code> <p>Figure size (width, height). Defaults to <code>(9, 0.9)</code>.</p> <code>(9, 0.9)</code> <code>ncols</code> <code>int</code> <p>Number of columns for subplot grid. Defaults to 11.</p> <code>11</code> <code>seed</code> <code>int</code> <p>Random seed for reproducibility. Defaults to 42.</p> <code>42</code> <code>leiden_key</code> <code>str</code> <p>Key for Leiden clustering in PAGA. Defaults to <code>\"leiden\"</code>.</p> <code>'leiden'</code> <code>leiden_resolution</code> <code>float</code> <p>Resolution parameter for Leiden clustering. Defaults to 1.0.</p> <code>1.0</code> <code>legend_loc</code> <code>str</code> <p>Location of the legend. Defaults to None.</p> <code>None</code> <code>colorbar_loc</code> <code>str</code> <p>Location of the colorbar. Defaults to None.</p> <code>None</code> <code>rasterized</code> <code>bool</code> <p>Whether to rasterize the plot. Defaults to True.</p> <code>True</code> <code>save_dir</code> <code>str</code> <p>Directory to save plots. Defaults to <code>\".\"</code>.</p> <code>'.'</code> <code>dpi</code> <code>int</code> <p>Image resolution. Defaults to 300.</p> <code>300</code> <code>save_format</code> <code>str</code> <p>Image format (<code>\"png\"</code>, <code>\"pdf\"</code>, etc.). Defaults to <code>\"png\"</code>.</p> <code>'png'</code> <code>file_suffix</code> <code>str</code> <p>Filename suffix. Defaults to <code>\"plot\"</code>.</p> <code>'plot'</code> <code>highlight_indices</code> <code>list</code> <p>Indices of highlighted points. Defaults to None.</p> <code>None</code> <code>highlight_color</code> <code>str</code> <p>Color of highlighted points. Defaults to <code>\"black\"</code>.</p> <code>'black'</code> <code>highlight_size</code> <code>int</code> <p>Size of highlighted points. Defaults to 20.</p> <code>20</code> <code>draw_path</code> <code>bool</code> <p>Whether to draw a connecting path for highlights. Defaults to False.</p> <code>False</code> <code>path_width</code> <code>int</code> <p>Width of connecting paths. Defaults to 1.</p> <code>1</code> <p>Returns:</p> Type Description <p>None</p>"},{"location":"api/plotting/#Concord.plotting.plot_embedding_3d","title":"<code>Concord.plotting.plot_embedding_3d(adata, basis='encoded_UMAP', color_by='batch', pal=None, save_path=None, point_size=3, opacity=0.7, seed=42, width=800, height=600, engine='plotly', autosize=True, static=False, static_format='png')</code>","text":"<p>Plots a 3D embedding using Plotly or Matplotlib.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>Single-cell AnnData object containing embeddings.</p> required <code>basis</code> <code>str</code> <p>The name of the 3D embedding stored in <code>adata.obsm</code>. Defaults to <code>'encoded_UMAP'</code>.</p> <code>'encoded_UMAP'</code> <code>color_by</code> <code>str</code> <p>Column in <code>adata.obs</code> used to color points. Defaults to <code>'batch'</code>.</p> <code>'batch'</code> <code>pal</code> <code>dict</code> <p>Color palette mapping categorical variables to colors. Defaults to None.</p> <code>None</code> <code>save_path</code> <code>str</code> <p>Path to save the figure. Defaults to None.</p> <code>None</code> <code>point_size</code> <code>int</code> <p>Size of the points in the plot. Defaults to 3.</p> <code>3</code> <code>opacity</code> <code>float</code> <p>Opacity of the points. Defaults to 0.7.</p> <code>0.7</code> <code>seed</code> <code>int</code> <p>Random seed for reproducibility. Defaults to 42.</p> <code>42</code> <code>width</code> <code>int</code> <p>Width of the plot in pixels. Defaults to 800.</p> <code>800</code> <code>height</code> <code>int</code> <p>Height of the plot in pixels. Defaults to 600.</p> <code>600</code> <code>engine</code> <code>str</code> <p>Rendering engine (<code>'plotly'</code> or <code>'matplotlib'</code>). Defaults to <code>'plotly'</code>.</p> <code>'plotly'</code> <code>autosize</code> <code>bool</code> <p>Whether to automatically adjust plot size. Defaults to True.</p> <code>True</code> <code>static</code> <code>bool</code> <p>If True, saves the plot as a static image. Defaults to False.</p> <code>False</code> <code>static_format</code> <code>str</code> <p>Format for static image (e.g., <code>'png'</code>, <code>'pdf'</code>). Defaults to <code>'png'</code>.</p> <code>'png'</code> <p>Returns:</p> Type Description <p>plotly.Figure or matplotlib.Figure: A 3D scatter plot.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the engine is not <code>'plotly'</code> or <code>'matplotlib'</code>.</p>"},{"location":"api/plotting/#Concord.plotting.plot_all_embeddings_3d","title":"<code>Concord.plotting.plot_all_embeddings_3d(adata, combined_keys, color_bys=('time', 'batch'), basis_types=('UMAP_3D',), pal=None, point_size=2.5, alpha=0.8, figsize=(10, 5), ncols=4, seed=42, legend_font_size=5, rasterized=False, save_dir='.', dpi=300, save_format='png', file_suffix='3d_plot', elev=30, azim=45, zoom_factor=0.0, **kwargs)</code>","text":"<p>Plots multiple 3D embeddings with different color mappings across various embedding types.</p> <p>Each subplot represents a different embedding (e.g., UMAP_3D) with a specified coloring  (e.g., time, batch). This function generates a grid of 3D scatter plots.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>Single-cell AnnData object containing embeddings.</p> required <code>combined_keys</code> <code>list</code> <p>List of feature representations for which embeddings exist in <code>adata.obsm</code>.</p> required <code>color_bys</code> <code>tuple of str</code> <p>List of <code>adata.obs</code> columns to color points by. Defaults to <code>('time', 'batch')</code>.</p> <code>('time', 'batch')</code> <code>basis_types</code> <code>tuple of str</code> <p>Types of embeddings to plot. Defaults to <code>('UMAP_3D',)</code>.</p> <code>('UMAP_3D',)</code> <code>pal</code> <code>dict</code> <p>Dictionary mapping categorical values to colors. Defaults to None.</p> <code>None</code> <code>point_size</code> <code>float</code> <p>Size of points in the scatter plot. Defaults to <code>2.5</code>.</p> <code>2.5</code> <code>alpha</code> <code>float</code> <p>Opacity of points. Defaults to <code>0.8</code>.</p> <code>0.8</code> <code>figsize</code> <code>tuple</code> <p>Figure size in inches (width, height). Defaults to <code>(10, 5)</code>.</p> <code>(10, 5)</code> <code>ncols</code> <code>int</code> <p>Number of columns in the subplot grid. Defaults to <code>4</code>.</p> <code>4</code> <code>seed</code> <code>int</code> <p>Random seed for color mapping. Defaults to <code>42</code>.</p> <code>42</code> <code>legend_font_size</code> <code>int</code> <p>Font size for legend labels. Defaults to <code>5</code>.</p> <code>5</code> <code>rasterized</code> <code>bool</code> <p>Whether to rasterize the scatter plots to reduce file size. Defaults to <code>False</code>.</p> <code>False</code> <code>save_dir</code> <code>str</code> <p>Directory where plots will be saved. Defaults to <code>'.'</code>.</p> <code>'.'</code> <code>dpi</code> <code>int</code> <p>Image resolution in dots per inch. Defaults to <code>300</code>.</p> <code>300</code> <code>save_format</code> <code>str</code> <p>Image format (<code>'png'</code>, <code>'pdf'</code>, <code>'svg'</code>, etc.). Defaults to <code>'png'</code>.</p> <code>'png'</code> <code>file_suffix</code> <code>str</code> <p>Suffix to append to saved file names. Defaults to <code>'3d_plot'</code>.</p> <code>'3d_plot'</code> <code>elev</code> <code>float</code> <p>Elevation angle for 3D view. Defaults to <code>30</code>.</p> <code>30</code> <code>azim</code> <code>float</code> <p>Azimuth angle for 3D view. Defaults to <code>45</code>.</p> <code>45</code> <code>zoom_factor</code> <code>float</code> <p>Zoom factor to adjust the scale of the plot. Defaults to <code>0.0</code>.</p> <code>0.0</code> <code>**kwargs</code> <p>Additional parameters forwarded to <code>plot_embedding_3d_matplotlib</code> for customization.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>None</code> <p>Saves one figure per (basis_type, color_by) combination.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If a specified <code>basis_type</code> is not found</p>"},{"location":"api/plotting/#Concord.plotting.plot_rotating_embedding_3d_to_mp4","title":"<code>Concord.plotting.plot_rotating_embedding_3d_to_mp4(adata, embedding_key='encoded_UMAP', color_by='batch', save_path='rotation.mp4', pal=None, point_size=3, opacity=0.7, width=800, height=1200, rotation_duration=10, num_steps=60, legend_itemsize=100, font_size=16, seed=42)</code>","text":"<p>Generates a rotating 3D embedding animation and saves it as an MP4 video.</p> <p>This function visualizes a 3D embedding (e.g., UMAP, PCA) with an animated rotation  and saves it as an MP4 video. The colors can be mapped to different cell metadata.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>Single-cell AnnData object containing embeddings and metadata.</p> required <code>embedding_key</code> <code>str</code> <p>Key in <code>adata.obsm</code> where the 3D embedding is stored. Defaults to <code>'encoded_UMAP'</code>.</p> <code>'encoded_UMAP'</code> <code>color_by</code> <code>str</code> <p>Column in <code>adata.obs</code> to color points by. Defaults to <code>'batch'</code>.</p> <code>'batch'</code> <code>save_path</code> <code>str</code> <p>File path to save the MP4 video. Defaults to <code>'rotation.mp4'</code>.</p> <code>'rotation.mp4'</code> <code>pal</code> <code>dict</code> <p>Color palette mapping categorical values to colors. Defaults to None.</p> <code>None</code> <code>point_size</code> <code>int</code> <p>Size of the scatter plot points. Defaults to <code>3</code>.</p> <code>3</code> <code>opacity</code> <code>float</code> <p>Opacity of the scatter plot points. Defaults to <code>0.7</code>.</p> <code>0.7</code> <code>width</code> <code>int</code> <p>Width of the output video in pixels. Defaults to <code>800</code>.</p> <code>800</code> <code>height</code> <code>int</code> <p>Height of the output video in pixels. Defaults to <code>1200</code>.</p> <code>1200</code> <code>rotation_duration</code> <code>int</code> <p>Duration of the rotation animation in seconds. Defaults to <code>10</code>.</p> <code>10</code> <code>num_steps</code> <code>int</code> <p>Number of frames used for the rotation. Higher values result in a smoother animation. Defaults to <code>60</code>.</p> <code>60</code> <code>legend_itemsize</code> <code>int</code> <p>Size of legend markers for categorical color mappings. Defaults to <code>100</code>.</p> <code>100</code> <code>font_size</code> <code>int</code> <p>Font size for legends and labels. Defaults to <code>16</code>.</p> <code>16</code> <code>seed</code> <code>int</code> <p>Random seed for color mapping. Defaults to <code>42</code>.</p> <code>42</code> <p>Returns:</p> Name Type Description <code>None</code> <p>Saves the rotating animation as an MP4 file.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If <code>embedding_key</code> is not found in <code>adata.obsm</code> or <code>color_by</code> is not in <code>adata.obs</code>.</p> <code>ValueError</code> <p>If the specified embedding has fewer than 3 dimensions.</p> Example <pre><code>plot_rotating_embedding_3d_to_mp4(\n    adata,\n    embedding_key='X_umap',\n    color_by='cell_type',\n    save_path='3D_rotation.mp4',\n    rotation_duration=15,\n    num_steps=90\n)\n</code></pre>"},{"location":"api/plotting/#Concord.plotting.heatmap_with_annotations","title":"<code>Concord.plotting.heatmap_with_annotations(adata, val, transpose=True, obs_keys=None, cmap='viridis', vmin=None, vmax=None, cluster_rows=True, cluster_cols=True, pal=None, add_color_legend=False, value_annot=False, title=None, title_fontsize=16, annot_fontsize=8, yticklabels=True, xticklabels=False, use_clustermap=True, cluster_method='ward', cluster_metric='euclidean', rasterize=True, ax=None, figsize=(12, 8), seed=42, dpi=300, show=True, save_path=None)</code>","text":"<p>Creates a heatmap colored by multiple columns in <code>adata.obs</code>, optionally clusters the rows/columns,  and provides categorical or continuous annotations.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>AnnData object containing the dataset.</p> required <code>val</code> <code>str | ndarray | DataFrame</code> <p>Data source for heatmap. Can be:     - <code>'X'</code>: Uses <code>adata.X</code>     - A layer name from <code>adata.layers</code>     - An embedding from <code>adata.obsm</code>     - A <code>numpy.ndarray</code> or <code>pandas.DataFrame</code></p> required <code>transpose</code> <code>bool</code> <p>If <code>True</code>, transposes the data matrix. Defaults to <code>True</code>.</p> <code>True</code> <code>obs_keys</code> <code>list</code> <p>List of column names in <code>adata.obs</code> to use for categorical or numerical coloring. Defaults to <code>None</code>.</p> <code>None</code> <code>cmap</code> <code>str</code> <p>Colormap for heatmap values. Defaults to <code>'viridis'</code>.</p> <code>'viridis'</code> <code>vmin</code> <code>float</code> <p>Minimum value for color scaling. Defaults to <code>None</code>.</p> <code>None</code> <code>vmax</code> <code>float</code> <p>Maximum value for color scaling. Defaults to <code>None</code>.</p> <code>None</code> <code>cluster_rows</code> <code>bool</code> <p>Whether to cluster rows. Defaults to <code>True</code>.</p> <code>True</code> <code>cluster_cols</code> <code>bool</code> <p>Whether to cluster columns. Defaults to <code>True</code>.</p> <code>True</code> <code>pal</code> <code>dict</code> <p>Dictionary mapping category values to colors. Defaults to <code>None</code>.</p> <code>None</code> <code>add_color_legend</code> <code>bool</code> <p>If <code>True</code>, adds a legend for categorical annotations. Defaults to <code>False</code>.</p> <code>False</code> <code>value_annot</code> <code>bool</code> <p>If <code>True</code>, annotates each heatmap cell with values. Defaults to <code>False</code>.</p> <code>False</code> <code>title</code> <code>str</code> <p>Title of the heatmap. Defaults to <code>None</code>.</p> <code>None</code> <code>title_fontsize</code> <code>int</code> <p>Font size for title. Defaults to <code>16</code>.</p> <code>16</code> <code>annot_fontsize</code> <code>int</code> <p>Font size for annotations (if <code>value_annot=True</code>). Defaults to <code>8</code>.</p> <code>8</code> <code>yticklabels</code> <code>bool</code> <p>Whether to show row labels. Defaults to <code>True</code>.</p> <code>True</code> <code>xticklabels</code> <code>bool</code> <p>Whether to show column labels. Defaults to <code>False</code>.</p> <code>False</code> <code>use_clustermap</code> <code>bool</code> <p>If <code>True</code>, uses <code>seaborn.clustermap</code> for hierarchical clustering. Otherwise, uses <code>sns.heatmap</code>. Defaults to <code>True</code>.</p> <code>True</code> <code>cluster_method</code> <code>str</code> <p>Clustering method for hierarchical clustering (e.g., <code>'ward'</code>, <code>'average'</code>, <code>'single'</code>). Defaults to <code>'ward'</code>.</p> <code>'ward'</code> <code>cluster_metric</code> <code>str</code> <p>Distance metric for hierarchical clustering (e.g., <code>'euclidean'</code>, <code>'correlation'</code>). Defaults to <code>'euclidean'</code>.</p> <code>'euclidean'</code> <code>rasterize</code> <code>bool</code> <p>If <code>True</code>, rasterizes heatmap elements for efficient plotting. Defaults to <code>True</code>.</p> <code>True</code> <code>ax</code> <code>Axes</code> <p>Matplotlib Axes object to plot on. Defaults to <code>None</code>.</p> <code>None</code> <code>figsize</code> <code>tuple</code> <p>Size of the figure <code>(width, height)</code>. Defaults to <code>(12, 8)</code>.</p> <code>(12, 8)</code> <code>seed</code> <code>int</code> <p>Random seed for reproducibility. Defaults to <code>42</code>.</p> <code>42</code> <code>dpi</code> <code>int</code> <p>Resolution of the saved figure. Defaults to <code>300</code>.</p> <code>300</code> <code>show</code> <code>bool</code> <p>If <code>True</code>, displays the plot. Defaults to <code>True</code>.</p> <code>True</code> <code>save_path</code> <code>str</code> <p>Path to save the figure. If <code>None</code>, the figure is not saved. Defaults to <code>None</code>.</p> <code>None</code> <p>Returns:</p> Type Description <p>matplotlib.Axes | seaborn.ClusterGrid:  - If <code>use_clustermap=True</code>, returns a <code>seaborn.ClusterGrid</code> object. - Otherwise, returns a <code>matplotlib.Axes</code> object.</p>"},{"location":"api/plotting/#Concord.plotting.plot_benchmark_table","title":"<code>Concord.plotting.plot_benchmark_table(df, pal='PRGn', pal_agg='YlGnBu', cmap_method='norm', cmap_padding=0.05, agg_name='Aggregate score', dpi=300, save_path=None, figsize=None)</code>","text":"<p>Plots a benchmarking results table using the <code>plottable</code> library.</p> <p>This function creates a formatted table displaying different benchmarking metrics  across various methods. It includes: - Circle-marked metric values. - Color-encoded values based on a chosen colormap. - Aggregate scores visualized as bar charts.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The benchmarking results DataFrame. It should have a multi-index in columns  where the first level represents metric categories and the second level contains  metric names.</p> required <code>pal</code> <code>str</code> <p>Colormap for individual metric values. Defaults to <code>'PRGn'</code>.</p> <code>'PRGn'</code> <code>pal_agg</code> <code>str</code> <p>Colormap for aggregate scores. Defaults to <code>'YlGnBu'</code>.</p> <code>'YlGnBu'</code> <code>cmap_method</code> <code>str</code> <p>Method for normalizing colormaps. Options:     - <code>'norm'</code>: Normalize based on standard deviation.     - <code>'minmax'</code>: Normalize based on the min-max range.     - <code>'minmax_padded'</code>: Adds padding to the min-max normalization.     - <code>'0_to_1'</code>: Normalize between 0 and 1. Defaults to <code>'norm'</code>.</p> <code>'norm'</code> <code>cmap_padding</code> <code>float</code> <p>Padding factor for <code>minmax_padded</code> colormap normalization. Defaults to <code>0.05</code>.</p> <code>0.05</code> <code>agg_name</code> <code>str</code> <p>The name of the aggregate score column. Defaults to <code>'Aggregate score'</code>.</p> <code>'Aggregate score'</code> <code>dpi</code> <code>int</code> <p>Resolution of the saved figure. Defaults to <code>300</code>.</p> <code>300</code> <code>save_path</code> <code>str</code> <p>If provided, saves the figure to the specified path. Defaults to <code>None</code>.</p> <code>None</code> <code>figsize</code> <code>tuple</code> <p>Figure size <code>(width, height)</code>. If <code>None</code>, it is determined dynamically based on  the number of columns and rows. Defaults to <code>None</code>.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>cmap_method</code> is not one of <code>'norm'</code>, <code>'minmax'</code>, <code>'minmax_padded'</code>, or <code>'0_to_1'</code>.</p> <p>Returns:</p> Type Description <p>None</p>"},{"location":"api/plotting/#Concord.plotting.plot_adata_layer_heatmaps","title":"<code>Concord.plotting.plot_adata_layer_heatmaps(adata, ncells=None, ngenes=None, layers=['X_concord_decoded', 'X_log1p'], transpose=False, obs_keys=None, cluster_rows=False, cluster_cols=False, use_clustermap=False, seed=0, figsize=(6, 6), cmap='viridis', dpi=300, vmin=None, vmax=None, save_path=None)</code>","text":"<p>Plots heatmaps of selected layers from an AnnData object, optionally clustering rows and columns.</p> <p>This function visualizes gene expression data from different layers of an AnnData object as heatmaps. It allows for subsampling of cells and genes, clustering of rows and columns, and saving the output figure.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>The AnnData object containing gene expression data.</p> required <code>ncells</code> <code>int</code> <p>Number of cells to subsample. If None, uses all cells. Defaults to <code>None</code>.</p> <code>None</code> <code>ngenes</code> <code>int</code> <p>Number of genes to subsample. If None, uses all genes. Defaults to <code>None</code>.</p> <code>None</code> <code>layers</code> <code>list of str</code> <p>List of layer names to plot heatmaps for. Defaults to <code>['X_concord_decoded', 'X_log1p']</code>.</p> <code>['X_concord_decoded', 'X_log1p']</code> <code>transpose</code> <code>bool</code> <p>If True, transposes the heatmap (genes as columns). Defaults to <code>False</code>.</p> <code>False</code> <code>obs_keys</code> <code>list of str</code> <p>List of categorical metadata columns from <code>adata.obs</code> to annotate along heatmap axes. Defaults to <code>None</code>.</p> <code>None</code> <code>cluster_rows</code> <code>bool</code> <p>Whether to cluster rows (genes). Defaults to <code>False</code>.</p> <code>False</code> <code>cluster_cols</code> <code>bool</code> <p>Whether to cluster columns (cells). Defaults to <code>False</code>.</p> <code>False</code> <code>use_clustermap</code> <code>bool</code> <p>If True, uses <code>seaborn.clustermap</code> instead of <code>sns.heatmap</code> for hierarchical clustering. Defaults to <code>False</code>.</p> <code>False</code> <code>seed</code> <code>int</code> <p>Random seed for reproducibility in subsampling. Defaults to <code>0</code>.</p> <code>0</code> <code>figsize</code> <code>tuple</code> <p>Figure size <code>(width, height)</code>. Defaults to <code>(6, 6)</code>.</p> <code>(6, 6)</code> <code>cmap</code> <code>str</code> <p>Colormap for the heatmap. Defaults to <code>'viridis'</code>.</p> <code>'viridis'</code> <code>dpi</code> <code>int</code> <p>Resolution of the saved figure. Defaults to <code>300</code>.</p> <code>300</code> <code>vmin</code> <code>float</code> <p>Minimum value for heatmap normalization. Defaults to <code>None</code>.</p> <code>None</code> <code>vmax</code> <code>float</code> <p>Maximum value for heatmap normalization. Defaults to <code>None</code>.</p> <code>None</code> <code>save_path</code> <code>str</code> <p>If provided, saves the heatmap figure to the specified path. Defaults to <code>None</code>.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>ncells</code> or <code>ngenes</code> is greater than the dimensions of <code>adata</code>.</p> <code>ValueError</code> <p>If a specified <code>layer</code> is not found in <code>adata.layers</code>.</p> <p>Returns:</p> Type Description <p>None Displays the heatmaps and optionally saves the figure.</p> Example <pre><code>plot_adata_layer_heatmaps(adata, ncells=500, ngenes=100, layers=['X', 'X_log1p'],\n                          cluster_rows=True, cluster_cols=True, use_clustermap=True,\n                          save_path=\"heatmap.png\")\n</code></pre>"},{"location":"api/plotting/#Concord.plotting.visualize_importance_weights","title":"<code>Concord.plotting.visualize_importance_weights(model, adata, top_n=20, mode='histogram', fontsize=12, figsize=(5, 3), save_path=None)</code>","text":"<p>Visualizes feature importance weights from a trained model.</p> <p>This function plots either a histogram of all importance weights or a bar chart of the top features based on their importance values.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Module</code> <p>The trained model containing feature importance weights.</p> required <code>adata</code> <code>AnnData</code> <p>The AnnData object containing gene expression data.</p> required <code>top_n</code> <code>int</code> <p>Number of top features to plot when <code>mode</code> is not 'histogram'. Defaults to <code>20</code>.</p> <code>20</code> <code>mode</code> <code>str</code> <p>Visualization mode. Options: - <code>'histogram'</code>: Plots the distribution of all importance weights. - <code>'highest'</code>: Shows top <code>top_n</code> features with highest importance. - <code>'lowest'</code>: Shows <code>top_n</code> features with lowest importance. - <code>'absolute'</code>: Shows <code>top_n</code> features with highest absolute importance. Defaults to <code>'histogram'</code>.</p> <code>'histogram'</code> <code>fontsize</code> <code>int</code> <p>Font size for axis labels and titles. Defaults to <code>12</code>.</p> <code>12</code> <code>figsize</code> <code>tuple</code> <p>Figure size <code>(width, height)</code>. Defaults to <code>(5, 3)</code>.</p> <code>(5, 3)</code> <code>save_path</code> <code>str</code> <p>If provided, saves the figure at the specified path. Defaults to <code>None</code>.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>mode</code> is not one of <code>'histogram'</code>, <code>'highest'</code>, <code>'lowest'</code>, <code>'absolute'</code>.</p> <p>Returns:</p> Type Description <p>None Displays or saves the importance weights plot.</p> Example <pre><code>visualize_importance_weights(model, adata, mode='highest', top_n=30)\n</code></pre>"},{"location":"api/plotting/#Concord.plotting.plot_importance_heatmap","title":"<code>Concord.plotting.plot_importance_heatmap(importance_matrix, input_feature=None, figsize=(20, 15), save_path=None)</code>","text":"<p>Plots a heatmap of feature importance across encoded neurons.</p> <p>This function visualizes the importance of each input feature for different encoded neurons using hierarchical clustering.</p> <p>Parameters:</p> Name Type Description Default <code>importance_matrix</code> <code>ndarray or Tensor</code> <p>The importance matrix with shape <code>(n_input_features, n_encoded_neurons)</code>.</p> required <code>input_feature</code> <code>list of str</code> <p>List of input feature names (e.g., gene names). If <code>None</code>, generic feature names are used.</p> <code>None</code> <code>figsize</code> <code>tuple</code> <p>Figure size <code>(width, height)</code>. Defaults to <code>(20, 15)</code>.</p> <code>(20, 15)</code> <code>save_path</code> <code>str</code> <p>If provided, saves the heatmap at the specified path. Defaults to <code>None</code>.</p> <code>None</code> <p>Returns:</p> Type Description <p>None Displays or saves the importance heatmap.</p> Example <pre><code>plot_importance_heatmap(importance_matrix, input_feature=adata.var_names)\n</code></pre>"},{"location":"api/plotting/#Concord.plotting.plot_top_genes_per_neuron","title":"<code>Concord.plotting.plot_top_genes_per_neuron(ranked_gene_lists, show_neurons=None, top_n=10, ncols=4, figsize=(4, 4), save_path=None)</code>","text":"<p>Plots bar charts of the top contributing genes for each neuron.</p> <p>This function generates bar plots showing the most important genes contributing to each encoded neuron in a compact grid layout.</p> <p>Parameters:</p> Name Type Description Default <code>ranked_gene_lists</code> <code>dict</code> <p>Dictionary where keys are neuron names and values are DataFrames containing ranked genes.</p> required <code>show_neurons</code> <code>list</code> <p>List of neurons to plot. If <code>None</code>, plots all neurons available in <code>ranked_gene_lists</code>. Defaults to <code>None</code>.</p> <code>None</code> <code>top_n</code> <code>int</code> <p>Number of top contributing genes to display for each neuron. Defaults to <code>10</code>.</p> <code>10</code> <code>ncols</code> <code>int</code> <p>Number of columns in the subplot grid. Defaults to <code>4</code>.</p> <code>4</code> <code>figsize</code> <code>tuple</code> <p>Size of each subplot <code>(width, height)</code>. Defaults to <code>(4, 4)</code>.</p> <code>(4, 4)</code> <code>save_path</code> <code>str</code> <p>If provided, saves the plot at the specified path. Defaults to <code>None</code>.</p> <code>None</code> <p>Returns:</p> Type Description <p>None Displays or saves the bar charts.</p> Example <pre><code>plot_top_genes_per_neuron(ranked_gene_lists, top_n=15, ncols=3, save_path=\"top_genes.png\")\n</code></pre>"},{"location":"api/plotting/#Concord.plotting.get_color_mapping","title":"<code>Concord.plotting.get_color_mapping(adata, col, pal, seed=42)</code>","text":"<p>Generates a color mapping for a given column in <code>adata.obs</code> or for gene expression.</p> <p>This function determines whether the column is numeric or categorical and assigns an appropriate colormap (for numeric data) or a categorical color palette.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>An AnnData object containing single-cell expression data.</p> required <code>col</code> <code>str</code> <p>The column in <code>adata.obs</code> or a gene name in <code>adata.var_names</code> to be used for coloring.</p> required <code>pal</code> <code>dict, str, or None</code> <p>Color palette or colormap for categorical or numeric data. - If <code>dict</code>, it should map categories to colors. - If <code>str</code>, it should be a recognized seaborn or matplotlib palette/colormap. - If <code>None</code>, defaults to 'Set1' for categorical data and 'viridis' for numeric data.</p> required <code>seed</code> <code>int</code> <p>Random seed for reproducibility when shuffling colors in categorical mapping. Defaults to <code>42</code>.</p> <code>42</code> <p>Returns:</p> Name Type Description <code>tuple</code> <p><code>(data_col, cmap, palette)</code> - <code>data_col</code> (pd.Series or np.ndarray): The extracted column data from <code>adata.obs</code> or <code>adata[:, col].X</code>. - <code>cmap</code> (matplotlib.colors.Colormap or None): A colormap for numeric data. Returns <code>None</code> for categorical data. - <code>palette</code> (dict or None): A dictionary mapping categorical values to colors. Returns <code>None</code> for numeric data.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the column is neither found in <code>adata.obs</code> nor in <code>adata.var_names</code>.</p> <code>ValueError</code> <p>If a numeric column is provided with a categorical palette (dict).</p> Example <pre><code>data_col, cmap, palette = get_color_mapping(adata, 'batch', pal='Set2')\n</code></pre> <pre><code>data_col, cmap, palette = get_color_mapping(adata, 'GeneX', pal='RdYlBu')\n</code></pre>"},{"location":"api/plotting/#Concord.plotting.plot_go_enrichment","title":"<code>Concord.plotting.plot_go_enrichment(gp_results, top_n=10, qval_correct=1e-10, color_palette='viridis_r', font_size=12, figsize=(7, 3), dpi=300, save_path=None)</code>","text":"<p>Plots the top Gene Ontology (GO) enrichment terms based on adjusted p-values (FDR q-values).</p> <p>Parameters:</p> Name Type Description Default <code>gp_results</code> <code>object</code> <p>GO enrichment results object containing a DataFrame in <code>gp_results.results</code>.</p> required <code>top_n</code> <code>int</code> <p>Number of top terms to display. Defaults to <code>10</code>.</p> <code>10</code> <code>qval_correct</code> <code>float</code> <p>A small correction factor added to q-values before taking <code>-log10</code>. Defaults to <code>1e-10</code>.</p> <code>1e-10</code> <code>color_palette</code> <code>str</code> <p>Color palette for the bar plot. Defaults to <code>'viridis_r'</code>.</p> <code>'viridis_r'</code> <code>font_size</code> <code>int</code> <p>Font size for plot labels. Defaults to <code>12</code>.</p> <code>12</code> <code>figsize</code> <code>tuple</code> <p>Size of the figure in inches (width, height). Defaults to <code>(7,3)</code>.</p> <code>(7, 3)</code> <code>dpi</code> <code>int</code> <p>Dots per inch (resolution) for saving the figure. Defaults to <code>300</code>.</p> <code>300</code> <code>save_path</code> <code>str</code> <p>File path to save the figure. If <code>None</code>, the figure is displayed instead of being saved. Defaults to <code>None</code>.</p> <code>None</code> <p>Returns:</p> Type Description <p>None</p> Example <pre><code>plot_go_enrichment(gp_results, top_n=15, save_path=\"go_enrichment.png\")\n</code></pre>"},{"location":"api/plotting/#Concord.plotting.plot_all_top_enriched_terms","title":"<code>Concord.plotting.plot_all_top_enriched_terms(all_gsea_results, top_n=10, ncols=1, font_size=10, color_palette='viridis_r', qval_correct=1e-10, figsize=(4, 4), dpi=300, save_path=None)</code>","text":"<p>Plots the top enriched Gene Set Enrichment Analysis (GSEA) terms for multiple neurons.</p> <p>Parameters:</p> Name Type Description Default <code>all_gsea_results</code> <code>dict</code> <p>Dictionary where keys are neuron names and values are GSEA results DataFrames.</p> required <code>top_n</code> <code>int</code> <p>Number of top enriched terms to display per neuron. Defaults to <code>10</code>.</p> <code>10</code> <code>ncols</code> <code>int</code> <p>Number of columns in the subplot grid layout. Defaults to <code>1</code>.</p> <code>1</code> <code>font_size</code> <code>int</code> <p>Font size for plot labels. Defaults to <code>10</code>.</p> <code>10</code> <code>color_palette</code> <code>str</code> <p>Color palette for the bar plots. Defaults to <code>'viridis_r'</code>.</p> <code>'viridis_r'</code> <code>qval_correct</code> <code>float</code> <p>A small correction factor added to q-values before taking <code>-log10</code>. Defaults to <code>1e-10</code>.</p> <code>1e-10</code> <code>figsize</code> <code>tuple</code> <p>Size of each subplot (width, height) in inches. Defaults to <code>(4,4)</code>.</p> <code>(4, 4)</code> <code>dpi</code> <code>int</code> <p>Resolution of the output figure. Defaults to <code>300</code>.</p> <code>300</code> <code>save_path</code> <code>str</code> <p>File path to save the figure. If <code>None</code>, the figure is displayed. Defaults to <code>None</code>.</p> <code>None</code> <p>Returns:</p> Type Description <p>None</p> Example <pre><code>plot_all_top_enriched_terms(all_gsea_results, top_n=5, ncols=2, save_path=\"gsea_terms.pdf\")\n</code></pre>"},{"location":"api/plotting/#Concord.plotting.plot_all_top_gsea_results","title":"<code>Concord.plotting.plot_all_top_gsea_results(all_gsea_results, terms_per_plot=5, ncols=4, figsize_per_plot=(3, 4), dpi=300, save_path=None)</code>","text":"<p>Plots Gene Set Enrichment Analysis (GSEA) results for multiple neurons in a grid layout.</p> <p>Parameters:</p> Name Type Description Default <code>all_gsea_results</code> <code>dict</code> <p>Dictionary where keys are neuron names and values are GSEA result objects.</p> required <code>terms_per_plot</code> <code>int</code> <p>Number of top enriched terms to display per neuron. Defaults to <code>5</code>.</p> <code>5</code> <code>ncols</code> <code>int</code> <p>Number of columns in the subplot grid. Defaults to <code>4</code>.</p> <code>4</code> <code>figsize_per_plot</code> <code>tuple</code> <p>Size of each subplot (width, height) in inches. Defaults to <code>(3,4)</code>.</p> <code>(3, 4)</code> <code>dpi</code> <code>int</code> <p>Resolution of the output figure in dots per inch. Defaults to <code>300</code>.</p> <code>300</code> <code>save_path</code> <code>str</code> <p>File path to save the figure. If <code>None</code>, the figure is displayed. Defaults to <code>None</code>.</p> <code>None</code> <p>Returns:</p> Type Description <p>None</p> Example <pre><code>plot_all_top_gsea_results(all_gsea_results, terms_per_plot=7, ncols=3, save_path=\"gsea_results.png\")\n</code></pre>"},{"location":"api/plotting/#Concord.plotting.plot_trustworthiness","title":"<code>Concord.plotting.plot_trustworthiness(trustworthiness_df, text_label=True, text_shift=1, legend=False, fontsize=8, legend_fontsize=8, figsize=(6, 4), dpi=300, save_path=None)</code>","text":"<p>Plots trustworthiness scores for different latent embeddings over a range of neighborhood sizes.</p> <p>Parameters:</p> Name Type Description Default <code>trustworthiness_df</code> <code>DataFrame</code> <p>DataFrame containing columns <code>Embedding</code>, <code>n_neighbors</code>, and <code>Trustworthiness</code>.</p> required <code>text_label</code> <code>bool</code> <p>Whether to display text labels for the last data point of each embedding. Defaults to <code>True</code>.</p> <code>True</code> <code>text_shift</code> <code>float</code> <p>Horizontal shift applied to text labels for readability. Defaults to <code>1</code>.</p> <code>1</code> <code>legend</code> <code>bool</code> <p>Whether to show a legend on the right. Defaults to <code>False</code>.</p> <code>False</code> <code>fontsize</code> <code>int</code> <p>Font size for plot labels. Defaults to <code>8</code>.</p> <code>8</code> <code>legend_fontsize</code> <code>int</code> <p>Font size for legend text. Defaults to <code>8</code>.</p> <code>8</code> <code>figsize</code> <code>tuple</code> <p>Figure size in inches (width, height). Defaults to <code>(6, 4)</code>.</p> <code>(6, 4)</code> <code>dpi</code> <code>int</code> <p>Resolution (dots per inch) for saving the figure. Defaults to <code>300</code>.</p> <code>300</code> <code>save_path</code> <code>str</code> <p>File path to save the figure. If <code>None</code>, the plot is displayed instead. Defaults to <code>None</code>.</p> <code>None</code> <p>Returns:</p> Type Description <p>None</p> Example <pre><code>plot_trustworthiness(trustworthiness_df, legend=True, save_path=\"trustworthiness_plot.png\")\n</code></pre>"},{"location":"api/plotting/#Concord.plotting.plot_distance_heatmap","title":"<code>Concord.plotting.plot_distance_heatmap(distances, n_cols=3, annot_value=False, figsize=(2, 1.6), cbar=True, fontsize=10, rasterize=True, dpi=300, save_path=None)</code>","text":"<p>Plots heatmaps of pairwise distance matrices in a grid layout.</p> <p>Parameters:</p> Name Type Description Default <code>distances</code> <code>dict</code> <p>Dictionary where keys are distance metric names and values are distance matrices.</p> required <code>n_cols</code> <code>int</code> <p>Number of columns in the subplot grid. Defaults to <code>3</code>.</p> <code>3</code> <code>annot_value</code> <code>bool</code> <p>Whether to annotate heatmap values. Defaults to <code>False</code>.</p> <code>False</code> <code>figsize</code> <code>tuple</code> <p>Base figure size for each subplot (width, height). Defaults to <code>(2, 1.6)</code>.</p> <code>(2, 1.6)</code> <code>cbar</code> <code>bool</code> <p>Whether to display a color bar. Defaults to <code>True</code>.</p> <code>True</code> <code>fontsize</code> <code>int</code> <p>Font size for axis labels and titles. Defaults to <code>10</code>.</p> <code>10</code> <code>rasterize</code> <code>bool</code> <p>Whether to rasterize the heatmap for better performance. Defaults to <code>True</code>.</p> <code>True</code> <code>dpi</code> <code>int</code> <p>Resolution (dots per inch) for saving the figure. Defaults to <code>300</code>.</p> <code>300</code> <code>save_path</code> <code>str</code> <p>File path to save the figure. If <code>None</code>, the plot is displayed instead. Defaults to <code>None</code>.</p> <code>None</code> <p>Returns:</p> Type Description <p>None</p> Example <pre><code>plot_distance_heatmap(distances, n_cols=4, save_path=\"distance_heatmaps.png\")\n</code></pre>"},{"location":"api/plotting/#Concord.plotting.plot_geometry_scatter","title":"<code>Concord.plotting.plot_geometry_scatter(data_dict, correlation=None, ground_key='PCA_no_noise', linear_fit=False, s=1, c=None, alpha=0.5, n_cols=3, fontsize=8, figsize=(4, 4), rasterized=True, dpi=300, save_path=None)</code>","text":"<p>Plots scatter plots comparing geometric properties of embeddings.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Dictionary where keys are embedding names and values are distance vectors.</p> required <code>correlation</code> <code>DataFrame</code> <p>DataFrame containing correlation values for each embedding. Defaults to <code>None</code>.</p> <code>None</code> <code>ground_key</code> <code>str</code> <p>Key used as the reference ground-truth embedding. Defaults to <code>'PCA_no_noise'</code>.</p> <code>'PCA_no_noise'</code> <code>linear_fit</code> <code>bool</code> <p>Whether to fit and plot a linear regression line. Defaults to <code>False</code>.</p> <code>False</code> <code>s</code> <code>float</code> <p>Marker size in scatter plots. Defaults to <code>1</code>.</p> <code>1</code> <code>c</code> <code>str or array - like</code> <p>Color of points. Defaults to <code>None</code>.</p> <code>None</code> <code>alpha</code> <code>float</code> <p>Opacity of points. Defaults to <code>0.5</code>.</p> <code>0.5</code> <code>n_cols</code> <code>int</code> <p>Number of columns in the subplot grid. Defaults to <code>3</code>.</p> <code>3</code> <code>fontsize</code> <code>int</code> <p>Font size for axis labels and titles. Defaults to <code>8</code>.</p> <code>8</code> <code>figsize</code> <code>tuple</code> <p>Base figure size for each subplot (width, height). Defaults to <code>(4, 4)</code>.</p> <code>(4, 4)</code> <code>rasterized</code> <code>bool</code> <p>Whether to rasterize scatter points for performance. Defaults to <code>True</code>.</p> <code>True</code> <code>dpi</code> <code>int</code> <p>Resolution (dots per inch) for saving the figure. Defaults to <code>300</code>.</p> <code>300</code> <code>save_path</code> <code>str</code> <p>File path to save the figure. If <code>None</code>, the plot is displayed instead. Defaults to <code>None</code>.</p> <code>None</code> <p>Returns:</p> Type Description <p>None</p> Example <pre><code>plot_geometry_scatter(data_dict, correlation=correlation_df, save_path=\"geometry_scatter.png\")\n</code></pre>"},{"location":"api/plotting/#Concord.plotting.plot_persistence_diagram","title":"<code>Concord.plotting.plot_persistence_diagram(diagram, homology_dimensions=None, ax=None, show=True, legend=True, legend_loc='lower right', label_axes=True, colormap='tab10', marker_size=20, diagonal=True, title=None, fontsize=12, axis_ticks=True, xlim=None, ylim=None, rasterized=True)</code>","text":"<p>Plots a persistence diagram showing birth and death times of topological features.</p> <p>Parameters:</p> Name Type Description Default <code>diagram</code> <code>array - like</code> <p>Persistence diagram data (birth, death, homology dimension).</p> required <code>homology_dimensions</code> <code>list</code> <p>Homology dimensions to plot (e.g., [0, 1, 2]). Defaults to all available.</p> <code>None</code> <code>ax</code> <code>Axes</code> <p>Matplotlib axis to plot on. If <code>None</code>, a new figure is created.</p> <code>None</code> <code>show</code> <code>bool</code> <p>Whether to display the plot. Defaults to <code>True</code>.</p> <code>True</code> <code>legend</code> <code>bool</code> <p>Whether to show a legend. Defaults to <code>True</code>.</p> <code>True</code> <code>legend_loc</code> <code>str</code> <p>Location of the legend. Defaults to <code>'lower right'</code>.</p> <code>'lower right'</code> <code>label_axes</code> <code>bool</code> <p>Whether to label the x- and y-axes. Defaults to <code>True</code>.</p> <code>True</code> <code>colormap</code> <code>str</code> <p>Colormap for different homology dimensions. Defaults to <code>'tab10'</code>.</p> <code>'tab10'</code> <code>marker_size</code> <code>int</code> <p>Size of markers for points. Defaults to <code>20</code>.</p> <code>20</code> <code>diagonal</code> <code>bool</code> <p>Whether to plot the diagonal y = x reference line. Defaults to <code>True</code>.</p> <code>True</code> <code>title</code> <code>str</code> <p>Title of the plot. Defaults to <code>None</code>.</p> <code>None</code> <code>fontsize</code> <code>int</code> <p>Font size for labels and title. Defaults to <code>12</code>.</p> <code>12</code> <code>axis_ticks</code> <code>bool</code> <p>Whether to display axis ticks. Defaults to <code>True</code>.</p> <code>True</code> <code>xlim</code> <code>tuple</code> <p>Limits for the x-axis. Defaults to <code>None</code>.</p> <code>None</code> <code>ylim</code> <code>tuple</code> <p>Limits for the y-axis. Defaults to <code>None</code>.</p> <code>None</code> <code>rasterized</code> <code>bool</code> <p>Whether to rasterize the plot for performance. Defaults to <code>True</code>.</p> <code>True</code> <p>Returns:</p> Type Description <p>matplotlib.axes.Axes: The axis object containing the persistence diagram.</p> Example <pre><code>plot_persistence_diagram(diagram, homology_dimensions=[0, 1])\n</code></pre>"},{"location":"api/plotting/#Concord.plotting.plot_persistence_diagrams","title":"<code>Concord.plotting.plot_persistence_diagrams(diagrams, marker_size=4, n_cols=3, dpi=300, base_size=(3, 3), legend=True, legend_loc=None, rasterized=True, fontsize=12, save_path=None, **kwargs)</code>","text":"<p>Plots multiple persistence diagrams in a grid layout.</p> <p>Parameters:</p> Name Type Description Default <code>diagrams</code> <code>dict</code> <p>Dictionary where keys are dataset names and values are persistence diagrams.</p> required <code>marker_size</code> <code>int</code> <p>Size of markers for points. Defaults to <code>4</code>.</p> <code>4</code> <code>n_cols</code> <code>int</code> <p>Number of columns in the grid. Defaults to <code>3</code>.</p> <code>3</code> <code>dpi</code> <code>int</code> <p>Resolution of the figure. Defaults to <code>300</code>.</p> <code>300</code> <code>base_size</code> <code>tuple</code> <p>Base figure size for each subplot <code>(width, height)</code>. Defaults to <code>(3, 3)</code>.</p> <code>(3, 3)</code> <code>legend</code> <code>bool</code> <p>Whether to include legends. Defaults to <code>True</code>.</p> <code>True</code> <code>legend_loc</code> <code>str</code> <p>Location of the legend. Defaults to <code>None</code>.</p> <code>None</code> <code>rasterized</code> <code>bool</code> <p>Whether to rasterize the plots. Defaults to <code>True</code>.</p> <code>True</code> <code>fontsize</code> <code>int</code> <p>Font size for labels and titles. Defaults to <code>12</code>.</p> <code>12</code> <code>save_path</code> <code>str</code> <p>File path to save the figure. Defaults to <code>None</code>.</p> <code>None</code> <p>Returns:</p> Type Description <p>None</p> Example <pre><code>plot_persistence_diagrams(diagrams, n_cols=2, save_path=\"persistence_diagrams.png\")\n</code></pre>"},{"location":"api/plotting/#Concord.plotting.plot_betti_curve","title":"<code>Concord.plotting.plot_betti_curve(diagram, nbins=100, homology_dimensions=[0, 1, 2], title='Betti curves', ymax=10, ax=None, show=True, legend=True, legend_loc='upper right', label_axes=True, axis_ticks=True, fontsize=12)</code>","text":"<p>Plots Betti curves, which track the number of topological features over filtration values.</p> <p>Parameters:</p> Name Type Description Default <code>diagram</code> <code>array - like</code> <p>Persistence diagram data used to compute Betti curves.</p> required <code>nbins</code> <code>int</code> <p>Number of bins for filtration values. Defaults to <code>100</code>.</p> <code>100</code> <code>homology_dimensions</code> <code>list</code> <p>List of homology dimensions to plot. Defaults to <code>[0, 1, 2]</code>.</p> <code>[0, 1, 2]</code> <code>title</code> <code>str</code> <p>Title of the plot. Defaults to <code>\"Betti curves\"</code>.</p> <code>'Betti curves'</code> <code>ymax</code> <code>int</code> <p>Maximum y-axis value. Defaults to <code>10</code>.</p> <code>10</code> <code>ax</code> <code>Axes</code> <p>Axis object for plotting. If <code>None</code>, a new figure is created.</p> <code>None</code> <code>show</code> <code>bool</code> <p>Whether to display the plot. Defaults to <code>True</code>.</p> <code>True</code> <code>legend</code> <code>bool</code> <p>Whether to include a legend. Defaults to <code>True</code>.</p> <code>True</code> <code>legend_loc</code> <code>str</code> <p>Location of the legend. Defaults to <code>'upper right'</code>.</p> <code>'upper right'</code> <code>label_axes</code> <code>bool</code> <p>Whether to label the axes. Defaults to <code>True</code>.</p> <code>True</code> <code>axis_ticks</code> <code>bool</code> <p>Whether to include axis ticks. Defaults to <code>True</code>.</p> <code>True</code> <code>fontsize</code> <code>int</code> <p>Font size for labels and title. Defaults to <code>12</code>.</p> <code>12</code> <p>Returns:</p> Type Description <p>matplotlib.axes.Axes: The axis object containing the Betti curve.</p> Example <pre><code>plot_betti_curve(diagram, nbins=50, homology_dimensions=[0,1])\n</code></pre>"},{"location":"api/plotting/#Concord.plotting.plot_betti_curves","title":"<code>Concord.plotting.plot_betti_curves(diagrams, nbins=100, ymax=8, n_cols=3, base_size=(3, 3), dpi=300, legend=True, save_path=None, **kwargs)</code>","text":"<p>Plots Betti curves for multiple persistence diagrams in a grid layout.</p>"},{"location":"api/plotting/#Concord.plotting.plot_betti_curves--parameters","title":"Parameters","text":"<p>diagrams : dict     A dictionary where keys are diagram names and values are persistence diagrams. nbins : int, optional     Number of bins to use for Betti curve computation, by default 100. ymax : int, optional     Maximum y-axis limit for the Betti curves, by default 8. n_cols : int, optional     Number of columns in the grid layout, by default 3. base_size : tuple, optional     Base figure size (width, height) for each subplot, by default (3,3). dpi : int, optional     Dots per inch for figure resolution, by default 300. legend : bool, optional     Whether to include a legend in each plot, by default True. save_path : str, optional     File path to save the plot. If None, the plot is displayed instead. **kwargs : dict     Additional keyword arguments passed to <code>plot_betti_curve</code>.</p>"},{"location":"api/plotting/#Concord.plotting.plot_betti_curves--returns","title":"Returns","text":"<p>None     Displays or saves the plotted figure.</p>"},{"location":"api/plotting/#Concord.plotting.plot_betti_curves--notes","title":"Notes","text":"<p>Each subplot corresponds to a Betti curve computed from a persistence diagram.</p>"},{"location":"api/plotting/#Concord.plotting.plot_betti_statistic","title":"<code>Concord.plotting.plot_betti_statistic(betti_stats_pivot, statistic='Entropy', dimension=None, log_y=False, bar_width=0.2, pal='tab20', figsize=(7, 4), dpi=300, save_path=None, xlabel_fontsize=8, ylabel_fontsize=8, tick_fontsize=7, title_fontsize=9, legend_fontsize=8)</code>","text":"<p>Plots a grouped bar chart of Betti number statistics across different methods.</p> <p>Parameters:</p> Name Type Description Default <code>betti_stats_pivot</code> <code>DataFrame</code> <p>DataFrame containing Betti number statistics.</p> required <code>statistic</code> <code>str</code> <p>Statistic to plot (e.g., 'Entropy', 'Variance'). Defaults to <code>'Entropy'</code>.</p> <code>'Entropy'</code> <code>dimension</code> <code>str or int</code> <p>Specific homology dimension to plot. Defaults to <code>None</code> (plots all).</p> <code>None</code> <code>log_y</code> <code>bool</code> <p>Whether to use a logarithmic scale on the y-axis. Defaults to <code>False</code>.</p> <code>False</code> <code>bar_width</code> <code>float</code> <p>Width of bars in the grouped bar chart. Defaults to <code>0.2</code>.</p> <code>0.2</code> <code>pal</code> <code>str</code> <p>Color palette. Defaults to <code>'tab20'</code>.</p> <code>'tab20'</code> <code>figsize</code> <code>tuple</code> <p>Figure size in inches. Defaults to <code>(7, 4)</code>.</p> <code>(7, 4)</code> <code>dpi</code> <code>int</code> <p>Resolution in dots per inch. Defaults to <code>300</code>.</p> <code>300</code> <code>save_path</code> <code>str</code> <p>Path to save the figure. Defaults to <code>None</code>.</p> <code>None</code> <p>Returns:</p> Type Description <p>None</p> Example <pre><code>plot_betti_statistic(betti_stats_df, statistic='Entropy', save_path=\"betti_statistic.png\")\n</code></pre>"},{"location":"api/plotting/#Concord.plotting.plot_betti_distance","title":"<code>Concord.plotting.plot_betti_distance(distance_metrics_df, metric, color='teal', log_y=False, figsize=(6, 4), dpi=300, save_path=None)</code>","text":"<p>Plots distance metrics for Betti numbers across different methods.</p> <p>Parameters:</p> Name Type Description Default <code>distance_metrics_df</code> <code>DataFrame</code> <p>DataFrame containing distance metrics.</p> required <code>metric</code> <code>str</code> <p>Metric to plot (<code>'L1 Distance'</code>, <code>'L2 Distance'</code>, <code>'Total Relative Error'</code>).</p> required <code>color</code> <code>str</code> <p>Color of the bars in the plot. Defaults to <code>'teal'</code>.</p> <code>'teal'</code> <code>log_y</code> <code>bool</code> <p>Whether to use a logarithmic scale on the y-axis. Defaults to <code>False</code>.</p> <code>False</code> <code>figsize</code> <code>tuple</code> <p>Figure size in inches. Defaults to <code>(6, 4)</code>.</p> <code>(6, 4)</code> <code>dpi</code> <code>int</code> <p>Resolution in dots per inch. Defaults to <code>300</code>.</p> <code>300</code> <code>save_path</code> <code>str</code> <p>File path to save the plot. Defaults to <code>None</code>.</p> <code>None</code> <p>Returns:</p> Type Description <p>None</p> Example <pre><code>plot_betti_distance(distance_metrics_df, metric=\"L1 Distance\")\n</code></pre>"},{"location":"api/utils/","title":"Utilities","text":"<p><code>utils</code> can be replaced by <code>ul</code>, e.g., <code>Concord.utils.list_adata_files</code> can be <code>Concord.ul.list_adata_files</code></p>"},{"location":"api/utils/#Concord.utils.benchmark_topology","title":"<code>Concord.utils.benchmark_topology(diagrams, expected_betti_numbers=[1, 0, 0], n_bins=100, save_dir=None, file_suffix=None)</code>","text":"<p>Benchmark the topological properties of persistence diagrams.</p> <p>Parameters:</p> Name Type Description Default <code>diagrams</code> <p>dict A dictionary where keys are method names and values are persistence diagrams.</p> required <code>expected_betti_numbers</code> <p>list, optional A list specifying the expected Betti numbers for different homology dimensions. Default is [1, 0, 0].</p> <code>[1, 0, 0]</code> <code>n_bins</code> <p>int, optional Number of bins to use for Betti curve calculations. Default is 100.</p> <code>100</code> <code>save_dir</code> <p>str, optional Directory to save benchmarking results as CSV files. If None, results are not saved.</p> <code>None</code> <code>file_suffix</code> <p>str, optional Suffix to append to saved filenames.</p> <code>None</code> <p>Returns:</p> Type Description <p>dict A dictionary containing: - <code>'betti_stats'</code>: DataFrame summarizing Betti statistics. - <code>'distance_metrics'</code>: DataFrame of computed distances between Betti curves. - <code>'combined_metrics'</code>: DataFrame of entropy, variance, and L1 distance metrics.</p>"},{"location":"api/utils/#Concord.utils.compute_persistent_homology","title":"<code>Concord.utils.compute_persistent_homology(adata, key='X_pca', homology_dimensions=[0, 1, 2])</code>","text":"<p>Computes persistent homology using Vietoris-Rips complex.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <p>anndata.AnnData The AnnData object containing the data.</p> required <code>key</code> <p>str, optional The key in <code>adata.obsm</code> specifying the embedding to use. Default is 'X_pca'.</p> <code>'X_pca'</code> <code>homology_dimensions</code> <p>list, optional List of homology dimensions to compute. Default is [0, 1, 2].</p> <code>[0, 1, 2]</code> <p>Returns:</p> Type Description <p>np.ndarray Persistence diagrams representing homology classes across filtration values.</p>"},{"location":"api/utils/#Concord.utils.compute_betti_median_or_mode","title":"<code>Concord.utils.compute_betti_median_or_mode(betti_values, statistic='median')</code>","text":"<p>Computes the median or mode of Betti numbers.</p> <p>Parameters:</p> Name Type Description Default <code>betti_values</code> <p>np.ndarray Array of Betti numbers across filtration values.</p> required <code>statistic</code> <p>str, optional Statistic to compute ('median' or 'mode'). Default is 'median'.</p> <code>'median'</code> <p>Returns:</p> Type Description <p>float The computed median or mode of the Betti numbers.</p>"},{"location":"api/utils/#Concord.utils.compute_betti_entropy","title":"<code>Concord.utils.compute_betti_entropy(betti_values)</code>","text":"<p>Computes the entropy of the Betti curve.</p> <p>Parameters:</p> Name Type Description Default <code>betti_values</code> <p>np.ndarray Array of Betti numbers across filtration values.</p> required <p>Returns:</p> Type Description <p>float The entropy of the Betti curve.</p>"},{"location":"api/utils/#Concord.utils.interpolate_betti_curve","title":"<code>Concord.utils.interpolate_betti_curve(betti_values, original_sampling, common_sampling)</code>","text":"<p>Interpolates Betti curve onto a common filtration grid.</p> <p>Parameters:</p> Name Type Description Default <code>betti_values</code> <p>np.ndarray Array of Betti numbers.</p> required <code>original_sampling</code> <p>np.ndarray The original filtration values associated with the Betti numbers.</p> required <code>common_sampling</code> <p>np.ndarray The target filtration values for interpolation.</p> required <p>Returns:</p> Type Description <p>np.ndarray Interpolated Betti curve.</p>"},{"location":"api/utils/#Concord.utils.compute_betti_statistics","title":"<code>Concord.utils.compute_betti_statistics(diagram, expected_betti_numbers, n_bins=100)</code>","text":"<p>Computes Betti statistics given a persistence diagram.</p> <p>Parameters:</p> Name Type Description Default <code>diagram</code> <p>np.ndarray Persistence diagram from Giotto-TDA.</p> required <code>expected_betti_numbers</code> <p>np.ndarray Expected Betti numbers for different homology dimensions.</p> required <code>n_bins</code> <p>int, optional Number of bins for the Betti curve computation. Default is 100.</p> <code>100</code> <p>Returns:</p> Type Description <p>dict A dictionary containing: - <code>'betti_stats'</code>: Dictionary of Betti statistics. - <code>'observed_betti_numbers'</code>: Observed Betti numbers. - <code>'expected_betti_numbers'</code>: Expected Betti numbers. - <code>'l1_distance'</code>: L1 distance between observed and expected Betti numbers. - <code>'l2_distance'</code>: L2 distance between observed and expected Betti numbers. - <code>'total_relative_error'</code>: Total relative error.</p>"},{"location":"api/utils/#Concord.utils.summarize_betti_statistics","title":"<code>Concord.utils.summarize_betti_statistics(betti_stats)</code>","text":"<p>Summarizes Betti statistics into pandas DataFrames.</p> <p>Parameters:</p> Name Type Description Default <code>betti_stats</code> <p>dict Dictionary containing Betti statistics for different methods.</p> required <p>Returns:</p> Type Description <p>tuple - <code>betti_stats_pivot</code>: DataFrame of Betti statistics. - <code>distance_metrics_df</code>: DataFrame of distance metrics.</p>"},{"location":"api/utils/#Concord.utils.benchmark_geometry","title":"<code>Concord.utils.benchmark_geometry(adata, keys, eval_metrics=['pseudotime', 'cell_distance_corr', 'local_distal_corr', 'trustworthiness', 'state_distance_corr', 'state_dispersion_corr', 'state_batch_distance_ratio'], dist_metric='cosine', groundtruth_key='PCA_no_noise', state_key='cluster', batch_key='batch', groundtruth_dispersion=None, ground_truth_dispersion_key='wt_noise', corr_types=['pearsonr', 'spearmanr', 'kendalltau'], trustworthiness_n_neighbors=np.arange(10, 101, 10), dispersion_metric='var', return_type='dataframe', local_percentile=0.1, distal_percentile=0.9, start_point=0, end_point=None, pseudotime_k=30, truetime_key='time', verbose=True, save_dir=None, file_suffix=None)</code>","text":"<p>Benchmark the geometric properties of different embeddings.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <p>anndata.AnnData The AnnData object containing cell embeddings.</p> required <code>keys</code> <p>list List of embeddings (keys in <code>adata.obsm</code>) to evaluate.</p> required <code>eval_metrics</code> <p>list, optional Metrics to compute, such as 'pseudotime', 'cell_distance_corr', etc. Default includes multiple metrics.</p> <code>['pseudotime', 'cell_distance_corr', 'local_distal_corr', 'trustworthiness', 'state_distance_corr', 'state_dispersion_corr', 'state_batch_distance_ratio']</code> <code>dist_metric</code> <p>str, optional Distance metric for computing cell distances. Default is 'cosine'.</p> <code>'cosine'</code> <code>groundtruth_key</code> <p>str, optional Key in <code>adata.obsm</code> containing the ground truth embedding. Default is 'PCA_no_noise'.</p> <code>'PCA_no_noise'</code> <code>state_key</code> <p>str, optional Key in <code>adata.obs</code> representing cell states or clusters.</p> <code>'cluster'</code> <code>batch_key</code> <p>str, optional Key in <code>adata.obs</code> representing batch information.</p> <code>'batch'</code> <code>groundtruth_dispersion</code> <p>dict, optional Precomputed dispersion values for ground truth, if available.</p> <code>None</code> <code>ground_truth_dispersion_key</code> <p>str, optional Key used when computing dispersion correlations. Default is 'wt_noise'.</p> <code>'wt_noise'</code> <code>corr_types</code> <p>list, optional List of correlation methods to compute. Default includes 'pearsonr', 'spearmanr', and 'kendalltau'.</p> <code>['pearsonr', 'spearmanr', 'kendalltau']</code> <code>trustworthiness_n_neighbors</code> <p>np.ndarray, optional Range of neighborhood sizes for trustworthiness computation. Default is <code>np.arange(10, 101, 10)</code>.</p> <code>arange(10, 101, 10)</code> <code>dispersion_metric</code> <p>str, optional Metric to compute dispersion, e.g., 'var' (variance). Default is 'var'.</p> <code>'var'</code> <code>return_type</code> <p>str, optional If 'dataframe', returns summary statistics; if 'full', returns additional details. Default is 'dataframe'.</p> <code>'dataframe'</code> <code>local_percentile</code> <p>float, optional Percentile threshold for local distance correlations. Default is 0.1.</p> <code>0.1</code> <code>distal_percentile</code> <p>float, optional Percentile threshold for distal distance correlations. Default is 0.9.</p> <code>0.9</code> <code>start_point</code> <p>int, optional Index of the starting cell for pseudotime computation. Must be specified.</p> <code>0</code> <code>end_point</code> <p>int, optional Index of the ending cell for pseudotime computation. Must be specified.</p> <code>None</code> <code>pseudotime_k</code> <p>int, optional Number of neighbors used in k-NN graph for pseudotime computation. Default is 30.</p> <code>30</code> <code>truetime_key</code> <p>str, optional Key in <code>adata.obs</code> representing ground truth time. Default is 'time'.</p> <code>'time'</code> <code>verbose</code> <p>bool, optional Whether to enable logging. Default is True.</p> <code>True</code> <code>save_dir</code> <p>str, optional Directory to save benchmarking results. If None, results are not saved.</p> <code>None</code> <code>file_suffix</code> <p>str, optional Suffix for saved filenames.</p> <code>None</code> <p>Returns:</p> Type Description <p>pd.DataFrame or tuple If <code>return_type='dataframe'</code>, returns a DataFrame summarizing benchmark results. If <code>return_type='full'</code>, returns both the DataFrame and a detailed results dictionary.</p>"},{"location":"api/utils/#Concord.utils.pairwise_distance","title":"<code>Concord.utils.pairwise_distance(adata, keys, metric='cosine')</code>","text":""},{"location":"api/utils/#Concord.utils.local_vs_distal_corr","title":"<code>Concord.utils.local_vs_distal_corr(X_high, X_low, local_percentile=25, distal_percentile=75, method='pearsonr')</code>","text":"<p>Computes correlation between local and distal pairwise distances.</p> <p>Parameters:</p> Name Type Description Default <code>X_high</code> <code>ndarray</code> <p>High-dimensional data matrix.</p> required <code>X_low</code> <code>ndarray</code> <p>Low-dimensional embedding matrix.</p> required <code>local_percentile</code> <code>int</code> <p>Percentile threshold for local distances. Defaults to 25.</p> <code>25</code> <code>distal_percentile</code> <code>int</code> <p>Percentile threshold for distal distances. Defaults to 75.</p> <code>75</code> <code>method</code> <code>str</code> <p>Correlation method; 'pearsonr', 'spearmanr', or 'kendalltau'. Defaults to 'pearsonr'.</p> <code>'pearsonr'</code> <p>Returns:</p> Name Type Description <code>float</code> <p>Correlation for local distances.</p> <code>float</code> <p>Correlation for distal distances.</p>"},{"location":"api/utils/#Concord.utils.compute_state_batch_distance_ratio","title":"<code>Concord.utils.compute_state_batch_distance_ratio(adata, basis='X_latent', batch_key='batch', state_key='cluster', metric='cosine')</code>","text":"<p>Computes the Batch-to-State Distance Ratio using centroids to evaluate batch correction.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>AnnData object containing latent embeddings.</p> required <code>basis</code> <code>str</code> <p>Key for latent embeddings in adata.obsm. Defaults to 'X_latent'.</p> <code>'X_latent'</code> <code>batch_key</code> <code>str</code> <p>Key for batch labels in adata.obs. Defaults to 'batch'.</p> <code>'batch'</code> <code>state_key</code> <code>str</code> <p>Key for cell state labels in adata.obs. Defaults to 'cluster'.</p> <code>'cluster'</code> <code>metric</code> <code>str</code> <p>Distance metric to use, e.g., 'cosine' or 'euclidean'. Defaults to 'cosine'.</p> <code>'cosine'</code> <p>Returns:</p> Name Type Description <code>float</code> <p>Ratio of average batch distance to average state distance.</p>"},{"location":"api/utils/#Concord.utils.compute_trustworthiness","title":"<code>Concord.utils.compute_trustworthiness(adata, embedding_keys, groundtruth, metric='euclidean', n_neighbors=10)</code>","text":"<p>Evaluates trustworthiness of embeddings in an AnnData object.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>AnnData object containing embeddings in adata.obsm.</p> required <code>embedding_keys</code> <code>list</code> <p>List of keys in adata.obsm to evaluate (e.g., ['X_umap', 'X_tsne']).</p> required <code>groundtruth</code> <code>str or ndarray</code> <p>Key in adata.obsm or adata.layers for ground truth data, or a precomputed matrix.</p> required <code>metric</code> <code>str</code> <p>Distance metric for trustworthiness calculation, e.g., 'euclidean' or 'cosine'. Defaults to 'euclidean'.</p> <code>'euclidean'</code> <code>n_neighbors</code> <code>int or list</code> <p>Neighborhood sizes for trustworthiness evaluation. Defaults to 10.</p> <code>10</code> <p>Returns:</p> Type Description <p>pandas.DataFrame: Trustworthiness scores for each embedding at each neighborhood size.</p> <p>pandas.DataFrame: Summary statistics with average trustworthiness and decay rate.</p>"},{"location":"api/utils/#Concord.utils.Simulation","title":"<code>Concord.utils.Simulation</code>","text":"<p>A class for simulating single-cell gene expression data with various structures and batch effects.</p> <p>Parameters:</p> Name Type Description Default <code>n_cells</code> <code>int</code> <p>Number of cells to simulate. Defaults to 1000.</p> <code>1000</code> <code>n_genes</code> <code>int</code> <p>Number of genes to simulate. Defaults to 1000.</p> <code>1000</code> <code>n_batches</code> <code>int</code> <p>Number of batches to simulate. Defaults to 2.</p> <code>2</code> <code>n_states</code> <code>int</code> <p>Number of states (e.g., clusters, trajectories). Defaults to 3.</p> <code>3</code> <code>state_type</code> <code>str</code> <p>Type of state to simulate; options include 'cluster', 'trajectory', 'tree', etc. Defaults to 'cluster'.</p> <code>'cluster'</code> <code>batch_type</code> <code>str or list</code> <p>Type of batch effect; options include 'batch_specific_features', 'variance_inflation', etc. Defaults to 'batch_specific_features'.</p> <code>'batch_specific_features'</code> <code>state_distribution</code> <code>str</code> <p>Distribution type for states; e.g., 'normal', 'poisson'. Defaults to 'normal'.</p> <code>'normal'</code> <code>state_level</code> <code>float</code> <p>Mean expression level for states. Defaults to 1.0.</p> <code>1.0</code> <code>state_min_level</code> <code>float</code> <p>Minimum expression level. Defaults to 0.0.</p> <code>0.0</code> <code>state_dispersion</code> <code>float</code> <p>Dispersion of state expression. Defaults to 0.1.</p> <code>0.1</code> <code>program_structure</code> <code>str</code> <p>Gene expression program structure; e.g., 'linear', 'bidirectional'. Defaults to \"linear\".</p> <code>'linear'</code> <code>program_on_time_fraction</code> <code>float</code> <p>Fraction of time the program is on. Defaults to 0.3.</p> <code>0.3</code> <code>program_gap_size</code> <code>int</code> <p>Size of gaps in expression programs. Defaults to 1.</p> <code>1</code> <code>program_noise_in_block</code> <code>bool</code> <p>Whether to add noise within each expression block. Defaults to True.</p> <code>True</code> <code>trajectory_program_num</code> <code>int</code> <p>Number of programs in a trajectory simulation. Defaults to 3.</p> <code>3</code> <code>trajectory_cell_block_size_ratio</code> <code>float</code> <p>Ratio of cell block sizes in a trajectory. Defaults to 0.3.</p> <code>0.3</code> <code>trajectory_loop_to</code> <code>int or list</code> <p>Loop connection in trajectory simulations. Defaults to None.</p> <code>None</code> <code>tree_branching_factor</code> <code>int</code> <p>Number of branches per tree level. Defaults to 2.</p> <code>2</code> <code>tree_depth</code> <code>int</code> <p>Depth of the simulated tree. Defaults to 3.</p> <code>3</code> <code>tree_program_decay</code> <code>float</code> <p>Decay factor for tree programs across branches. Defaults to 0.5.</p> <code>0.5</code> <code>tree_cellcount_decay</code> <code>float</code> <p>Decay factor for cell numbers across tree branches. Defaults to 1.0.</p> <code>1.0</code> <code>batch_distribution</code> <code>str or list</code> <p>Distribution for batch effects. Defaults to 'normal'.</p> <code>'normal'</code> <code>batch_level</code> <code>float or list</code> <p>Magnitude of batch effects. Defaults to 1.0.</p> <code>1.0</code> <code>batch_dispersion</code> <code>float or list</code> <p>Dispersion of batch effects. Defaults to 0.1.</p> <code>0.1</code> <code>batch_cell_proportion</code> <code>list</code> <p>Proportion of cells per batch. Defaults to None.</p> <code>None</code> <code>batch_feature_frac</code> <code>float or list</code> <p>Fraction of genes affected by batch effects. Defaults to 0.1.</p> <code>0.1</code> <code>global_non_specific_gene_fraction</code> <code>float</code> <p>Fraction of genes that are globally non-specific. Defaults to 0.1.</p> <code>0.1</code> <code>pairwise_non_specific_gene_fraction</code> <code>dict</code> <p>Pairwise-specific gene fraction between state pairs. Defaults to None.</p> <code>None</code> <code>universal_gene_fraction</code> <code>float</code> <p>Fraction of universal genes expressed across all cells. Defaults to 0.0.</p> <code>0.0</code> <code>non_neg</code> <code>bool</code> <p>Whether to enforce non-negative expression values. Defaults to False.</p> <code>False</code> <code>to_int</code> <code>bool</code> <p>Whether to convert expression values to integers. Defaults to False.</p> <code>False</code> <code>seed</code> <code>int</code> <p>Random seed for reproducibility. Defaults to 0.</p> <code>0</code> <p>Methods:</p> Name Description <code>simulate_data</code> <p>Simulates gene expression data, including batch effects.</p> <code>simulate_state</code> <p>Simulates cell state-specific gene expression patterns.</p> <code>simulate_batch</code> <p>Simulates batch-specific effects on gene expression.</p> <code>simulate_clusters</code> <p>Simulates gene expression in discrete clusters.</p> <code>simulate_trajectory</code> <p>Simulates continuous gene expression trajectories.</p> <code>simulate_tree</code> <p>Simulates hierarchical branching gene expression.</p> <code>simulate_gatto</code> <p>Simulates expression patterns similar to Gatto et al., 2023.</p> <code>simulate_s_curve</code> <p>Simulates an S-curve structure in gene expression.</p> <code>simulate_swiss_roll</code> <p>Simulates a Swiss roll structure with optional hole.</p> <code>simulate_expression_block</code> <p>Generates structured gene expression within a cell population.</p> <code>simulate_dropout</code> <p>Simulates dropout in gene expression data.</p> <code>downsample_mtx_umi</code> <p>Performs UMI count downsampling.</p> <code>simulate_distribution</code> <p>Samples values from specified distributions.</p>"},{"location":"api/utils/#Concord.utils.Simulation.downsample_mtx_umi","title":"<code>downsample_mtx_umi(mtx, ratio=0.1, seed=1)</code>  <code>staticmethod</code>","text":"<p>Simulates downsampling of a gene expression matrix (UMI counts) by a given ratio.</p> <p>Parameters:</p> Name Type Description Default <code>mtx</code> <code>ndarray</code> <p>The input matrix where rows represent genes and columns represent cells.</p> required <code>ratio</code> <code>float</code> <p>The downsampling ratio (default 0.1).</p> <code>0.1</code> <code>seed</code> <code>int</code> <p>Random seed for reproducibility (default 1).</p> <code>1</code> <p>Returns:</p> Type Description <p>numpy.ndarray: The downsampled matrix.</p>"},{"location":"api/utils/#Concord.utils.Simulation.rnegbin","title":"<code>rnegbin(mu, theta, size)</code>  <code>staticmethod</code>","text":"<p>Generate random numbers from a negative binomial distribution.</p> <p>Parameters: n: Number of random numbers to generate. mu: Mean of the distribution. theta: Dispersion parameter.</p>"},{"location":"api/utils/#Concord.utils.Simulation.simulate_batch","title":"<code>simulate_batch(adata, cell_indices=None, cell_proportion=0.3, batch_name='batch_1', effect_type='batch_specific_features', distribution='normal', level=1.0, dispersion=0.1, batch_feature_frac=0.1, seed=42)</code>","text":"<p>Applies batch-specific effects to an existing simulated dataset.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>Base dataset to apply batch effects.</p> required <code>cell_indices</code> <code>array - like</code> <p>Indices of cells to modify. Defaults to None.</p> <code>None</code> <code>cell_proportion</code> <code>float</code> <p>Proportion of cells affected. Defaults to 0.3.</p> <code>0.3</code> <code>batch_name</code> <code>str</code> <p>Name of the batch. Defaults to 'batch_1'.</p> <code>'batch_1'</code> <code>effect_type</code> <code>str</code> <p>Type of batch effect (e.g., 'batch_specific_features', 'variance_inflation'). Defaults to 'batch_specific_features'.</p> <code>'batch_specific_features'</code> <code>distribution</code> <code>str</code> <p>Distribution type for batch effects (e.g., 'normal'). Defaults to 'normal'.</p> <code>'normal'</code> <code>level</code> <code>float</code> <p>Effect level (e.g., scaling factor). Defaults to 1.0.</p> <code>1.0</code> <code>dispersion</code> <code>float</code> <p>Dispersion of batch effects. Defaults to 0.1.</p> <code>0.1</code> <code>batch_feature_frac</code> <code>float</code> <p>Fraction of genes affected by batch effects. Defaults to 0.1.</p> <code>0.1</code> <code>seed</code> <code>int</code> <p>Random seed for reproducibility. Defaults to 42.</p> <code>42</code> <p>Returns:</p> Name Type Description <code>tuple</code> <ul> <li>batch_adata (AnnData): Modified dataset with batch effects.</li> <li>batch_adata_pre (AnnData): Dataset before applying batch effects.</li> </ul>"},{"location":"api/utils/#Concord.utils.Simulation.simulate_clusters","title":"<code>simulate_clusters(n_genes=6, n_cells=12, num_clusters=2, program_structure='uniform', program_on_time_fraction=0.3, distribution='normal', mean_expression=10, min_expression=1, dispersion=1.0, global_non_specific_gene_fraction=0.1, pairwise_non_specific_gene_fraction=None, cluster_key='cluster', permute=False, seed=42)</code>","text":"<p>Simulates gene expression for discrete cell clusters.</p> <p>Parameters:</p> Name Type Description Default <code>n_genes</code> <code>int or list</code> <p>Number of genes per cluster or total genes. Defaults to 6.</p> <code>6</code> <code>n_cells</code> <code>int or list</code> <p>Number of cells per cluster or total cells. Defaults to 12.</p> <code>12</code> <code>num_clusters</code> <code>int</code> <p>Number of clusters to simulate. Defaults to 2.</p> <code>2</code> <code>program_structure</code> <code>str</code> <p>Expression program structure ('linear', 'uniform', etc.). Defaults to 'uniform'.</p> <code>'uniform'</code> <code>program_on_time_fraction</code> <code>float</code> <p>Fraction of program duration. Defaults to 0.3.</p> <code>0.3</code> <code>distribution</code> <code>str</code> <p>Type of distribution for gene expression. Defaults to 'normal'.</p> <code>'normal'</code> <code>mean_expression</code> <code>float</code> <p>Mean expression level. Defaults to 10.</p> <code>10</code> <code>min_expression</code> <code>float</code> <p>Minimum expression level. Defaults to 1.</p> <code>1</code> <code>dispersion</code> <code>float</code> <p>Dispersion in expression levels. Defaults to 1.0.</p> <code>1.0</code> <code>global_non_specific_gene_fraction</code> <code>float</code> <p>Fraction of globally expressed genes. Defaults to 0.1.</p> <code>0.1</code> <code>pairwise_non_specific_gene_fraction</code> <code>dict</code> <p>Pairwise-specific genes between cluster pairs. Defaults to None.</p> <code>None</code> <code>cluster_key</code> <code>str</code> <p>Key for cluster labeling. Defaults to 'cluster'.</p> <code>'cluster'</code> <code>permute</code> <code>bool</code> <p>Whether to shuffle cells. Defaults to False.</p> <code>False</code> <code>seed</code> <code>int</code> <p>Random seed. Defaults to 42.</p> <code>42</code> <p>Returns:</p> Name Type Description <code>AnnData</code> <p>Simulated dataset with clustered gene expression.</p>"},{"location":"api/utils/#Concord.utils.Simulation.simulate_data","title":"<code>simulate_data()</code>","text":"<p>Simulates single-cell gene expression data, integrating state-based and batch effects.</p> <p>Returns:</p> Name Type Description <code>tuple</code> <ul> <li>adata (AnnData): Simulated gene expression data with batch effects.</li> <li>adata_pre (AnnData): Pre-batch effect simulated data.</li> </ul>"},{"location":"api/utils/#Concord.utils.Simulation.simulate_dropout","title":"<code>simulate_dropout(mtx, dropout_lambda=1.0, seed=None)</code>  <code>staticmethod</code>","text":"<p>Simulates dropout in UMI counts based on the specified dropout lambda.</p> <p>Parameters:</p> Name Type Description Default <code>mtx</code> <code>ndarray</code> <p>The actual UMI counts matrix (genes x cells).</p> required <code>dropout_lambda</code> <code>float</code> <p>The lambda parameter controlling the dropout probability.</p> <code>1.0</code> <code>seed</code> <code>int</code> <p>Seed for the random number generator for reproducibility.</p> <code>None</code> <p>Returns:</p> Type Description <p>numpy.ndarray: The UMI counts matrix after applying dropout.</p>"},{"location":"api/utils/#Concord.utils.Simulation.simulate_state","title":"<code>simulate_state()</code>","text":"<p>Simulates gene expression profiles for different cell states.</p> <p>Returns:</p> Name Type Description <code>AnnData</code> <p>An AnnData object containing simulated state-specific expression data.</p>"},{"location":"api/utils/#Concord.utils.Simulation.simulate_trajectory","title":"<code>simulate_trajectory(n_genes=10, n_cells=100, cell_block_size_ratio=0.3, program_num=3, program_structure='linear', program_on_time_fraction=0.3, distribution='normal', mean_expression=10, min_expression=0, dispersion=1.0, seed=42, loop_to=None)</code>","text":"<p>Simulates a continuous trajectory of gene expression.</p> <p>Parameters:</p> Name Type Description Default <code>n_genes</code> <code>int</code> <p>Number of genes. Defaults to 10.</p> <code>10</code> <code>n_cells</code> <code>int</code> <p>Number of cells. Defaults to 100.</p> <code>100</code> <code>cell_block_size_ratio</code> <code>float</code> <p>Ratio of cell blocks. Defaults to 0.3.</p> <code>0.3</code> <code>program_num</code> <code>int</code> <p>Number of gene programs in the trajectory. Defaults to 3.</p> <code>3</code> <code>program_structure</code> <code>str</code> <p>Structure of gene programs ('linear', 'bidirectional'). Defaults to 'linear'.</p> <code>'linear'</code> <code>program_on_time_fraction</code> <code>float</code> <p>Fraction of time the program is on. Defaults to 0.3.</p> <code>0.3</code> <code>distribution</code> <code>str</code> <p>Distribution type. Defaults to 'normal'.</p> <code>'normal'</code> <code>mean_expression</code> <code>float</code> <p>Mean expression level. Defaults to 10.</p> <code>10</code> <code>min_expression</code> <code>float</code> <p>Minimum expression level. Defaults to 0.</p> <code>0</code> <code>dispersion</code> <code>float</code> <p>Dispersion of expression. Defaults to 1.0.</p> <code>1.0</code> <code>seed</code> <code>int</code> <p>Random seed. Defaults to 42.</p> <code>42</code> <code>loop_to</code> <code>int or list</code> <p>Defines looping relationships in the trajectory. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>AnnData</code> <p>Simulated dataset with continuous gene expression patterns.</p>"},{"location":"api/utils/#Concord.utils.Simulation.simulate_tree","title":"<code>simulate_tree(n_genes=10, n_cells=100, branching_factor=2, depth=3, program_structure='linear_increasing', program_on_time_fraction=0.3, program_gap_size=1, program_decay=0.5, cellcount_decay=1.0, distribution='normal', mean_expression=10, min_expression=0, dispersion=1.0, seed=42, noise_in_block=True)</code>","text":"<p>Simulates hierarchical branching gene expression patterns.</p> <p>Parameters:</p> Name Type Description Default <code>n_genes</code> <code>int</code> <p>Number of genes. Defaults to 10.</p> <code>10</code> <code>n_cells</code> <code>int</code> <p>Number of cells. Defaults to 100.</p> <code>100</code> <code>branching_factor</code> <code>int</code> <p>Number of branches per level. Defaults to 2.</p> <code>2</code> <code>depth</code> <code>int</code> <p>Depth of the branching tree. Defaults to 3.</p> <code>3</code> <code>program_structure</code> <code>str</code> <p>Gene program structure. Defaults to 'linear_increasing'.</p> <code>'linear_increasing'</code> <code>program_on_time_fraction</code> <code>float</code> <p>Program activation time fraction. Defaults to 0.3.</p> <code>0.3</code> <code>program_gap_size</code> <code>int</code> <p>Gap size between programs. Defaults to 1.</p> <code>1</code> <code>program_decay</code> <code>float</code> <p>Decay factor for program effects. Defaults to 0.5.</p> <code>0.5</code> <code>cellcount_decay</code> <code>float</code> <p>Decay factor for cell counts. Defaults to 1.0.</p> <code>1.0</code> <code>distribution</code> <code>str</code> <p>Expression distribution type. Defaults to 'normal'.</p> <code>'normal'</code> <code>mean_expression</code> <code>float</code> <p>Mean gene expression level. Defaults to 10.</p> <code>10</code> <code>min_expression</code> <code>float</code> <p>Minimum gene expression level. Defaults to 0.</p> <code>0</code> <code>dispersion</code> <code>float</code> <p>Dispersion of expression. Defaults to 1.0.</p> <code>1.0</code> <code>seed</code> <code>int</code> <p>Random seed. Defaults to 42.</p> <code>42</code> <code>noise_in_block</code> <code>bool</code> <p>Whether to add noise within expression blocks. Defaults to True.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>AnnData</code> <p>Simulated dataset with hierarchical tree-like gene expression.</p>"},{"location":"api/utils/#Concord.utils.select_features","title":"<code>Concord.utils.select_features(adata, n_top_features=2000, flavor='seurat_v3', filter_gene_by_counts=False, normalize=False, log1p=False, grouping='cluster', emb_key='X_pca', k=512, knn_samples=100, gini_cut_qt=None, save_path=None, figsize=(10, 3), subsample_frac=1.0, random_state=0)</code>","text":"<p>Selects top informative features from an AnnData object.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>AnnData object containing gene expression data.</p> required <code>n_top_features</code> <code>int</code> <p>Number of top features to select. Defaults to 2000.</p> <code>2000</code> <code>flavor</code> <code>str</code> <p>Feature selection method. Options: - 'seurat_v3': Highly variable gene selection based on Seurat v3. - 'iff': Uses Informative Feature Filtering (IFF) method. Defaults to \"seurat_v3\".</p> <code>'seurat_v3'</code> <code>filter_gene_by_counts</code> <code>Union[int, bool]</code> <p>Minimum count threshold for feature filtering. Defaults to False.</p> <code>False</code> <code>normalize</code> <code>bool</code> <p>Whether to normalize the data before feature selection. Defaults to False.</p> <code>False</code> <code>log1p</code> <code>bool</code> <p>Whether to apply log1p transformation before feature selection. Defaults to False.</p> <code>False</code> <code>grouping</code> <code>Union[str, Series, List[str]]</code> <p>Clustering/grouping strategy for IFF method. Defaults to 'cluster'.</p> <code>'cluster'</code> <code>emb_key</code> <code>str</code> <p>Embedding key in <code>adata.obsm</code> used for clustering. Defaults to 'X_pca'.</p> <code>'X_pca'</code> <code>k</code> <code>int</code> <p>Number of neighbors for k-NN if <code>grouping='knn'</code>. Defaults to 512.</p> <code>512</code> <code>knn_samples</code> <code>int</code> <p>Number of k-NN samples if <code>grouping='knn'</code>. Defaults to 100.</p> <code>100</code> <code>gini_cut_qt</code> <code>float</code> <p>Quantile threshold for selecting features by Gini coefficient in IFF. Defaults to None.</p> <code>None</code> <code>save_path</code> <code>Optional[Union[str, Path]]</code> <p>Path to save Gini coefficient plot. Defaults to None.</p> <code>None</code> <code>figsize</code> <code>tuple</code> <p>Size of Gini coefficient plot. Defaults to (10, 3).</p> <code>(10, 3)</code> <code>subsample_frac</code> <code>float</code> <p>Fraction of data to subsample for feature selection. Defaults to 1.0.</p> <code>1.0</code> <code>random_state</code> <code>int</code> <p>Random seed for reproducibility. Defaults to 0.</p> <code>0</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: List of selected feature names.</p>"},{"location":"api/utils/#Concord.utils.generate_synthetic_doublets","title":"<code>Concord.utils.generate_synthetic_doublets(adata, doublet_synth_ratio, seed, batch_key, droplet_type_key, mean=0.5, var=0.1, clip_range=(0.2, 0.8), plot_histogram=True, combine_with_original=False)</code>","text":"<p>Generate synthetic doublets from singlet data in an AnnData object within each batch.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <p>AnnData object containing the singlet data (with maybe unclassified doublets)</p> required <code>doublet_synth_ratio</code> <p>float, the ratio of synthetic doublets to true singlets</p> required <code>seed</code> <p>int, random seed for reproducibility</p> required <code>batch_key</code> <p>str, the key in .obs indicating batch information</p> required <code>droplet_type_key</code> <p>str, the key in .obs indicating droplet type</p> required <code>mean</code> <p>float, mean of the normal distribution for generating fractions (default: 0.5)</p> <code>0.5</code> <code>var</code> <p>float, variance of the normal distribution for generating fractions (default: 0.1)</p> <code>0.1</code> <code>clip_range</code> <p>tuple, range to clip the generated fractions (default: (0.2, 0.8))</p> <code>(0.2, 0.8)</code> <code>plot_histogram</code> <p>bool, whether to plot the histogram of synthetic doublet fractions</p> <code>True</code> <p>Returns:</p> Name Type Description <code>adata_synthetic_doublets</code> <p>AnnData object containing the synthetic doublets</p>"},{"location":"api/utils/#Concord.utils.list_adata_files","title":"<code>Concord.utils.list_adata_files(folder_path, substring=None, extension='*.h5ad')</code>","text":"<p>List all <code>.h5ad</code> files in a directory (recursively) that match a given substring.</p> <p>Parameters:</p> Name Type Description Default <code>folder_path</code> <p>str Path to the folder where <code>.h5ad</code> files are located.</p> required <code>substring</code> <p>str, optional A substring to filter filenames (default is None, meaning no filtering).</p> <code>None</code> <code>extension</code> <p>str, optional File extension to search for (default is \"*.h5ad\").</p> <code>'*.h5ad'</code> <p>Returns:</p> Type Description <p>list A list of file paths matching the criteria.</p>"},{"location":"api/utils/#Concord.utils.read_and_concatenate_adata","title":"<code>Concord.utils.read_and_concatenate_adata(adata_files, merge='unique', add_dataset_col=False, dataset_col_name='dataset', output_file=None)</code>","text":"<p>Read and concatenate multiple AnnData <code>.h5ad</code> files into a single AnnData object.</p> <p>Parameters:</p> Name Type Description Default <code>adata_files</code> <p>list List of file paths to <code>.h5ad</code> files to be concatenated.</p> required <code>merge</code> <p>str, optional How to handle conflicting columns, e.g., 'unique' (default), 'first', etc.</p> <code>'unique'</code> <code>add_dataset_col</code> <p>bool, optional Whether to add a new column in <code>adata.obs</code> identifying the source dataset.</p> <code>False</code> <code>dataset_col_name</code> <p>str, optional Name of the new column storing dataset names.</p> <code>'dataset'</code> <code>output_file</code> <p>str, optional Path to save the concatenated AnnData object. If None, the object is not saved.</p> <code>None</code> <p>Returns:</p> Type Description <p>ad.AnnData The concatenated AnnData object.</p>"},{"location":"api/utils/#Concord.utils.filter_and_copy_attributes","title":"<code>Concord.utils.filter_and_copy_attributes(adata_target, adata_source)</code>","text":"<p>Filter <code>adata_target</code> to match the cells in <code>adata_source</code>, then copy <code>.obs</code> and <code>.obsm</code>.</p> <p>Parameters:</p> Name Type Description Default <code>adata_target</code> <p>ad.AnnData The AnnData object to be filtered.</p> required <code>adata_source</code> <p>ad.AnnData The reference AnnData object containing the desired cells and attributes.</p> required <p>Returns:</p> Type Description <p>ad.AnnData The filtered AnnData object with updated <code>.obs</code> and <code>.obsm</code>.</p>"},{"location":"api/utils/#Concord.utils.ensure_categorical","title":"<code>Concord.utils.ensure_categorical(adata, obs_key=None, drop_unused=True)</code>","text":"<p>Convert an <code>.obs</code> column to categorical dtype.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <p>ad.AnnData The AnnData object.</p> required <code>obs_key</code> <p>str Column in <code>.obs</code> to be converted to categorical.</p> <code>None</code> <code>drop_unused</code> <p>bool, optional Whether to remove unused categories (default is True).</p> <code>True</code>"},{"location":"api/utils/#Concord.utils.save_obsm_to_hdf5","title":"<code>Concord.utils.save_obsm_to_hdf5(adata, filename)</code>","text":"<p>Save the <code>.obsm</code> attribute of an AnnData object to an HDF5 file.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <p>anndata.AnnData The AnnData object containing the <code>.obsm</code> attribute to be saved.</p> required <code>filename</code> <p>str The path to the HDF5 file where <code>.obsm</code> data will be stored.</p> required <p>Returns:</p> Type Description <p>None Saves <code>.obsm</code> data to the specified HDF5 file.</p>"},{"location":"api/utils/#Concord.utils.load_obsm_from_hdf5","title":"<code>Concord.utils.load_obsm_from_hdf5(filename)</code>","text":"<p>Load the <code>.obsm</code> attribute from an HDF5 file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <p>str Path to the HDF5 file containing <code>.obsm</code> data.</p> required <p>Returns:</p> Type Description <p>dict A dictionary where keys are <code>.obsm</code> names and values are corresponding matrices.</p>"},{"location":"api/utils/#Concord.utils.subset_adata_to_obsm_indices","title":"<code>Concord.utils.subset_adata_to_obsm_indices(adata, obsm)</code>","text":"<p>Subset an AnnData object to match the indices present in <code>.obsm</code>.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <p>anndata.AnnData The original AnnData object.</p> required <code>obsm</code> <p>dict A dictionary containing <code>.obsm</code> data, where keys are embedding names, and values are arrays.</p> required <p>Returns:</p> Type Description <p>anndata.AnnData A subsetted AnnData object that contains only the indices available in <code>.obsm</code>.</p>"},{"location":"api/utils/#Concord.utils.anndata_to_viscello","title":"<code>Concord.utils.anndata_to_viscello(adata, output_dir, project_name='MyProject', organism='hsa', clist_only=False)</code>","text":"<p>Converts an AnnData object to a VisCello project directory.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>AnnData object containing single-cell data.</p> required <code>output_dir</code> <code>str</code> <p>Directory where the VisCello project will be created.</p> required <code>project_name</code> <code>str</code> <p>Name of the project. Defaults to \"MyProject\".</p> <code>'MyProject'</code> <code>organism</code> <code>str</code> <p>Organism code (e.g., 'hsa' for human). Defaults to 'hsa'.</p> <code>'hsa'</code> <code>clist_only</code> <code>bool</code> <p>Whether to generate only the clist file. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <p>None</p> Side Effects <ul> <li>Creates a directory with the necessary files for VisCello.</li> <li>Saves <code>eset.rds</code> (ExpressionSet), <code>config.yml</code>, and <code>clist.rds</code>.</li> </ul>"},{"location":"api/utils/#Concord.utils.update_clist_with_subsets","title":"<code>Concord.utils.update_clist_with_subsets(global_adata, adata_subsets, viscello_dir, cluster_key=None)</code>","text":"<p>Updates an existing VisCello clist with new subsets.</p> <p>Parameters:</p> Name Type Description Default <code>global_adata</code> <code>AnnData</code> <p>The full AnnData object.</p> required <code>adata_subsets</code> <code>dict</code> <p>Dictionary mapping subset names to AnnData objects.</p> required <code>viscello_dir</code> <code>str</code> <p>Path to the existing VisCello directory.</p> required <code>cluster_key</code> <code>str</code> <p>Key in <code>adata.obs</code> for cluster assignments. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <p>None</p> Side Effects <ul> <li>Reads the existing <code>clist.rds</code> file from <code>viscello_dir</code>.</li> <li>Adds new subsets as <code>Cello</code> objects to the clist.</li> <li>Saves the updated <code>clist.rds</code> file in <code>viscello_dir</code>.</li> </ul>"},{"location":"galleries/cbce_show/","title":"3D CONCORD UMAP of C. elegans and C. briggsae Embryogenesis","text":"<ul> <li>Data from Large, Christopher RL, et al. \"Lineage-resolved analysis of embryonic gene expression evolution in C. elegans and C. briggsae.\" bioRxiv (2024): 2024-02, visualized with 3D UMAP with CONCORD latent. Click the image to view interactive plots.</li> </ul> Embryo TimeCell ClassCell TypeLineageSpecies <p> \u2b07\ufe0f Download Interactive HTML</p> <p> \u2b07\ufe0f Download Interactive HTML</p> <p> \u2b07\ufe0f Download Interactive HTML</p> <p> \u2b07\ufe0f Download Interactive HTML</p> <p> \u2b07\ufe0f Download Interactive HTML</p>"},{"location":"galleries/huycke_show/","title":"3D CONCORD UMAP of Intestine Development Atlas","text":"<ul> <li>Data from Huycke, Tyler R., et al. \"Patterning and folding of intestinal villi by active mesenchymal dewetting.\" Cell 187.12 (2024): 3072-3089, visualized with 3D UMAP with CONCORD latent. Click the image to view interactive plots.</li> </ul> Cell cycleBroad cell typeZonationDevelopmental stageBatch <p> \u2b07\ufe0f Download Interactive HTML</p> <p> \u2b07\ufe0f Download Interactive HTML</p> <p> \u2b07\ufe0f Download Interactive HTML</p> <p> \u2b07\ufe0f Download Interactive HTML</p> <p> \u2b07\ufe0f Download Interactive HTML</p>"},{"location":"notebooks/concord_Huycke/","title":"Intestine development by Huycke et al.","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n</pre> %load_ext autoreload %autoreload 2 In\u00a0[2]: Copied! <pre>import Concord as ccd\nimport scanpy as sc\nimport torch\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndata_path = \"../data/intestine_dev/intestine_adata.h5ad\"\nadata = sc.read(\n    data_path\n)\n\nadata.layers[\"counts\"] = adata.X.copy()\nsc.pp.normalize_total(adata)\nsc.pp.log1p(adata)\nccd.ul.score_cell_cycle(adata, organism='Mm')\n</pre> import Concord as ccd import scanpy as sc import torch import warnings warnings.filterwarnings('ignore')  data_path = \"../data/intestine_dev/intestine_adata.h5ad\" adata = sc.read(     data_path )  adata.layers[\"counts\"] = adata.X.copy() sc.pp.normalize_total(adata) sc.pp.log1p(adata) ccd.ul.score_cell_cycle(adata, organism='Mm') <pre>Concord - INFO - Processed 43 human genes to mouse orthologs.\nConcord - INFO - Processed 54 human genes to mouse orthologs.\n</pre> In\u00a0[3]: Copied! <pre>import time\nfrom pathlib import Path\nproj_name = \"concord_Huycke_intestine\"\nsave_dir = f\"../save/dev_{proj_name}-{time.strftime('%b%d')}/\"\nsave_dir = Path(save_dir)\nsave_dir.mkdir(parents=True, exist_ok=True)\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nfile_suffix = f\"{proj_name}_{time.strftime('%b%d')}\"\nseed = 0\n</pre> import time from pathlib import Path proj_name = \"concord_Huycke_intestine\" save_dir = f\"../save/dev_{proj_name}-{time.strftime('%b%d')}/\" save_dir = Path(save_dir) save_dir.mkdir(parents=True, exist_ok=True) device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') file_suffix = f\"{proj_name}_{time.strftime('%b%d')}\" seed = 0 In\u00a0[\u00a0]: Copied! <pre>output_key = 'Concord'\nfeature_list = ccd.ul.select_features(adata, n_top_features=10000, flavor='seurat_v3')\ncur_ccd = ccd.Concord(adata=adata, input_feature=feature_list, domain_key='LaneID', \n                      latent_dim=32,\n                      clr_temperature = .3, # Check out advanced usage to learn what this parameter controls\n                      p_intra_domain=1.0, # Check out advanced usage to learn what this parameter controls\n                      seed=seed, \n                      inplace=False, \n                      verbose=True, \n                      device=device) \n\n# Encode data, saving the latent embedding in adata.obsm['Concord']\ncur_ccd.encode_adata(input_layer_key='X_log1p', output_key=output_key)\n\n# Save the latent embedding to a filem, so that it can be loaded later\nccd.ul.save_obsm_to_hdf5(cur_ccd.adata, save_dir / f\"obsm_{file_suffix}.h5\")\nadata.obsm = cur_ccd.adata.obsm # If not inplace\n</pre> output_key = 'Concord' feature_list = ccd.ul.select_features(adata, n_top_features=10000, flavor='seurat_v3') cur_ccd = ccd.Concord(adata=adata, input_feature=feature_list, domain_key='LaneID',                        latent_dim=32,                       clr_temperature = .3, # Check out advanced usage to learn what this parameter controls                       p_intra_domain=1.0, # Check out advanced usage to learn what this parameter controls                       seed=seed,                        inplace=False,                        verbose=True,                        device=device)   # Encode data, saving the latent embedding in adata.obsm['Concord'] cur_ccd.encode_adata(input_layer_key='X_log1p', output_key=output_key)  # Save the latent embedding to a filem, so that it can be loaded later ccd.ul.save_obsm_to_hdf5(cur_ccd.adata, save_dir / f\"obsm_{file_suffix}.h5\") adata.obsm = cur_ccd.adata.obsm # If not inplace <pre>Concord - INFO - Setting sampler_knn to 1309 to be 1/50 the number of cells in the dataset. You can change this value by setting sampler_knn in the configuration.\nConcord - INFO - Column 'LaneID' is already of type: category\nConcord - INFO - Unused levels dropped for column 'LaneID'.\nConcord - INFO - Encoder input dim: 10000\nConcord - INFO - Decoder input dim: 40\nConcord - INFO - Model loaded to device: cuda:0\nConcord - INFO - Total number of parameters: 2590128\nConcord.model.dataloader - INFO - Preprocessing adata...\nConcord.utils.preprocessor - INFO - Data is already log1p transformed. Skip normalization.\nConcord.utils.preprocessor - INFO - Data is already log1p transformed. Storing in the specified layer.\nConcord.utils.preprocessor - INFO - Filtering features with provided list (10000 features)...\nConcord.model.anndataset - INFO - Initialized dataset with 65468 samples. Data structure: ['input', 'domain', 'idx']\nConcord.model.dataloader - INFO - Using existing embedding 'X_pca' from adata.obsm\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss IVF index. nprobe=10\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.dataloader - INFO - Number of unique_domains: 6\nConcord.model.dataloader - INFO - Calculating each domain's coverage of the global manifold using X_pca.\nConcord.model.dataloader - INFO - Converting coverage to p_intra_domain...\nConcord.model.dataloader - INFO - Final p_intra_domain values: L1: 1.00, L2: 1.00, R: 1.00, Live_1: 1.00, Live_2: 1.00, Rare: 1.00\nConcord - INFO - Starting epoch 1/5\nConcord - INFO - Processing chunk 1/1 for epoch 1\nConcord - INFO - Number of samples in train_dataloader: 65468\n</pre> <pre>Epoch 0 Training: 1020it [00:32, 31.28it/s, loss=3.05]</pre> <pre>Concord - INFO - Epoch   0 | Train Loss: 3.33, MSE: 0.09, CLASS: 0.00, CONTRAST: 3.24, IMPORTANCE: 0.00\nConcord - INFO - Starting epoch 2/5\nConcord - INFO - Processing chunk 1/1 for epoch 2\nConcord - INFO - Number of samples in train_dataloader: 65468\n</pre> <pre>\nEpoch 1 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1020/1020 [00:30&lt;00:00, 33.47it/s, loss=3.06]</pre> <pre>Concord - INFO - Epoch   1 | Train Loss: 2.99, MSE: 0.06, CLASS: 0.00, CONTRAST: 2.93, IMPORTANCE: 0.00\nConcord - INFO - Starting epoch 3/5\nConcord - INFO - Processing chunk 1/1 for epoch 3\nConcord - INFO - Number of samples in train_dataloader: 65468\n</pre> <pre>\nEpoch 2 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1020/1020 [00:27&lt;00:00, 36.61it/s, loss=2.94]</pre> <pre>Concord - INFO - Epoch   2 | Train Loss: 2.94, MSE: 0.06, CLASS: 0.00, CONTRAST: 2.88, IMPORTANCE: 0.00\nConcord - INFO - Starting epoch 4/5\nConcord - INFO - Processing chunk 1/1 for epoch 4\nConcord - INFO - Number of samples in train_dataloader: 65468\n</pre> <pre>\nEpoch 3 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1020/1020 [00:28&lt;00:00, 36.01it/s, loss=3.09]</pre> <pre>Concord - INFO - Epoch   3 | Train Loss: 2.91, MSE: 0.06, CLASS: 0.00, CONTRAST: 2.85, IMPORTANCE: 0.00\nConcord - INFO - Starting epoch 5/5\nConcord - INFO - Processing chunk 1/1 for epoch 5\nConcord - INFO - Number of samples in train_dataloader: 65468\n</pre> <pre>\nEpoch 4 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1020/1020 [00:29&lt;00:00, 34.81it/s, loss=3.05]</pre> <pre>Concord - INFO - Epoch   4 | Train Loss: 2.89, MSE: 0.06, CLASS: 0.00, CONTRAST: 2.83, IMPORTANCE: 0.00\n</pre> <pre>\n</pre> <pre>Concord - INFO - Model saved to save/final_model.pth\nConcord - INFO - Final model saved at: save/final_model.pth; Configuration saved at: save/config.json.\nConcord.model.dataloader - INFO - Preprocessing adata...\nConcord.utils.preprocessor - INFO - Data is already log1p transformed. Skip normalization.\nConcord.utils.preprocessor - INFO - Data is already log1p transformed. Storing in the specified layer.\nConcord.utils.preprocessor - INFO - Filtering features with provided list (10000 features)...\nConcord.model.anndataset - INFO - Initialized dataset with 65468 samples. Data structure: ['input', 'domain', 'idx']\nConcord - INFO - Predicting for chunk 1/1\n</pre> In\u00a0[100]: Copied! <pre>#ccd.ul.run_umap(adata, source_key=output_key, umap_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.1, metric='euclidean', random_state=seed)\nshow_basis = f'{output_key}_UMAP'\nshow_cols = ['MouseAge_combined', 'seg_classify', 'phase', 'batch', 'cell_type', \"mes_subtype\", \"dropout_est\"]\nccd.pl.plot_embedding(\n    adata, show_basis, show_cols, figsize=(13,12), dpi=600, ncols=3, font_size=5, point_size=1, legend_loc='on data',\n    save_path=save_dir / f\"{show_basis}_{file_suffix}.png\"\n)\n</pre> #ccd.ul.run_umap(adata, source_key=output_key, umap_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.1, metric='euclidean', random_state=seed) show_basis = f'{output_key}_UMAP' show_cols = ['MouseAge_combined', 'seg_classify', 'phase', 'batch', 'cell_type', \"mes_subtype\", \"dropout_est\"] ccd.pl.plot_embedding(     adata, show_basis, show_cols, figsize=(13,12), dpi=600, ncols=3, font_size=5, point_size=1, legend_loc='on data',     save_path=save_dir / f\"{show_basis}_{file_suffix}.png\" ) <p>It is best to use 3D UMAP rather than 2D to visualize Concord latent, because 2D may not be enough to 'unpack' the complex structures learned by Concord, thus tends to break trajectories.</p> In\u00a0[93]: Copied! <pre>import plotly.io as pio\npio.renderers.default = 'notebook'\nccd.ul.run_umap(adata,  source_key=output_key, umap_key=f'{output_key}_UMAP_3D', n_components=3, n_neighbors=15, min_dist=0.1, metric='euclidean')\n\n# Plot the 3D UMAP embeddings\n#show_cols = ['MouseAge_combined', 'seg_classify', 'phase', 'batch', 'cell_type', \"mes_subtype\"]\ncol = 'cell_type'\nshow_basis = f'{output_key}_UMAP_3D'\nccd.pl.plot_embedding_3d(\n        adata, basis=show_basis, color_by=col,\n        save_path=save_dir / f'{show_basis}_{file_suffix}.html',\n        point_size=1, opacity=0.8, width=1500, height=1000\n    )\n</pre> import plotly.io as pio pio.renderers.default = 'notebook' ccd.ul.run_umap(adata,  source_key=output_key, umap_key=f'{output_key}_UMAP_3D', n_components=3, n_neighbors=15, min_dist=0.1, metric='euclidean')  # Plot the 3D UMAP embeddings #show_cols = ['MouseAge_combined', 'seg_classify', 'phase', 'batch', 'cell_type', \"mes_subtype\"] col = 'cell_type' show_basis = f'{output_key}_UMAP_3D' ccd.pl.plot_embedding_3d(         adata, basis=show_basis, color_by=col,         save_path=save_dir / f'{show_basis}_{file_suffix}.html',         point_size=1, opacity=0.8, width=1500, height=1000     ) <pre>Concord - INFO - UMAP embedding stored in adata.obsm['Concord_UMAP_3D']\nConcord - INFO - 3D plot saved to ../save/dev_concord_Huycke_intestine-Sep29/Concord_UMAP_3D_concord_Huycke_intestine_Sep29.html\n</pre> <p>We can just visualize the Mesenchmal cell (Pdgfra hi/lo) subset, note the loop of cell cycle and the differentiation from Pdgfra-lo to Pdgfra-hi cells.</p> In\u00a0[97]: Copied! <pre>col = 'mes_subtype'\nshow_basis = f'{output_key}_UMAP_3D'\nccd.pl.plot_embedding_3d(\n        adata, basis=show_basis, color_by=col,\n        save_path=save_dir / f'{show_basis}_{file_suffix}.html',\n        point_size=1, opacity=0.8, width=1500, height=800\n    )\n</pre> col = 'mes_subtype' show_basis = f'{output_key}_UMAP_3D' ccd.pl.plot_embedding_3d(         adata, basis=show_basis, color_by=col,         save_path=save_dir / f'{show_basis}_{file_suffix}.html',         point_size=1, opacity=0.8, width=1500, height=800     ) <pre>Concord - INFO - 3D plot saved to ../save/dev_concord_Huycke_intestine-Sep29/Concord_UMAP_3D_concord_Huycke_intestine_Sep29.html\n</pre> In\u00a0[101]: Copied! <pre>obsm_filename = save_dir / f\"obsm_{file_suffix}.h5\"\nccd.ul.save_obsm_to_hdf5(adata, obsm_filename)\nadata.write_h5ad(\"../data/intestine_dev/intestine_adata_concord_{file_suffix}.h5ad\")\n</pre> obsm_filename = save_dir / f\"obsm_{file_suffix}.h5\" ccd.ul.save_obsm_to_hdf5(adata, obsm_filename) adata.write_h5ad(\"../data/intestine_dev/intestine_adata_concord_{file_suffix}.h5ad\") <p>You can optionally convert the result to VisCello (https://github.com/kimpenn/VisCello) for interactive exploration.</p> In\u00a0[\u00a0]: Copied! <pre>ccd.ul.anndata_to_viscello(adata, save_dir / f\"cello_{proj_name}_{file_suffix}\", project_name = proj_name, organism='mmu')\n</pre> ccd.ul.anndata_to_viscello(adata, save_dir / f\"cello_{proj_name}_{file_suffix}\", project_name = proj_name, organism='mmu')"},{"location":"notebooks/concord_Huycke/#basic-setup","title":"Basic setup\u00b6","text":""},{"location":"notebooks/concord_Huycke/#run-concord","title":"Run Concord\u00b6","text":""},{"location":"notebooks/concord_Huycke/#visualize-concord-latent-with-umap","title":"Visualize Concord latent with UMAP\u00b6","text":""},{"location":"notebooks/concord_Huycke/#2d-umap","title":"2D UMAP\u00b6","text":""},{"location":"notebooks/concord_Huycke/#3d-umap","title":"3D UMAP\u00b6","text":""},{"location":"notebooks/concord_Huycke/#save-the-result","title":"Save the result\u00b6","text":""},{"location":"notebooks/concord_mouse_organogenesis_100k/","title":"Mouse organogenesis (100k subset for tutorial)","text":"<p>Dataset from The single-cell transcriptional landscape of mammalian organogenesis by Cao et al., Nature (2019). This tutorial notebook runs on the 100k data subset from https://oncoscape.v3.sttrcancer.org/atlas.gs.washington.edu.mouse.rna/downloads, but CONCORD can be easily scaled to the full dataset.</p> In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n</pre> %load_ext autoreload %autoreload 2 In\u00a0[24]: Copied! <pre>import Concord as ccd\nimport scanpy as sc\nimport torch\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndata_path = \"../data/mouse_organogenesis/adata_sampled_100k.h5ad\"\nadata = sc.read(\n    data_path\n)\nimport pandas as pd\n# Make sure that the gene names are unique\ngene_names = adata.var['gene_short_name']\ngene_names_unique = pd.Series(pd.Index(gene_names)).astype(str)\ngene_names_unique = pd.Index(gene_names_unique.where(~gene_names_unique.duplicated(), gene_names_unique + \"_\" + gene_names_unique.groupby(gene_names_unique).cumcount().astype(str)))\nadata.var_names = gene_names_unique\nadata.var.index.name = None\nadata.layers[\"counts\"] = adata.X.copy()\nsc.pp.normalize_total(adata)\nsc.pp.log1p(adata)\nadata.var\nccd.ul.score_cell_cycle(adata, organism='Mm')\n</pre> import Concord as ccd import scanpy as sc import torch import warnings warnings.filterwarnings('ignore')  data_path = \"../data/mouse_organogenesis/adata_sampled_100k.h5ad\" adata = sc.read(     data_path ) import pandas as pd # Make sure that the gene names are unique gene_names = adata.var['gene_short_name'] gene_names_unique = pd.Series(pd.Index(gene_names)).astype(str) gene_names_unique = pd.Index(gene_names_unique.where(~gene_names_unique.duplicated(), gene_names_unique + \"_\" + gene_names_unique.groupby(gene_names_unique).cumcount().astype(str))) adata.var_names = gene_names_unique adata.var.index.name = None adata.layers[\"counts\"] = adata.X.copy() sc.pp.normalize_total(adata) sc.pp.log1p(adata) adata.var ccd.ul.score_cell_cycle(adata, organism='Mm') <pre>Concord - INFO - Processed 43 human genes to mouse orthologs.\nConcord - INFO - Processed 54 human genes to mouse orthologs.\n</pre> In\u00a0[25]: Copied! <pre>import time\nfrom pathlib import Path\nproj_name = \"concord_mouse_organogenesis_100k\"\nsave_dir = f\"../save/dev_{proj_name}-{time.strftime('%b%d')}/\"\nsave_dir = Path(save_dir)\nsave_dir.mkdir(parents=True, exist_ok=True)\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nfile_suffix = f\"{proj_name}_{time.strftime('%b%d')}\"\nseed = 0\n</pre> import time from pathlib import Path proj_name = \"concord_mouse_organogenesis_100k\" save_dir = f\"../save/dev_{proj_name}-{time.strftime('%b%d')}/\" save_dir = Path(save_dir) save_dir.mkdir(parents=True, exist_ok=True) device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') file_suffix = f\"{proj_name}_{time.strftime('%b%d')}\" seed = 0 In\u00a0[62]: Copied! <pre>col = 'Main_cell_type'\nshow_basis = f'Original_main_umap'\nccd.ul.ensure_categorical(adata, col)\nccd.pl.plot_embedding_3d(\n        adata, basis=show_basis, color_by=col,\n        save_path=save_dir / f'{show_basis}_{file_suffix}.html',\n        point_size=1, opacity=0.8, width=1500, height=1000\n    )\n</pre> col = 'Main_cell_type' show_basis = f'Original_main_umap' ccd.ul.ensure_categorical(adata, col) ccd.pl.plot_embedding_3d(         adata, basis=show_basis, color_by=col,         save_path=save_dir / f'{show_basis}_{file_suffix}.html',         point_size=1, opacity=0.8, width=1500, height=1000     ) <pre>Concord - INFO - Column 'Main_cell_type' is already of type: category\nConcord - INFO - Unused levels dropped for column 'Main_cell_type'.\n</pre> <pre>Concord - INFO - 3D plot saved to ../save/dev_concord_mouse_organogenesis_100k-Sep29/Original_main_umap_concord_mouse_organogenesis_100k_Sep29.html\n</pre> In\u00a0[38]: Copied! <pre>cross_tab = pd.crosstab(adata.obs['nuclei_extraction_date'], adata.obs['embryo_id'])\ncross_tab\n</pre> cross_tab = pd.crosstab(adata.obs['nuclei_extraction_date'], adata.obs['embryo_id']) cross_tab Out[38]: embryo_id 1 3 4 5 6 7 8 9 10 11 ... 59 60 61 62 63 64 65 66 67 68 nuclei_extraction_date 1 1113 590 900 1656 2000 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 2614 2354 1928 2384 732 ... 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 ... 1843 2474 2557 2456 777 3253 1361 2702 1198 2038 <p>5 rows \u00d7 61 columns</p> <p>Based on the check above, we will use embryo_id as the 'domain_key' for batch integration.</p> In\u00a0[\u00a0]: Copied! <pre>output_key = 'Concord'\nfeature_list = ccd.ul.select_features(adata, n_top_features=10000, flavor='seurat_v3')\ncur_ccd = ccd.Concord(adata=adata, \n                      input_feature=feature_list, \n                      domain_key='embryo_id', # Batch key\n                      latent_dim=300,\n                      encoder_dims=[1000], \n                      decoder_dims=[1000], \n                      clr_temperature = .5, # Check out advanced usage to learn what this parameter controls\n                      p_intra_domain=1.0, # Check out advanced usage to learn what this parameter controls\n                      seed=seed, \n                      inplace=False, \n                      verbose=True, \n                      device=device) \n\n# Encode data, saving the latent embedding in adata.obsm['Concord']\ncur_ccd.encode_adata(input_layer_key='X_log1p', output_key=output_key)\n\n# Save the latent embedding to a filem, so that it can be loaded later\nccd.ul.save_obsm_to_hdf5(cur_ccd.adata, save_dir / f\"obsm_{file_suffix}.h5\")\nadata.obsm = cur_ccd.adata.obsm # If not inplace\n</pre> output_key = 'Concord' feature_list = ccd.ul.select_features(adata, n_top_features=10000, flavor='seurat_v3') cur_ccd = ccd.Concord(adata=adata,                        input_feature=feature_list,                        domain_key='embryo_id', # Batch key                       latent_dim=300,                       encoder_dims=[1000],                        decoder_dims=[1000],                        clr_temperature = .5, # Check out advanced usage to learn what this parameter controls                       p_intra_domain=1.0, # Check out advanced usage to learn what this parameter controls                       seed=seed,                        inplace=False,                        verbose=True,                        device=device)   # Encode data, saving the latent embedding in adata.obsm['Concord'] cur_ccd.encode_adata(input_layer_key='X_log1p', output_key=output_key)  # Save the latent embedding to a filem, so that it can be loaded later ccd.ul.save_obsm_to_hdf5(cur_ccd.adata, save_dir / f\"obsm_{file_suffix}.h5\") adata.obsm = cur_ccd.adata.obsm # If not inplace <pre>Concord - INFO - Setting sampler_knn to 2000 to be 1/50 the number of cells in the dataset. You can change this value by setting sampler_knn in the configuration.\nConcord - INFO - Column 'embryo_id' is now of type: category\nConcord - INFO - Encoder input dim: 10000\nConcord - INFO - Decoder input dim: 308\nConcord - INFO - Model loaded to device: cuda:0\nConcord - INFO - Total number of parameters: 20635388\nConcord.model.dataloader - INFO - Preprocessing adata...\nConcord.utils.preprocessor - INFO - Data is already log1p transformed. Skip normalization.\nConcord.utils.preprocessor - INFO - Data is already log1p transformed. Storing in the specified layer.\nConcord.utils.preprocessor - INFO - Filtering features with provided list (10000 features)...\nConcord.model.anndataset - INFO - Initialized dataset with 100000 samples. Data structure: ['input', 'domain', 'idx']\nConcord.model.dataloader - INFO - Using existing embedding 'X_pca' from adata.obsm\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss IVF index. nprobe=10\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.dataloader - INFO - Number of unique_domains: 61\nConcord.model.dataloader - INFO - Final p_intra_domain values: 1: 1.00, 3: 1.00, 4: 1.00, 5: 1.00, 6: 1.00, 7: 1.00, 8: 1.00, 9: 1.00, 10: 1.00, 11: 1.00, 12: 1.00, 13: 1.00, 14: 1.00, 15: 1.00, 16: 1.00, 17: 1.00, 19: 1.00, 20: 1.00, 21: 1.00, 22: 1.00, 24: 1.00, 25: 1.00, 26: 1.00, 27: 1.00, 28: 1.00, 29: 1.00, 31: 1.00, 33: 1.00, 34: 1.00, 35: 1.00, 36: 1.00, 37: 1.00, 38: 1.00, 39: 1.00, 40: 1.00, 41: 1.00, 42: 1.00, 43: 1.00, 44: 1.00, 46: 1.00, 47: 1.00, 48: 1.00, 49: 1.00, 50: 1.00, 51: 1.00, 52: 1.00, 53: 1.00, 55: 1.00, 56: 1.00, 57: 1.00, 58: 1.00, 59: 1.00, 60: 1.00, 61: 1.00, 62: 1.00, 63: 1.00, 64: 1.00, 65: 1.00, 66: 1.00, 67: 1.00, 68: 1.00\nConcord - INFO - Starting epoch 1/5\nConcord - INFO - Processing chunk 1/1 for epoch 1\nConcord - INFO - Number of samples in train_dataloader: 100000\n</pre> <pre>Epoch 0 Training: 1533it [00:57, 26.72it/s, loss=3.74]</pre> <pre>Concord - INFO - Epoch   0 | Train Loss: 3.82, MSE: 0.01, CLASS: 0.00, CONTRAST: 3.81, IMPORTANCE: 0.00\nConcord - INFO - Starting epoch 2/5\nConcord - INFO - Processing chunk 1/1 for epoch 2\nConcord - INFO - Number of samples in train_dataloader: 100000\n</pre> <pre>\nEpoch 1 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1533/1533 [01:03&lt;00:00, 24.24it/s, loss=3.73]</pre> <pre>Concord - INFO - Epoch   1 | Train Loss: 3.66, MSE: 0.01, CLASS: 0.00, CONTRAST: 3.65, IMPORTANCE: 0.00\nConcord - INFO - Starting epoch 3/5\nConcord - INFO - Processing chunk 1/1 for epoch 3\nConcord - INFO - Number of samples in train_dataloader: 100000\n</pre> <pre>\nEpoch 2 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1533/1533 [00:56&lt;00:00, 27.32it/s, loss=3.69]</pre> <pre>Concord - INFO - Epoch   2 | Train Loss: 3.63, MSE: 0.01, CLASS: 0.00, CONTRAST: 3.62, IMPORTANCE: 0.00\nConcord - INFO - Starting epoch 4/5\nConcord - INFO - Processing chunk 1/1 for epoch 4\nConcord - INFO - Number of samples in train_dataloader: 100000\n</pre> <pre>\nEpoch 3 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1533/1533 [00:59&lt;00:00, 25.69it/s, loss=3.67]</pre> <pre>Concord - INFO - Epoch   3 | Train Loss: 3.61, MSE: 0.01, CLASS: 0.00, CONTRAST: 3.60, IMPORTANCE: 0.00\n</pre> <pre>\n</pre> <pre>Concord - INFO - Starting epoch 5/5\nConcord - INFO - Processing chunk 1/1 for epoch 5\nConcord - INFO - Number of samples in train_dataloader: 100000\n</pre> <pre>Epoch 4 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1533/1533 [00:52&lt;00:00, 29.00it/s, loss=3.53]</pre> <pre>Concord - INFO - Epoch   4 | Train Loss: 3.59, MSE: 0.01, CLASS: 0.00, CONTRAST: 3.58, IMPORTANCE: 0.00\n</pre> <pre>\n</pre> <pre>Concord - INFO - Model saved to save/final_model.pth\nConcord - INFO - Final model saved at: save/final_model.pth; Configuration saved at: save/config.json.\nConcord.model.dataloader - INFO - Preprocessing adata...\nConcord.utils.preprocessor - INFO - Data is already log1p transformed. Skip normalization.\nConcord.utils.preprocessor - INFO - Data is already log1p transformed. Storing in the specified layer.\nConcord.utils.preprocessor - INFO - Filtering features with provided list (10000 features)...\nConcord.model.anndataset - INFO - Initialized dataset with 100000 samples. Data structure: ['input', 'domain', 'idx']\nConcord - INFO - Predicting for chunk 1/1\n</pre> In\u00a0[69]: Copied! <pre>ccd.ul.run_umap(adata, source_key=output_key, umap_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.1, metric='euclidean', random_state=seed)\nshow_basis = f'{output_key}_UMAP'\nshow_cols = ['embryo_id', 'embryo_sex', 'development_stage', 'num_genes_expressed', 'Main_cell_type', 'Main_trajectory', 'Sub_trajectory_name', 'Sub_trajectory_Pseudotime', 'phase']\nccd.pl.plot_embedding(\n    adata, show_basis, show_cols, figsize=(13,11), dpi=600, ncols=3, font_size=5, point_size=.5, legend_loc='on data',\n    save_path=save_dir / f\"{show_basis}_{file_suffix}.png\"\n)\n</pre> ccd.ul.run_umap(adata, source_key=output_key, umap_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.1, metric='euclidean', random_state=seed) show_basis = f'{output_key}_UMAP' show_cols = ['embryo_id', 'embryo_sex', 'development_stage', 'num_genes_expressed', 'Main_cell_type', 'Main_trajectory', 'Sub_trajectory_name', 'Sub_trajectory_Pseudotime', 'phase'] ccd.pl.plot_embedding(     adata, show_basis, show_cols, figsize=(13,11), dpi=600, ncols=3, font_size=5, point_size=.5, legend_loc='on data',     save_path=save_dir / f\"{show_basis}_{file_suffix}.png\" ) <p>It is best to use 3D UMAP rather than 2D to visualize Concord latent, because 2D may not be enough to 'unpack' the complex structures learned by Concord, thus tends to break trajectories.</p> In\u00a0[70]: Copied! <pre>import plotly.io as pio\npio.renderers.default = 'notebook'\nccd.ul.run_umap(adata,  source_key=output_key, umap_key=f'{output_key}_UMAP_3D', n_components=3, n_neighbors=15, min_dist=0.1, metric='euclidean')\n\n# Plot the 3D UMAP embeddings\ncol = 'Main_cell_type'\nshow_basis = f'{output_key}_UMAP_3D'\nccd.pl.plot_embedding_3d(\n        adata, basis=show_basis, color_by=col,\n        save_path=save_dir / f'{show_basis}_{file_suffix}.html',\n        point_size=1, opacity=0.8, width=1500, height=1000\n    )\n</pre> import plotly.io as pio pio.renderers.default = 'notebook' ccd.ul.run_umap(adata,  source_key=output_key, umap_key=f'{output_key}_UMAP_3D', n_components=3, n_neighbors=15, min_dist=0.1, metric='euclidean')  # Plot the 3D UMAP embeddings col = 'Main_cell_type' show_basis = f'{output_key}_UMAP_3D' ccd.pl.plot_embedding_3d(         adata, basis=show_basis, color_by=col,         save_path=save_dir / f'{show_basis}_{file_suffix}.html',         point_size=1, opacity=0.8, width=1500, height=1000     ) <pre>Concord - INFO - UMAP embedding stored in adata.obsm['Concord_UMAP_3D']\nConcord - INFO - 3D plot saved to ../save/dev_concord_mouse_organogenesis_100k-Sep29/Concord_UMAP_3D_concord_mouse_organogenesis_100k_Sep29.html\n</pre> <p>Concord is able to learn both local and global structure. This means Concord have much higher resolution for each cell type in the dataset, and you can simply re-run UMAP on the global-learned latent of that cell type (without re-run Concord on that subset) to see the detailed structure for that cell type (which sometimes global UMAP cannot correctly embed). Here we demonstrate with two main trajectories: Mesenchymal trajectory and Neural tube and notochord trajectory.</p> <p>In practice, it is still recommended to subset and then run Concord because if you use variably expressed gene (VEG) selection for Concord input, it will further enrich for more cell sub-type specific genes/signals to enable even greater resolution within a cell type.</p> In\u00a0[84]: Copied! <pre>adata.obs['Main_trajectory'].value_counts()\n</pre> adata.obs['Main_trajectory'].value_counts() Out[84]: <pre>Main_trajectory\nMesenchymal trajectory                  43846\nNeural tube and notochord trajectory    41217\nEpithelial trajectory                    5144\nHaematopoiesis trajectory                3267\nEndothelial trajectory                   1918\nNeural crest 1                           1905\nNeural crest 2                           1676\nHepatocyte trajectory                     868\nNeural crest 3                            111\nLens trajectory                            48\nName: count, dtype: int64</pre> In\u00a0[\u00a0]: Copied! <pre>show_traj = 'Mesenchymal trajectory'\nadata_sub = adata[adata.obs['Main_trajectory'] == show_traj]\nccd.ul.run_umap(adata_sub, source_key=output_key, umap_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.1, metric='euclidean', random_state=seed)\nshow_basis = f'{output_key}_UMAP'\nshow_cols = ['embryo_id', 'embryo_sex', 'development_stage', 'num_genes_expressed', 'Main_cell_type', 'Main_trajectory', 'Sub_trajectory_name', 'Sub_trajectory_Pseudotime', 'phase']\nccd.pl.plot_embedding(\n    adata_sub, show_basis, show_cols, figsize=(13,11), dpi=600, ncols=3, font_size=5, point_size=1, legend_loc='on data',\n    save_path=save_dir / f\"{show_traj.replace(' ', '_')}_{show_basis}_{file_suffix}.png\"\n)\n# output cleared due to github file size limit\n</pre> show_traj = 'Mesenchymal trajectory' adata_sub = adata[adata.obs['Main_trajectory'] == show_traj] ccd.ul.run_umap(adata_sub, source_key=output_key, umap_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.1, metric='euclidean', random_state=seed) show_basis = f'{output_key}_UMAP' show_cols = ['embryo_id', 'embryo_sex', 'development_stage', 'num_genes_expressed', 'Main_cell_type', 'Main_trajectory', 'Sub_trajectory_name', 'Sub_trajectory_Pseudotime', 'phase'] ccd.pl.plot_embedding(     adata_sub, show_basis, show_cols, figsize=(13,11), dpi=600, ncols=3, font_size=5, point_size=1, legend_loc='on data',     save_path=save_dir / f\"{show_traj.replace(' ', '_')}_{show_basis}_{file_suffix}.png\" ) # output cleared due to github file size limit In\u00a0[103]: Copied! <pre>ccd.ul.run_umap(adata_sub,  source_key=output_key, umap_key=f'{output_key}_UMAP_3D', n_components=3, n_neighbors=15, min_dist=0.1, metric='euclidean')\n\n# Plot the 3D UMAP embeddings\ncol = 'Main_cell_type'\nshow_basis = f'{output_key}_UMAP_3D'\nccd.pl.plot_embedding_3d(\n        adata_sub, basis=show_basis, color_by=col,\n        save_path=save_dir / f\"{show_traj.replace(' ', '_')}_{show_basis}_{file_suffix}.html\",\n        point_size=1, opacity=0.8, width=1500, height=1000\n    )\n# output cleared due to github size limit\n</pre> ccd.ul.run_umap(adata_sub,  source_key=output_key, umap_key=f'{output_key}_UMAP_3D', n_components=3, n_neighbors=15, min_dist=0.1, metric='euclidean')  # Plot the 3D UMAP embeddings col = 'Main_cell_type' show_basis = f'{output_key}_UMAP_3D' ccd.pl.plot_embedding_3d(         adata_sub, basis=show_basis, color_by=col,         save_path=save_dir / f\"{show_traj.replace(' ', '_')}_{show_basis}_{file_suffix}.html\",         point_size=1, opacity=0.8, width=1500, height=1000     ) # output cleared due to github size limit In\u00a0[\u00a0]: Copied! <pre>show_traj = 'Neural tube and notochord trajectory'\nadata_sub = adata[adata.obs['Main_trajectory'] == show_traj]\nccd.ul.run_umap(adata_sub, source_key=output_key, umap_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.1, metric='euclidean', random_state=seed)\nshow_basis = f'{output_key}_UMAP'\nshow_cols = ['embryo_id', 'embryo_sex', 'development_stage', 'num_genes_expressed', 'Main_cell_type', 'Main_trajectory', 'Sub_trajectory_name', 'Sub_trajectory_Pseudotime', 'phase']\nccd.pl.plot_embedding(\n    adata_sub, show_basis, show_cols, figsize=(13,11), dpi=600, ncols=3, font_size=5, point_size=1, legend_loc='on data',\n    save_path=save_dir / f\"{show_traj.replace(' ', '_')}_{show_basis}_{file_suffix}.png\"\n)\n# output cleared due to github file size limit\n</pre> show_traj = 'Neural tube and notochord trajectory' adata_sub = adata[adata.obs['Main_trajectory'] == show_traj] ccd.ul.run_umap(adata_sub, source_key=output_key, umap_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.1, metric='euclidean', random_state=seed) show_basis = f'{output_key}_UMAP' show_cols = ['embryo_id', 'embryo_sex', 'development_stage', 'num_genes_expressed', 'Main_cell_type', 'Main_trajectory', 'Sub_trajectory_name', 'Sub_trajectory_Pseudotime', 'phase'] ccd.pl.plot_embedding(     adata_sub, show_basis, show_cols, figsize=(13,11), dpi=600, ncols=3, font_size=5, point_size=1, legend_loc='on data',     save_path=save_dir / f\"{show_traj.replace(' ', '_')}_{show_basis}_{file_suffix}.png\" ) # output cleared due to github file size limit In\u00a0[105]: Copied! <pre>ccd.ul.run_umap(adata_sub,  source_key=output_key, umap_key=f'{output_key}_UMAP_3D', n_components=3, n_neighbors=15, min_dist=0.1, metric='euclidean')\n\n# Plot the 3D UMAP embeddings\ncol = 'Main_cell_type'\nshow_basis = f'{output_key}_UMAP_3D'\nccd.pl.plot_embedding_3d(\n        adata_sub, basis=show_basis, color_by=col,\n        save_path=save_dir / f\"{show_traj.replace(' ', '_')}_{show_basis}_{file_suffix}.html\",\n        point_size=1, opacity=0.8, width=1500, height=1000\n    )\n</pre> ccd.ul.run_umap(adata_sub,  source_key=output_key, umap_key=f'{output_key}_UMAP_3D', n_components=3, n_neighbors=15, min_dist=0.1, metric='euclidean')  # Plot the 3D UMAP embeddings col = 'Main_cell_type' show_basis = f'{output_key}_UMAP_3D' ccd.pl.plot_embedding_3d(         adata_sub, basis=show_basis, color_by=col,         save_path=save_dir / f\"{show_traj.replace(' ', '_')}_{show_basis}_{file_suffix}.html\",         point_size=1, opacity=0.8, width=1500, height=1000     ) <p>Because the global CONCORD latent already captures a lot of details of each cell types and states, it is not necessary to run this zoom-in analysis (you can just re-run UMAP on CONCORD latent from global integration as above). However, more improvement may be achived through recalling VEG and running CONCORD on subset of cells.</p> In\u00a0[\u00a0]: Copied! <pre>feature_list = ccd.ul.select_features(adata_sub, n_top_features=10000, flavor='seurat_v3')\nsub_ccd = ccd.Concord(adata=adata_sub, \n                      input_feature=feature_list, \n                      domain_key='embryo_id', # \n                      latent_dim=100,\n                      encoder_dims=[1000],\n                      decoder_dims=[1000],\n                      clr_temperature = .5, # Check out advanced usage to learn what this parameter controls\n                      p_intra_domain=1.0, # Check out advanced usage to learn what this parameter controls\n                      seed=seed, \n                      inplace=False, \n                      verbose=False, \n                      device=device) \n\n# Encode data, saving the latent embedding in adata.obsm['Concord']\nsub_ccd.encode_adata(input_layer_key='X_log1p', output_key=output_key)\n\n# Save the latent embedding to a filem, so that it can be loaded later\nccd.ul.save_obsm_to_hdf5(sub_ccd.adata, save_dir / f\"obsm_{show_traj.replace(' ', '_')}_{file_suffix}.h5\")\nadata_sub.obsm = sub_ccd.adata.obsm # If not inplace\n</pre> feature_list = ccd.ul.select_features(adata_sub, n_top_features=10000, flavor='seurat_v3') sub_ccd = ccd.Concord(adata=adata_sub,                        input_feature=feature_list,                        domain_key='embryo_id', #                        latent_dim=100,                       encoder_dims=[1000],                       decoder_dims=[1000],                       clr_temperature = .5, # Check out advanced usage to learn what this parameter controls                       p_intra_domain=1.0, # Check out advanced usage to learn what this parameter controls                       seed=seed,                        inplace=False,                        verbose=False,                        device=device)   # Encode data, saving the latent embedding in adata.obsm['Concord'] sub_ccd.encode_adata(input_layer_key='X_log1p', output_key=output_key)  # Save the latent embedding to a filem, so that it can be loaded later ccd.ul.save_obsm_to_hdf5(sub_ccd.adata, save_dir / f\"obsm_{show_traj.replace(' ', '_')}_{file_suffix}.h5\") adata_sub.obsm = sub_ccd.adata.obsm # If not inplace <pre>Epoch 0 Training: 615it [00:23, 26.40it/s, loss=3.85]\nEpoch 1 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 615/615 [00:20&lt;00:00, 29.47it/s, loss=3.96]\nEpoch 2 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 615/615 [00:20&lt;00:00, 29.96it/s, loss=3.57]\nEpoch 3 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 615/615 [00:20&lt;00:00, 29.69it/s, loss=3.52]\nEpoch 4 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 615/615 [00:20&lt;00:00, 29.74it/s, loss=3.76]\n</pre> In\u00a0[99]: Copied! <pre>show_traj = 'Neural tube and notochord trajectory'\nccd.ul.run_umap(adata_sub, source_key=output_key, umap_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.1, metric='euclidean', random_state=seed)\nshow_basis = f'{output_key}_UMAP'\nshow_cols = ['embryo_id', 'embryo_sex', 'development_stage', 'num_genes_expressed', 'Main_cell_type', 'Main_trajectory', 'Sub_trajectory_name', 'Sub_trajectory_Pseudotime', 'phase']\nccd.pl.plot_embedding(\n    adata_sub, show_basis, show_cols, figsize=(13,11), dpi=600, ncols=3, font_size=5, point_size=1, legend_loc='on data',\n    save_path=save_dir / f\"{show_traj.replace(' ', '_')}_concord_zoom_{show_basis}_{file_suffix}.png\"\n)\n</pre> show_traj = 'Neural tube and notochord trajectory' ccd.ul.run_umap(adata_sub, source_key=output_key, umap_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.1, metric='euclidean', random_state=seed) show_basis = f'{output_key}_UMAP' show_cols = ['embryo_id', 'embryo_sex', 'development_stage', 'num_genes_expressed', 'Main_cell_type', 'Main_trajectory', 'Sub_trajectory_name', 'Sub_trajectory_Pseudotime', 'phase'] ccd.pl.plot_embedding(     adata_sub, show_basis, show_cols, figsize=(13,11), dpi=600, ncols=3, font_size=5, point_size=1, legend_loc='on data',     save_path=save_dir / f\"{show_traj.replace(' ', '_')}_concord_zoom_{show_basis}_{file_suffix}.png\" ) In\u00a0[100]: Copied! <pre>ccd.ul.run_umap(adata_sub,  source_key=output_key, umap_key=f'{output_key}_UMAP_3D', n_components=3, n_neighbors=30, min_dist=0.1, metric='euclidean')\n\n# Plot the 3D UMAP embeddings\ncol = 'Main_cell_type'\nshow_basis = f'{output_key}_UMAP_3D'\nccd.pl.plot_embedding_3d(\n        adata_sub, basis=show_basis, color_by=col,\n        save_path=save_dir / f\"{show_traj.replace(' ', '_')}_concord_zoom_{show_basis}_{file_suffix}.html\",\n        point_size=1, opacity=0.8, width=1500, height=1000\n    )\n</pre> ccd.ul.run_umap(adata_sub,  source_key=output_key, umap_key=f'{output_key}_UMAP_3D', n_components=3, n_neighbors=30, min_dist=0.1, metric='euclidean')  # Plot the 3D UMAP embeddings col = 'Main_cell_type' show_basis = f'{output_key}_UMAP_3D' ccd.pl.plot_embedding_3d(         adata_sub, basis=show_basis, color_by=col,         save_path=save_dir / f\"{show_traj.replace(' ', '_')}_concord_zoom_{show_basis}_{file_suffix}.html\",         point_size=1, opacity=0.8, width=1500, height=1000     ) In\u00a0[80]: Copied! <pre>obsm_filename = save_dir / f\"obsm_{file_suffix}.h5\"\nccd.ul.save_obsm_to_hdf5(adata, obsm_filename)\nadata.write_h5ad(f\"../data/mouse_organogenesis/{proj_name}_concord_{file_suffix}.h5ad\")\n</pre> obsm_filename = save_dir / f\"obsm_{file_suffix}.h5\" ccd.ul.save_obsm_to_hdf5(adata, obsm_filename) adata.write_h5ad(f\"../data/mouse_organogenesis/{proj_name}_concord_{file_suffix}.h5ad\") <p>You can optionally convert the result to VisCello (https://github.com/kimpenn/VisCello) for interactive exploration.</p> In\u00a0[83]: Copied! <pre>ccd.ul.anndata_to_viscello(adata, save_dir / f\"cello_{proj_name}_{file_suffix}\", project_name = proj_name, organism='mmu')\n</pre> ccd.ul.anndata_to_viscello(adata, save_dir / f\"cello_{proj_name}_{file_suffix}\", project_name = proj_name, organism='mmu') <pre>VisCello project created at ../save/dev_concord_mouse_organogenesis_100k-Sep29/cello_concord_mouse_organogenesis_100k_concord_mouse_organogenesis_100k_Sep29\n</pre>"},{"location":"notebooks/concord_mouse_organogenesis_100k/#mouse-organogenesis-100k-subset-for-tutorial","title":"Mouse organogenesis (100k subset for tutorial)\u00b6","text":""},{"location":"notebooks/concord_mouse_organogenesis_100k/#basic-setup","title":"Basic setup\u00b6","text":""},{"location":"notebooks/concord_mouse_organogenesis_100k/#original-umap","title":"Original UMAP\u00b6","text":""},{"location":"notebooks/concord_mouse_organogenesis_100k/#run-concord","title":"Run Concord\u00b6","text":""},{"location":"notebooks/concord_mouse_organogenesis_100k/#visualize-concord-latent-with-umap","title":"Visualize Concord latent with UMAP\u00b6","text":""},{"location":"notebooks/concord_mouse_organogenesis_100k/#2d-umap","title":"2D UMAP\u00b6","text":""},{"location":"notebooks/concord_mouse_organogenesis_100k/#3d-umap","title":"3D UMAP\u00b6","text":""},{"location":"notebooks/concord_mouse_organogenesis_100k/#zoom-in-to-sub-trajectories-without-rerunning-concord","title":"Zoom in to sub-trajectories without rerunning Concord\u00b6","text":""},{"location":"notebooks/concord_mouse_organogenesis_100k/#mesenchymal-trajectory-global-latent","title":"Mesenchymal trajectory (Global latent)\u00b6","text":""},{"location":"notebooks/concord_mouse_organogenesis_100k/#neural-tube-and-notochord-trajectory-global-latent","title":"Neural tube and notochord trajectory (Global latent)\u00b6","text":""},{"location":"notebooks/concord_mouse_organogenesis_100k/#neural-tube-and-notochord-trajectory-re-run-concord-on-subset","title":"Neural tube and notochord trajectory (Re-run Concord on subset)\u00b6","text":""},{"location":"notebooks/concord_mouse_organogenesis_100k/#save-the-result","title":"Save the result\u00b6","text":""},{"location":"notebooks/concord_pancreas_scanpy/","title":"Pancreas dataset from scanpy tutorial","text":"<p>From Scanpy: \"The following data has been used in the scGen paper [Lotfollahi et al., 2019], has been used here, was curated here and can be downloaded from here (the BBKNN paper).</p> <p>It contains data for human pancreas from 4 different studies [Baron et al., 2016, Muraro et al., 2016, Segerstolpe et al., 2016, Wang et al., 2016], which have been used in the seminal papers on single-cell dataset integration [Butler et al., 2018, Haghverdi et al., 2018] and many times ever since.\"</p> In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n</pre> %load_ext autoreload %autoreload 2 In\u00a0[2]: Copied! <pre>import Concord as ccd\nimport torch\nimport warnings\nimport scanpy as sc\nwarnings.filterwarnings('ignore')\n\nadata = sc.read(\"../data/scanpy_pancreas/pancreas.h5ad\", backup_url=\"https://www.dropbox.com/s/qj1jlm9w10wmt0u/pancreas.h5ad?dl=1\")\n</pre> import Concord as ccd import torch import warnings import scanpy as sc warnings.filterwarnings('ignore')  adata = sc.read(\"../data/scanpy_pancreas/pancreas.h5ad\", backup_url=\"https://www.dropbox.com/s/qj1jlm9w10wmt0u/pancreas.h5ad?dl=1\")  In\u00a0[3]: Copied! <pre>from pathlib import Path\nimport time\nproj_name = \"pancreas_scanpy\"\nsave_dir = Path(f\"../save/{proj_name}_{time.strftime('%b%d')}/\")\nsave_dir.mkdir(parents=True, exist_ok=True)\ndevice = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\nseed = 0\n</pre> from pathlib import Path import time proj_name = \"pancreas_scanpy\" save_dir = Path(f\"../save/{proj_name}_{time.strftime('%b%d')}/\") save_dir.mkdir(parents=True, exist_ok=True) device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu') seed = 0 In\u00a0[4]: Copied! <pre># adata.X is already scaled, but Concord expects non-negative values, either raw counts or log transformed counts are fine. \nadata = sc.AnnData(X=adata.raw.X, var=adata.raw.var, obs=adata.obs, obsm=adata.obsm, uns=adata.uns)\n</pre> # adata.X is already scaled, but Concord expects non-negative values, either raw counts or log transformed counts are fine.  adata = sc.AnnData(X=adata.raw.X, var=adata.raw.var, obs=adata.obs, obsm=adata.obsm, uns=adata.uns) In\u00a0[13]: Copied! <pre>sc.pp.highly_variable_genes(adata, n_top_genes=5000)  # Identify highly variable genes\nsc.pp.pca(adata)\nsc.pp.neighbors(adata, n_neighbors=30)  \nsc.tl.umap(adata, min_dist=0.1)\n</pre> sc.pp.highly_variable_genes(adata, n_top_genes=5000)  # Identify highly variable genes sc.pp.pca(adata) sc.pp.neighbors(adata, n_neighbors=30)   sc.tl.umap(adata, min_dist=0.1) In\u00a0[17]: Copied! <pre>show_basis = 'X_umap'\ncolor_by = [\"batch\", \"celltype\"]\nfile_suffix = f\"{proj_name}_{time.strftime('%b%d-%H%M')}\"\nccd.pl.plot_embedding(\n    adata, basis=show_basis, color_by=color_by, figsize=(8, 4), dpi=300, ncols=2, font_size=3, point_size=5, legend_loc='on data',\n    save_path=save_dir / f\"{show_basis}_{file_suffix}.png\"\n)\n</pre> show_basis = 'X_umap' color_by = [\"batch\", \"celltype\"] file_suffix = f\"{proj_name}_{time.strftime('%b%d-%H%M')}\" ccd.pl.plot_embedding(     adata, basis=show_basis, color_by=color_by, figsize=(8, 4), dpi=300, ncols=2, font_size=3, point_size=5, legend_loc='on data',     save_path=save_dir / f\"{show_basis}_{file_suffix}.png\" ) <p>Use <code>pip install bbknn</code> to install the package if not installed.</p> In\u00a0[7]: Copied! <pre># subset adata to variable genes\nadata_hvg = adata[:, adata.var.highly_variable]\nsc.external.pp.bbknn(adata_hvg, batch_key=\"batch\")\n</pre> # subset adata to variable genes adata_hvg = adata[:, adata.var.highly_variable] sc.external.pp.bbknn(adata_hvg, batch_key=\"batch\") <pre>WARNING: consider updating your call to make use of `computation`\n</pre> In\u00a0[8]: Copied! <pre>sc.tl.umap(adata_hvg, min_dist=0.1)\nshow_basis = 'X_umap'\ncolor_by = [\"batch\", \"celltype\"]\nccd.pl.plot_embedding(\n    adata_hvg, basis=show_basis, color_by=color_by, figsize=(8, 4), dpi=300, ncols=2, font_size=3, point_size=5, legend_loc='on data',\n    save_path=save_dir / f\"{show_basis}_{file_suffix}.png\"\n)\n</pre> sc.tl.umap(adata_hvg, min_dist=0.1) show_basis = 'X_umap' color_by = [\"batch\", \"celltype\"] ccd.pl.plot_embedding(     adata_hvg, basis=show_basis, color_by=color_by, figsize=(8, 4), dpi=300, ncols=2, font_size=3, point_size=5, legend_loc='on data',     save_path=save_dir / f\"{show_basis}_{file_suffix}.png\" ) In\u00a0[14]: Copied! <pre>feature_list = ccd.ul.select_features(adata, \n                                      n_top_features=5000, \n                                      flavor='seurat_v3', normalize=False, log1p=False)\n</pre> feature_list = ccd.ul.select_features(adata,                                        n_top_features=5000,                                        flavor='seurat_v3', normalize=False, log1p=False) In\u00a0[15]: Copied! <pre>cur_ccd = ccd.Concord(adata=adata, \n                      input_feature=feature_list, # top 10000 VEGs selected above\n                      domain_key='batch', # key indicating batch\n                      augmentation_mask_prob = 0.5, # augmentation mask probability, recommend between 0.1 and 0.7\n                      clr_temperature = 0.5, # temperature for NT-Xent loss\n                      seed=seed, # random seed\n                      p_intra_domain = 1.0, # probability of intra-domain sampling\n                      verbose=False, # print training progress\n                      inplace=False, # whether to modify original adata, set to False if you want to keep all expressions\n                      device=device # device to run on\n                      ) \n\n# Encode data, saving the latent embedding in adata.obsm['Concord']\nfile_suffix = f\"{proj_name}_{time.strftime('%b%d-%H%M')}\"\noutput_key = 'Concord'\ncur_ccd.encode_adata(input_layer_key='X_log1p', output_key=output_key)\n\nadata.obsm = cur_ccd.adata.obsm # If not inplace\n# Save the latent embedding to a file, so that it can be loaded later\nccd.ul.save_obsm_to_hdf5(cur_ccd.adata, save_dir / f\"obsm_{file_suffix}.h5\")\n</pre> cur_ccd = ccd.Concord(adata=adata,                        input_feature=feature_list, # top 10000 VEGs selected above                       domain_key='batch', # key indicating batch                       augmentation_mask_prob = 0.5, # augmentation mask probability, recommend between 0.1 and 0.7                       clr_temperature = 0.5, # temperature for NT-Xent loss                       seed=seed, # random seed                       p_intra_domain = 1.0, # probability of intra-domain sampling                       verbose=False, # print training progress                       inplace=False, # whether to modify original adata, set to False if you want to keep all expressions                       device=device # device to run on                       )   # Encode data, saving the latent embedding in adata.obsm['Concord'] file_suffix = f\"{proj_name}_{time.strftime('%b%d-%H%M')}\" output_key = 'Concord' cur_ccd.encode_adata(input_layer_key='X_log1p', output_key=output_key)  adata.obsm = cur_ccd.adata.obsm # If not inplace # Save the latent embedding to a file, so that it can be loaded later ccd.ul.save_obsm_to_hdf5(cur_ccd.adata, save_dir / f\"obsm_{file_suffix}.h5\") <pre>Epoch 0 Training: 227it [00:02, 86.19it/s, loss=4.35]\nEpoch 1 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 227/227 [00:02&lt;00:00, 85.47it/s, loss=5.72]\nEpoch 2 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 227/227 [00:02&lt;00:00, 84.74it/s, loss=3.95]\nEpoch 3 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 227/227 [00:02&lt;00:00, 80.81it/s, loss=3.75]\nEpoch 4 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 227/227 [00:02&lt;00:00, 85.29it/s, loss=3.78]\n</pre> In\u00a0[16]: Copied! <pre>ccd.ul.run_umap(adata, source_key=output_key, umap_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.1, metric='euclidean', random_state=seed)\nshow_basis = f'{output_key}_UMAP'\ncolor_by = [\"batch\", \"celltype\"]\nccd.pl.plot_embedding(\n    adata, basis=show_basis, color_by=color_by, figsize=(8, 4), dpi=300, ncols=2, font_size=3, point_size=5, legend_loc='on data',\n    save_path=save_dir / f\"{show_basis}_{file_suffix}.png\"\n)\n</pre> ccd.ul.run_umap(adata, source_key=output_key, umap_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.1, metric='euclidean', random_state=seed) show_basis = f'{output_key}_UMAP' color_by = [\"batch\", \"celltype\"] ccd.pl.plot_embedding(     adata, basis=show_basis, color_by=color_by, figsize=(8, 4), dpi=300, ncols=2, font_size=3, point_size=5, legend_loc='on data',     save_path=save_dir / f\"{show_basis}_{file_suffix}.png\" ) <p>It is best to use 3D UMAP rather than 2D to visualize Concord latent, because 2D may not be enough to 'unpack' the complex structures learned by Concord, thus tends to break trajectories.</p> In\u00a0[18]: Copied! <pre>import plotly.io as pio\npio.renderers.default = 'notebook'\nccd.ul.run_umap(adata,  source_key=output_key, umap_key=f'{output_key}_UMAP_3D', n_components=3, n_neighbors=15, min_dist=0.1, metric='euclidean')\nshow_basis = f'{output_key}_UMAP_3D'\n#show_cols = ['log_nFeature', 'stage_numeric', 'group', 'cell_state', 'cell_type']\nshow_col = 'batch'\nccd.pl.plot_embedding_3d(\n    adata, basis=show_basis, color_by=show_col,\n    save_path=save_dir / f'{output_key}_UMAP_3D_{file_suffix}.html',\n    point_size=1, opacity=0.8, width=1500, height=1000\n)\n</pre> import plotly.io as pio pio.renderers.default = 'notebook' ccd.ul.run_umap(adata,  source_key=output_key, umap_key=f'{output_key}_UMAP_3D', n_components=3, n_neighbors=15, min_dist=0.1, metric='euclidean') show_basis = f'{output_key}_UMAP_3D' #show_cols = ['log_nFeature', 'stage_numeric', 'group', 'cell_state', 'cell_type'] show_col = 'batch' ccd.pl.plot_embedding_3d(     adata, basis=show_basis, color_by=show_col,     save_path=save_dir / f'{output_key}_UMAP_3D_{file_suffix}.html',     point_size=1, opacity=0.8, width=1500, height=1000 ) In\u00a0[19]: Copied! <pre>show_col = 'celltype'\nccd.pl.plot_embedding_3d(\n    adata, basis=show_basis, color_by=show_col,\n    save_path=save_dir / f'{output_key}_UMAP_3D_{file_suffix}.html',\n    point_size=1, opacity=0.8, width=1500, height=1000\n)\n</pre> show_col = 'celltype' ccd.pl.plot_embedding_3d(     adata, basis=show_basis, color_by=show_col,     save_path=save_dir / f'{output_key}_UMAP_3D_{file_suffix}.html',     point_size=1, opacity=0.8, width=1500, height=1000 ) In\u00a0[20]: Copied! <pre>from Concord.utils.doublet_utils import generate_synthetic_doublets\nadata_wt_syndoub = generate_synthetic_doublets(adata, doublet_synth_ratio=0.2, seed=seed, batch_key='batch', droplet_type_key = 'droplet_label', \n                                               mean=0.5, var=0.1, clip_range=(0.2, 0.8), combine_with_original=True, plot_histogram=True)\n</pre> from Concord.utils.doublet_utils import generate_synthetic_doublets adata_wt_syndoub = generate_synthetic_doublets(adata, doublet_synth_ratio=0.2, seed=seed, batch_key='batch', droplet_type_key = 'droplet_label',                                                 mean=0.5, var=0.1, clip_range=(0.2, 0.8), combine_with_original=True, plot_histogram=True) In\u00a0[21]: Copied! <pre>adata_wt_syndoub.obs['droplet_label'].value_counts()\n</pre> adata_wt_syndoub.obs['droplet_label'].value_counts() Out[21]: <pre>droplet_label\nsinglet    14693\ndoublet     2937\nName: count, dtype: int64</pre> In\u00a0[22]: Copied! <pre>cur_ccd = ccd.Concord(adata=adata_wt_syndoub, \n                      input_feature=feature_list, # top VEGs selected above\n                      domain_key='batch', # key indicating batch\n                      augmentation_mask_prob = 0.5, # augmentation mask probability, recommend between 0.1 and 0.7\n                      seed=seed, # random seed\n                      p_intra_domain = 1.0, # probability of intra-domain sampling\n                      verbose=True, # print training progress\n                      device=device, # device to run on\n                      inplace=False, # whether to modify original adata, set to False if you want to keep all expressions, set to True if you want to save memory\n                      # New doublet arguments\n                      train_frac = 0.9, # fraction of data to use for training\n                      use_classifier = True, # use classifier for doublet detection\n                      class_key = 'droplet_label', # key indicating if a cell is a doublet\n                      ) \n\nfile_suffix = f\"{proj_name}_wt_syndoub_{time.strftime('%b%d-%H%M')}\"\noutput_key = 'Concord_wt_syndoub'\ncur_ccd.encode_adata(input_layer_key='X_log1p', output_key=output_key)\n\n# Save the latent embedding to a file, so that it can be loaded later/\nccd.ul.save_obsm_to_hdf5(cur_ccd.adata, save_dir / f\"obsm_{file_suffix}.h5\")\n</pre> cur_ccd = ccd.Concord(adata=adata_wt_syndoub,                        input_feature=feature_list, # top VEGs selected above                       domain_key='batch', # key indicating batch                       augmentation_mask_prob = 0.5, # augmentation mask probability, recommend between 0.1 and 0.7                       seed=seed, # random seed                       p_intra_domain = 1.0, # probability of intra-domain sampling                       verbose=True, # print training progress                       device=device, # device to run on                       inplace=False, # whether to modify original adata, set to False if you want to keep all expressions, set to True if you want to save memory                       # New doublet arguments                       train_frac = 0.9, # fraction of data to use for training                       use_classifier = True, # use classifier for doublet detection                       class_key = 'droplet_label', # key indicating if a cell is a doublet                       )   file_suffix = f\"{proj_name}_wt_syndoub_{time.strftime('%b%d-%H%M')}\" output_key = 'Concord_wt_syndoub' cur_ccd.encode_adata(input_layer_key='X_log1p', output_key=output_key)  # Save the latent embedding to a file, so that it can be loaded later/ ccd.ul.save_obsm_to_hdf5(cur_ccd.adata, save_dir / f\"obsm_{file_suffix}.h5\") <pre>Concord - INFO - Setting sampler_knn to 352 to be 1/50 the number of cells in the dataset. You can change this value by setting sampler_knn in the configuration.\nConcord - INFO - Column 'batch' is now of type: category\nConcord - INFO - Column 'droplet_label' is now of type: category\nConcord - INFO - Encoder input dim: 5000\nConcord - INFO - Decoder input dim: 40\nConcord - INFO - Classifier input dim: 32\nConcord - INFO - Model loaded to device: cuda:2\nConcord - INFO - Total number of parameters: 1296298\nConcord.model.dataloader - INFO - Preprocessing adata...\nConcord.utils.preprocessor - INFO - Data is already log1p transformed. Skip normalization.\nConcord.utils.preprocessor - INFO - Data is already log1p transformed. Storing in the specified layer.\nConcord.utils.preprocessor - INFO - Filtering features with provided list (5000 features)...\nConcord.model.anndataset - INFO - Initialized dataset with 17630 samples. Data structure: ['input', 'domain', 'class', 'idx']\nConcord.model.dataloader - INFO - PCA embedding not found in adata.obsm. Running PCA...\nConcord.model.dataloader - INFO - PCA completed.\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss IVF index. nprobe=10\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.dataloader - INFO - Number of unique_domains: 4\nConcord.model.dataloader - INFO - Final p_intra_domain values: 0: 1.00, 1: 1.00, 2: 1.00, 3: 1.00\nConcord.model.anndataset - INFO - Initialized dataset with 15867 samples. Data structure: ['input', 'domain', 'class', 'idx']\nConcord.model.anndataset - INFO - Initialized dataset with 1763 samples. Data structure: ['input', 'domain', 'class', 'idx']\nConcord - INFO - Starting epoch 1/5\nConcord - INFO - Processing chunk 1/1 for epoch 1\nConcord - INFO - Number of samples in train_dataloader: 15867\nConcord - INFO - Number of samples in val_dataloader: 1763\n</pre> <pre>Epoch 0 Training: 273it [00:03, 75.94it/s, loss=4.27]</pre> <pre>Concord - INFO - Epoch   0 | Train Loss: 4.80, MSE: 0.37, CLASS: 0.44, CONTRAST: 4.00, IMPORTANCE: 0.00\n</pre> <pre>\n</pre> <pre>Concord - INFO - Epoch:   0 | Train accuracy:  0.83 | precision: 0: 0.64, 1: 0.84 | recall: 0: 0.11, 1: 0.99 | f1: 0: 0.18, 1: 0.91\n</pre> <pre>Epoch 0 Validation: 242it [00:01, 134.58it/s, loss=1.39] </pre> <pre>Concord - INFO - Epoch   0 | Val Loss: 1.84, MSE: 0.16, CLASS: 0.30, CONTRAST: 1.38, IMPORTANCE: 0.00\n</pre> <pre>\n</pre> <pre>Concord - INFO - Epoch:   0 | Val accuracy:  0.88 | precision: 0: 0.82, 1: 0.88 | recall: 0: 0.32, 1: 0.99 | f1: 0: 0.46, 1: 0.93\nConcord - INFO - New best model found at epoch 1 with validation loss: 1.8390\nConcord - INFO - Starting epoch 2/5\nConcord - INFO - Processing chunk 1/1 for epoch 2\nConcord - INFO - Number of samples in train_dataloader: 15867\nConcord - INFO - Number of samples in val_dataloader: 1763\n</pre> <pre>Epoch 1 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 273/273 [00:03&lt;00:00, 80.39it/s, loss=4.64]</pre> <pre>Concord - INFO - Epoch   1 | Train Loss: 4.37, MSE: 0.21, CLASS: 0.37, CONTRAST: 3.79, IMPORTANCE: 0.00\n</pre> <pre>\n</pre> <pre>Concord - INFO - Epoch:   1 | Train accuracy:  0.86 | precision: 0: 0.73, 1: 0.87 | recall: 0: 0.30, 1: 0.98 | f1: 0: 0.43, 1: 0.92\n</pre> <pre>Epoch 1 Validation:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 241/273 [00:01&lt;00:00, 167.33it/s, loss=1.79] </pre> <pre>Concord - INFO - Epoch   1 | Val Loss: 1.64, MSE: 0.14, CLASS: 0.28, CONTRAST: 1.22, IMPORTANCE: 0.00\n</pre> <pre>\n</pre> <pre>Concord - INFO - Epoch:   1 | Val accuracy:  0.88 | precision: 0: 0.76, 1: 0.89 | recall: 0: 0.41, 1: 0.97 | f1: 0: 0.54, 1: 0.93\nConcord - INFO - New best model found at epoch 2 with validation loss: 1.6441\nConcord - INFO - Starting epoch 3/5\nConcord - INFO - Processing chunk 1/1 for epoch 3\nConcord - INFO - Number of samples in train_dataloader: 15867\nConcord - INFO - Number of samples in val_dataloader: 1763\n</pre> <pre>Epoch 2 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 273/273 [00:03&lt;00:00, 72.75it/s, loss=4.24]</pre> <pre>Concord - INFO - Epoch   2 | Train Loss: 4.24, MSE: 0.18, CLASS: 0.35, CONTRAST: 3.71, IMPORTANCE: 0.00\n</pre> <pre>\n</pre> <pre>Concord - INFO - Epoch:   2 | Train accuracy:  0.87 | precision: 0: 0.76, 1: 0.88 | recall: 0: 0.39, 1: 0.97 | f1: 0: 0.51, 1: 0.92\n</pre> <pre>Epoch 2 Validation:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 239/273 [00:01&lt;00:00, 155.66it/s, loss=1.38] </pre> <pre>Concord - INFO - Epoch   2 | Val Loss: 1.56, MSE: 0.12, CLASS: 0.26, CONTRAST: 1.18, IMPORTANCE: 0.00\n</pre> <pre>\n</pre> <pre>Concord - INFO - Epoch:   2 | Val accuracy:  0.89 | precision: 0: 0.81, 1: 0.89 | recall: 0: 0.43, 1: 0.98 | f1: 0: 0.56, 1: 0.94\nConcord - INFO - New best model found at epoch 3 with validation loss: 1.5638\nConcord - INFO - Starting epoch 4/5\nConcord - INFO - Processing chunk 1/1 for epoch 4\nConcord - INFO - Number of samples in train_dataloader: 15867\nConcord - INFO - Number of samples in val_dataloader: 1763\n</pre> <pre>Epoch 3 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 273/273 [00:03&lt;00:00, 74.27it/s, loss=4]   </pre> <pre>Concord - INFO - Epoch   3 | Train Loss: 4.16, MSE: 0.17, CLASS: 0.34, CONTRAST: 3.66, IMPORTANCE: 0.00\n</pre> <pre>\n</pre> <pre>Concord - INFO - Epoch:   3 | Train accuracy:  0.88 | precision: 0: 0.77, 1: 0.89 | recall: 0: 0.41, 1: 0.97 | f1: 0: 0.54, 1: 0.93\n</pre> <pre>Epoch 3 Validation:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 240/273 [00:01&lt;00:00, 150.97it/s, loss=1.16] </pre> <pre>Concord - INFO - Epoch   3 | Val Loss: 1.54, MSE: 0.12, CLASS: 0.26, CONTRAST: 1.16, IMPORTANCE: 0.00\n</pre> <pre>\n</pre> <pre>Concord - INFO - Epoch:   3 | Val accuracy:  0.90 | precision: 0: 0.85, 1: 0.90 | recall: 0: 0.48, 1: 0.98 | f1: 0: 0.61, 1: 0.94\nConcord - INFO - New best model found at epoch 4 with validation loss: 1.5438\nConcord - INFO - Starting epoch 5/5\nConcord - INFO - Processing chunk 1/1 for epoch 5\nConcord - INFO - Number of samples in train_dataloader: 15867\nConcord - INFO - Number of samples in val_dataloader: 1763\n</pre> <pre>Epoch 4 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 273/273 [00:03&lt;00:00, 72.97it/s, loss=3.94]</pre> <pre>Concord - INFO - Epoch   4 | Train Loss: 4.11, MSE: 0.16, CLASS: 0.33, CONTRAST: 3.63, IMPORTANCE: 0.00\n</pre> <pre>\n</pre> <pre>Concord - INFO - Epoch:   4 | Train accuracy:  0.88 | precision: 0: 0.76, 1: 0.89 | recall: 0: 0.43, 1: 0.97 | f1: 0: 0.55, 1: 0.93\n</pre> <pre>Epoch 4 Validation:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 236/273 [00:01&lt;00:00, 161.66it/s, loss=1.7]  </pre> <pre>Concord - INFO - Epoch   4 | Val Loss: 1.52, MSE: 0.11, CLASS: 0.27, CONTRAST: 1.13, IMPORTANCE: 0.00\n</pre> <pre>\n</pre> <pre>Concord - INFO - Epoch:   4 | Val accuracy:  0.89 | precision: 0: 0.86, 1: 0.89 | recall: 0: 0.48, 1: 0.98 | f1: 0: 0.61, 1: 0.93\nConcord - INFO - New best model found at epoch 5 with validation loss: 1.5152\nConcord - INFO - Best model state loaded into the model before final save.\nConcord - INFO - Model saved to save/final_model.pth\nConcord - INFO - Final model saved at: save/final_model.pth; Configuration saved at: save/config.json.\nConcord.model.dataloader - INFO - Preprocessing adata...\nConcord.utils.preprocessor - INFO - Data is already log1p transformed. Skip normalization.\nConcord.utils.preprocessor - INFO - Data is already log1p transformed. Storing in the specified layer.\nConcord.utils.preprocessor - INFO - Filtering features with provided list (5000 features)...\nConcord.model.anndataset - INFO - Initialized dataset with 17630 samples. Data structure: ['input', 'domain', 'class', 'idx']\nConcord - INFO - Predicting for chunk 1/1\n</pre> In\u00a0[23]: Copied! <pre>adata_wt_syndoub.obsm = cur_ccd.adata.obsm # If not inplace\nadata_wt_syndoub.obs = cur_ccd.adata.obs # If not inplace\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ncrosstab_result = pd.crosstab(adata_wt_syndoub.obs[f'{output_key}_class_pred'], adata_wt_syndoub.obs[f'{output_key}_class_true'])\nprint(crosstab_result)\n\n# Plot confusion matrix as heatmap\nplt.figure(figsize=(4,2))\nsns.heatmap(crosstab_result, annot=True, fmt=\"d\", cmap=\"Blues\")\nplt.xlabel(\"True\")\nplt.ylabel(\"Predicted\")\nplt.title(\"Confusion Matrix\")\n</pre> adata_wt_syndoub.obsm = cur_ccd.adata.obsm # If not inplace adata_wt_syndoub.obs = cur_ccd.adata.obs # If not inplace import pandas as pd import seaborn as sns import matplotlib.pyplot as plt crosstab_result = pd.crosstab(adata_wt_syndoub.obs[f'{output_key}_class_pred'], adata_wt_syndoub.obs[f'{output_key}_class_true']) print(crosstab_result)  # Plot confusion matrix as heatmap plt.figure(figsize=(4,2)) sns.heatmap(crosstab_result, annot=True, fmt=\"d\", cmap=\"Blues\") plt.xlabel(\"True\") plt.ylabel(\"Predicted\") plt.title(\"Confusion Matrix\") <pre>Concord_wt_syndoub_class_true  doublet  singlet\nConcord_wt_syndoub_class_pred                  \ndoublet                           1473      286\nsinglet                           1464    14407\n</pre> Out[23]: <pre>Text(0.5, 1.0, 'Confusion Matrix')</pre> In\u00a0[28]: Copied! <pre>adata_wt_syndoub.obs\n</pre> adata_wt_syndoub.obs Out[28]: celltype sample n_genes batch n_counts louvain droplet_label Concord_wt_syndoub_class_true Concord_wt_syndoub_class_pred class_prob_doublet class_prob_singlet human1_lib1.final_cell_0001-0 acinar Baron 3526.0 0 22411.0 2 singlet singlet singlet 0.045450 0.954550 human1_lib1.final_cell_0002-0 acinar Baron 4201.0 0 27949.0 2 singlet singlet singlet 0.059101 0.940899 human1_lib1.final_cell_0003-0 acinar Baron 2119.0 0 16892.0 2 singlet singlet singlet 0.031126 0.968874 human1_lib1.final_cell_0004-0 acinar Baron 2956.0 0 19299.0 2 singlet singlet singlet 0.055361 0.944639 human1_lib1.final_cell_0005-0 acinar Baron 2715.0 0 15067.0 2 singlet singlet singlet 0.043646 0.956354 ... ... ... ... ... ... ... ... ... ... ... ... 2932 NaN NaN NaN 3 NaN NaN doublet doublet singlet 0.072913 0.927087 2933 NaN NaN NaN 3 NaN NaN doublet doublet singlet 0.135804 0.864196 2934 NaN NaN NaN 3 NaN NaN doublet doublet singlet 0.461214 0.538786 2935 NaN NaN NaN 3 NaN NaN doublet doublet singlet 0.071255 0.928745 2936 NaN NaN NaN 3 NaN NaN doublet doublet singlet 0.085542 0.914458 <p>17630 rows \u00d7 11 columns</p> In\u00a0[30]: Copied! <pre>ccd.ul.run_umap(adata_wt_syndoub, source_key=output_key, umap_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.1, metric='euclidean', random_state=seed)\nshow_basis = f'{output_key}_UMAP'\ncolor_by = [\"batch\", \"celltype\", f'{output_key}_class_pred', f'{output_key}_class_true', f'class_prob_doublet']\nccd.pl.plot_embedding(\n    adata_wt_syndoub, basis=show_basis, color_by=color_by, figsize=(8, 5), dpi=300, ncols=3, font_size=3, point_size=5, legend_loc='on data',\n    save_path=save_dir / f\"{show_basis}_{file_suffix}.png\"\n)\n</pre> ccd.ul.run_umap(adata_wt_syndoub, source_key=output_key, umap_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.1, metric='euclidean', random_state=seed) show_basis = f'{output_key}_UMAP' color_by = [\"batch\", \"celltype\", f'{output_key}_class_pred', f'{output_key}_class_true', f'class_prob_doublet'] ccd.pl.plot_embedding(     adata_wt_syndoub, basis=show_basis, color_by=color_by, figsize=(8, 5), dpi=300, ncols=3, font_size=3, point_size=5, legend_loc='on data',     save_path=save_dir / f\"{show_basis}_{file_suffix}.png\" ) In\u00a0[31]: Copied! <pre>adata = adata_wt_syndoub[(adata_wt_syndoub.obs['droplet_label'] == 'singlet') &amp; (adata_wt_syndoub.obs['Concord_wt_syndoub_class_pred'] == 'singlet')]\nprint(adata.shape)\n</pre> adata = adata_wt_syndoub[(adata_wt_syndoub.obs['droplet_label'] == 'singlet') &amp; (adata_wt_syndoub.obs['Concord_wt_syndoub_class_pred'] == 'singlet')] print(adata.shape) <pre>(14407, 24516)\n</pre> In\u00a0[32]: Copied! <pre>cur_ccd = ccd.Concord(adata=adata, \n                      input_feature=feature_list, # top VEGs selected above\n                      domain_key='batch', # key indicating batch\n                      augmentation_mask_prob = 0.5, # augmentation mask probability, recommend between 0.1 and 0.7\n                      seed=seed, # random seed\n                      p_intra_domain = 1.0, # probability of intra-domain sampling\n                      verbose=True, # print training progress\n                      inplace=False, # whether to modify original adata, set to False if you want to keep all expressions, True if you want to save memory\n                      device=device # device to run on\n                      ) \n\n# Encode data, saving the latent embedding in adata.obsm['Concord']\nfile_suffix = f\"{proj_name}_{time.strftime('%b%d-%H%M')}\"\noutput_key = 'Concord'\ncur_ccd.encode_adata(input_layer_key='X_log1p', output_key=output_key)\n\n# Save the latent embedding to a file, so that it can be loaded later\nccd.ul.save_obsm_to_hdf5(cur_ccd.adata, save_dir / f\"obsm_{file_suffix}.h5\")\n</pre> cur_ccd = ccd.Concord(adata=adata,                        input_feature=feature_list, # top VEGs selected above                       domain_key='batch', # key indicating batch                       augmentation_mask_prob = 0.5, # augmentation mask probability, recommend between 0.1 and 0.7                       seed=seed, # random seed                       p_intra_domain = 1.0, # probability of intra-domain sampling                       verbose=True, # print training progress                       inplace=False, # whether to modify original adata, set to False if you want to keep all expressions, True if you want to save memory                       device=device # device to run on                       )   # Encode data, saving the latent embedding in adata.obsm['Concord'] file_suffix = f\"{proj_name}_{time.strftime('%b%d-%H%M')}\" output_key = 'Concord' cur_ccd.encode_adata(input_layer_key='X_log1p', output_key=output_key)  # Save the latent embedding to a file, so that it can be loaded later ccd.ul.save_obsm_to_hdf5(cur_ccd.adata, save_dir / f\"obsm_{file_suffix}.h5\") <pre>Concord - INFO - Setting sampler_knn to 288 to be 1/50 the number of cells in the dataset. You can change this value by setting sampler_knn in the configuration.\nConcord - INFO - Column 'batch' is already of type: category\nConcord - INFO - Unused levels dropped for column 'batch'.\nConcord - INFO - Encoder input dim: 5000\nConcord - INFO - Decoder input dim: 40\nConcord - INFO - Model loaded to device: cuda:2\nConcord - INFO - Total number of parameters: 1295112\nConcord.model.dataloader - INFO - Preprocessing adata...\nConcord.utils.preprocessor - INFO - Data is already log1p transformed. Skip normalization.\nConcord.utils.preprocessor - INFO - Data is already log1p transformed. Storing in the specified layer.\nConcord.utils.preprocessor - INFO - Filtering features with provided list (5000 features)...\nConcord.model.anndataset - INFO - Initialized dataset with 14407 samples. Data structure: ['input', 'domain', 'idx']\nConcord.model.dataloader - INFO - Using existing embedding 'X_pca' from adata.obsm\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.knn - INFO - Building Faiss IVF index. nprobe=10\nConcord.model.knn - INFO - Using FAISS CPU index.\nConcord.model.dataloader - INFO - Number of unique_domains: 4\nConcord.model.dataloader - INFO - Final p_intra_domain values: 0: 1.00, 1: 1.00, 2: 1.00, 3: 1.00\nConcord - INFO - Starting epoch 1/5\nConcord - INFO - Processing chunk 1/1 for epoch 1\nConcord - INFO - Number of samples in train_dataloader: 14407\n</pre> <pre>Epoch 0 Training: 223it [00:02, 78.84it/s, loss=3.92]</pre> <pre>Concord - INFO - Epoch   0 | Train Loss: 4.47, MSE: 0.41, CLASS: 0.00, CONTRAST: 4.06, IMPORTANCE: 0.00\nConcord - INFO - Starting epoch 2/5\n</pre> <pre>\n</pre> <pre>Concord - INFO - Processing chunk 1/1 for epoch 2\nConcord - INFO - Number of samples in train_dataloader: 14407\n</pre> <pre>Epoch 1 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 223/223 [00:02&lt;00:00, 74.70it/s, loss=3.92]</pre> <pre>Concord - INFO - Epoch   1 | Train Loss: 4.11, MSE: 0.23, CLASS: 0.00, CONTRAST: 3.88, IMPORTANCE: 0.00\nConcord - INFO - Starting epoch 3/5\nConcord - INFO - Processing chunk 1/1 for epoch 3\n</pre> <pre>\n</pre> <pre>Concord - INFO - Number of samples in train_dataloader: 14407\n</pre> <pre>Epoch 2 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 223/223 [00:02&lt;00:00, 80.12it/s, loss=3.94]</pre> <pre>Concord - INFO - Epoch   2 | Train Loss: 3.99, MSE: 0.19, CLASS: 0.00, CONTRAST: 3.80, IMPORTANCE: 0.00\n</pre> <pre>\n</pre> <pre>Concord - INFO - Starting epoch 4/5\nConcord - INFO - Processing chunk 1/1 for epoch 4\nConcord - INFO - Number of samples in train_dataloader: 14407\n</pre> <pre>Epoch 3 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 223/223 [00:02&lt;00:00, 80.23it/s, loss=3.68]</pre> <pre>Concord - INFO - Epoch   3 | Train Loss: 3.92, MSE: 0.18, CLASS: 0.00, CONTRAST: 3.74, IMPORTANCE: 0.00\n</pre> <pre>\n</pre> <pre>Concord - INFO - Starting epoch 5/5\nConcord - INFO - Processing chunk 1/1 for epoch 5\nConcord - INFO - Number of samples in train_dataloader: 14407\n</pre> <pre>Epoch 4 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 223/223 [00:02&lt;00:00, 81.88it/s, loss=3.69]</pre> <pre>Concord - INFO - Epoch   4 | Train Loss: 3.88, MSE: 0.17, CLASS: 0.00, CONTRAST: 3.71, IMPORTANCE: 0.00\n</pre> <pre>\n</pre> <pre>Concord - INFO - Model saved to save/final_model.pth\nConcord - INFO - Final model saved at: save/final_model.pth; Configuration saved at: save/config.json.\nConcord.model.dataloader - INFO - Preprocessing adata...\nConcord.utils.preprocessor - INFO - Data is already log1p transformed. Skip normalization.\nConcord.utils.preprocessor - INFO - Data is already log1p transformed. Storing in the specified layer.\nConcord.utils.preprocessor - INFO - Filtering features with provided list (5000 features)...\nConcord.model.anndataset - INFO - Initialized dataset with 14407 samples. Data structure: ['input', 'domain', 'idx']\nConcord - INFO - Predicting for chunk 1/1\n</pre> In\u00a0[33]: Copied! <pre>adata.obsm = cur_ccd.adata.obsm # If not inplace\nccd.ul.run_umap(adata, source_key=output_key, umap_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.1, metric='euclidean', random_state=seed)\nshow_basis = f'{output_key}_UMAP'\ncolor_by = [\"batch\", \"celltype\"]\nccd.pl.plot_embedding(\n    adata, basis=show_basis, color_by=color_by, figsize=(8, 4), dpi=300, ncols=2, font_size=3, point_size=5, legend_loc='on data',\n    save_path=save_dir / f\"{show_basis}_{file_suffix}.png\"\n)\n</pre> adata.obsm = cur_ccd.adata.obsm # If not inplace ccd.ul.run_umap(adata, source_key=output_key, umap_key=f'{output_key}_UMAP', n_components=2, n_neighbors=30, min_dist=0.1, metric='euclidean', random_state=seed) show_basis = f'{output_key}_UMAP' color_by = [\"batch\", \"celltype\"] ccd.pl.plot_embedding(     adata, basis=show_basis, color_by=color_by, figsize=(8, 4), dpi=300, ncols=2, font_size=3, point_size=5, legend_loc='on data',     save_path=save_dir / f\"{show_basis}_{file_suffix}.png\" ) <pre>Concord - INFO - UMAP embedding stored in adata.obsm['Concord_UMAP']\n</pre> In\u00a0[36]: Copied! <pre>obsm_filename = save_dir / f\"obsm_{file_suffix}.h5\"\nccd.ul.save_obsm_to_hdf5(adata, obsm_filename)\nadata.write_h5ad(f\"{save_dir}/{proj_name}_{file_suffix}.h5ad\")\n</pre> obsm_filename = save_dir / f\"obsm_{file_suffix}.h5\" ccd.ul.save_obsm_to_hdf5(adata, obsm_filename) adata.write_h5ad(f\"{save_dir}/{proj_name}_{file_suffix}.h5ad\") <p>You can optionally convert the result to VisCello (https://github.com/kimpenn/VisCello) for interactive exploration.</p> In\u00a0[69]: Copied! <pre>ccd.ul.anndata_to_viscello(adata, f'{save_dir}/cello_{proj_name}_{file_suffix}', project_name = proj_name, organism='dre')\n</pre> ccd.ul.anndata_to_viscello(adata, f'{save_dir}/cello_{proj_name}_{file_suffix}', project_name = proj_name, organism='dre') <pre>R was initialized outside of rpy2 (R_NilValue != NULL). Trying to use it nevertheless.\n</pre> <pre>VisCello project created at ../data/fish_tome//cello_concord_zebrafish_embryogenesis_concord_zebrafish_embryogenesis_Concordant_Oct03-1733\n</pre>"},{"location":"notebooks/concord_pancreas_scanpy/#pancreas-dataset-from-scanpy-tutorial","title":"Pancreas dataset from scanpy tutorial\u00b6","text":""},{"location":"notebooks/concord_pancreas_scanpy/#basic-setup","title":"Basic setup\u00b6","text":""},{"location":"notebooks/concord_pancreas_scanpy/#pca-umap","title":"PCA + UMAP\u00b6","text":""},{"location":"notebooks/concord_pancreas_scanpy/#bbknn-used-by-scanpy-tutorial","title":"BBKNN used by scanpy tutorial\u00b6","text":""},{"location":"notebooks/concord_pancreas_scanpy/#run-concord","title":"Run Concord\u00b6","text":""},{"location":"notebooks/concord_pancreas_scanpy/#visualize-concord-latent-with-umap","title":"Visualize Concord latent with UMAP\u00b6","text":""},{"location":"notebooks/concord_pancreas_scanpy/#2d-umap","title":"2D UMAP\u00b6","text":""},{"location":"notebooks/concord_pancreas_scanpy/#3d-umap","title":"3D UMAP\u00b6","text":""},{"location":"notebooks/concord_pancreas_scanpy/#doublet-calling-with-concord-optional","title":"Doublet calling with Concord (Optional)\u00b6","text":""},{"location":"notebooks/concord_pancreas_scanpy/#simulate-synthetic-doublets","title":"Simulate synthetic doublets\u00b6","text":""},{"location":"notebooks/concord_pancreas_scanpy/#run-on-the-singlet-set","title":"Run on the singlet set\u00b6","text":""},{"location":"notebooks/concord_pancreas_scanpy/#save-the-result","title":"Save the result\u00b6","text":""},{"location":"notebooks/pbmc_tutorial/","title":"PBMC3k dataset, single batch","text":"In\u00a0[1]: Copied! <pre># Load required packages\nimport Concord as ccd\nimport scanpy as sc\nimport torch\n# Load and prepare example data\nadata = sc.datasets.pbmc3k_processed()\nadata = adata.raw.to_adata()  # Store raw counts in adata.X, by default Concord will run standard total count normalization and log transformation internally, not necessary if you want to use your normalized data in adata.X, if so, specify 'X' in cur_ccd.encode_adata(input_layer_key='X', output_key='Concord')\n</pre> # Load required packages import Concord as ccd import scanpy as sc import torch # Load and prepare example data adata = sc.datasets.pbmc3k_processed() adata = adata.raw.to_adata()  # Store raw counts in adata.X, by default Concord will run standard total count normalization and log transformation internally, not necessary if you want to use your normalized data in adata.X, if so, specify 'X' in cur_ccd.encode_adata(input_layer_key='X', output_key='Concord') In\u00a0[2]: Copied! <pre># Set device to cpu or to gpu (if your torch has been set up correctly to use GPU), for mac you can use either torch.device('mps') or torch.device('cpu')\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\n# (Optional) Select top variably expressed/accessible features for analysis (other methods besides seurat_v3 available)\nfeature_list = ccd.ul.select_features(adata, n_top_features=5000, flavor='seurat_v3')\n\n# Initialize Concord with an AnnData object, skip input_feature to use all features\ncur_ccd = ccd.Concord(adata=adata, input_feature=feature_list, device=device) \n\n# If integrating data across batch, simply add the domain_key argument to indicate the batch key in adata.obs\n# cur_ccd = ccd.Concord(adata=adata, input_feature=feature_list, domain_key='batch', device=device) \n\n# Encode data, saving the latent embedding in adata.obsm['Concord']\ncur_ccd.encode_adata(output_key='Concord')\n</pre> # Set device to cpu or to gpu (if your torch has been set up correctly to use GPU), for mac you can use either torch.device('mps') or torch.device('cpu') device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')  # (Optional) Select top variably expressed/accessible features for analysis (other methods besides seurat_v3 available) feature_list = ccd.ul.select_features(adata, n_top_features=5000, flavor='seurat_v3')  # Initialize Concord with an AnnData object, skip input_feature to use all features cur_ccd = ccd.Concord(adata=adata, input_feature=feature_list, device=device)   # If integrating data across batch, simply add the domain_key argument to indicate the batch key in adata.obs # cur_ccd = ccd.Concord(adata=adata, input_feature=feature_list, domain_key='batch', device=device)   # Encode data, saving the latent embedding in adata.obsm['Concord'] cur_ccd.encode_adata(output_key='Concord') <pre>Concord.utils.feature_selector - INFO - Selecting highly variable features with flavor seurat_v3...\nConcord - WARNING - domain/batch information not found, all samples will be treated as from single domain/batch.\nConcord.model.knn - WARNING - FAISS not found. Using sklearn for k-NN computation.\nConcord.model.dataloader - WARNING - You specified p_intra_domain as 0.95 but you only have one domain. Resetting p_intra_domain to 1.0.\n</pre> <pre>/opt/anaconda3/envs/concord/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:75: UserWarning: `flavor='seurat_v3'` expects raw count data, but non-integers were found.\n  warnings.warn(\nOMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n</pre> <pre>p_intra_knn: 0.3\n</pre> <pre>Epoch 0 Training: 41it [00:00, 82.30it/s, loss=4.07]\nEpoch 1 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 41/41 [00:00&lt;00:00, 153.92it/s, loss=3.88]\nEpoch 2 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 41/41 [00:00&lt;00:00, 154.82it/s, loss=3.68]\nEpoch 3 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 41/41 [00:00&lt;00:00, 156.83it/s, loss=3.67]\nEpoch 4 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 41/41 [00:00&lt;00:00, 153.61it/s, loss=3.78]\nEpoch 5 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 41/41 [00:00&lt;00:00, 157.46it/s, loss=3.65]\nEpoch 6 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 41/41 [00:00&lt;00:00, 150.75it/s, loss=3.63]\nEpoch 7 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 41/41 [00:00&lt;00:00, 160.04it/s, loss=3.64]\nEpoch 8 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 41/41 [00:00&lt;00:00, 157.94it/s, loss=3.51]\nEpoch 9 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 41/41 [00:00&lt;00:00, 152.19it/s, loss=3.71]\n</pre> In\u00a0[3]: Copied! <pre>ccd.ul.run_umap(adata, source_key='Concord', result_key='Concord_UMAP', n_components=2, n_neighbors=15, min_dist=0.1, metric='euclidean')\n\n# Plot the UMAP embeddings\ncolor_by = ['n_genes', 'louvain'] # Choose which variables you want to visualize\nccd.pl.plot_embedding(\n    adata, basis='Concord_UMAP', color_by=color_by, figsize=(10, 5), dpi=600, ncols=2, font_size=6, point_size=10, legend_loc='on data',\n    save_path='Concord_UMAP.png'\n)\n</pre> ccd.ul.run_umap(adata, source_key='Concord', result_key='Concord_UMAP', n_components=2, n_neighbors=15, min_dist=0.1, metric='euclidean')  # Plot the UMAP embeddings color_by = ['n_genes', 'louvain'] # Choose which variables you want to visualize ccd.pl.plot_embedding(     adata, basis='Concord_UMAP', color_by=color_by, figsize=(10, 5), dpi=600, ncols=2, font_size=6, point_size=10, legend_loc='on data',     save_path='Concord_UMAP.png' ) <pre>/opt/anaconda3/envs/concord/lib/python3.12/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n  warn(\n</pre> <p>The latent space produced by CONCORD often capture complex biological structures that may not be fully visualized in 2D projections. We recommend exploring the latent space using a 3D UMAP to more effectively capture and examine the intricacies of the data. For example:</p> In\u00a0[4]: Copied! <pre>ccd.ul.run_umap(adata, source_key='Concord', result_key='Concord_UMAP_3D', n_components=3, n_neighbors=15, min_dist=0.1, metric='euclidean')\n\n# Plot the 3D UMAP embeddings\ncol = 'louvain'\nfig = ccd.pl.plot_embedding_3d(\n    adata, basis='Concord_UMAP_3D', color_by=col, \n    save_path='Concord_UMAP_3D.html',\n    point_size=3, opacity=0.8, width=1500, height=1000\n)\n</pre> ccd.ul.run_umap(adata, source_key='Concord', result_key='Concord_UMAP_3D', n_components=3, n_neighbors=15, min_dist=0.1, metric='euclidean')  # Plot the 3D UMAP embeddings col = 'louvain' fig = ccd.pl.plot_embedding_3d(     adata, basis='Concord_UMAP_3D', color_by=col,      save_path='Concord_UMAP_3D.html',     point_size=3, opacity=0.8, width=1500, height=1000 )"},{"location":"notebooks/pbmc_tutorial/#getting-started","title":"Getting Started\u00b6","text":"<p>Concord integrates seamlessly with <code>anndata</code> objects. Single-cell datasets, such as 10x Genomics outputs, can easily be loaded into an <code>annData</code> object using the <code>Scanpy</code> package. If you're using R and have data in a <code>Seurat</code> object, you can convert it to <code>anndata</code> format by following this tutorial. In this quick-start example, we'll demonstrate CONCORD using the <code>pbmc3k</code> dataset provided by the <code>scanpy</code> package.</p>"},{"location":"notebooks/pbmc_tutorial/#load-package-and-data","title":"Load package and data\u00b6","text":""},{"location":"notebooks/pbmc_tutorial/#run-concord","title":"Run CONCORD\u00b6","text":""},{"location":"notebooks/pbmc_tutorial/#visualization","title":"Visualization\u00b6","text":"<p>CONCORD latent embeddings can be directly used for downstream analyses such as visualization with UMAP and t-SNE or constructing k-nearest neighbor (kNN) graphs. Unlike PCA, it is important to utilize the full CONCORD latent embedding in downstream analyses, as each dimension is designed to capture meaningful and complementary aspects of the underlying data structure.</p>"},{"location":"notebooks/simulation_trajectory_show/","title":"Trajectory simulation","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n</pre> %load_ext autoreload %autoreload 2 In\u00a0[2]: Copied! <pre>import numpy as np\nimport scanpy as sc\nimport time\nfrom pathlib import Path\nimport torch\nimport Concord as ccd\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\nimport matplotlib as mpl\n\nfrom matplotlib import font_manager, rcParams\ncustom_rc = {\n    'font.family': 'Arial',  # Set the desired font for this plot\n}\n\nmpl.rcParams['svg.fonttype'] = 'none'\nmpl.rcParams['pdf.fonttype'] = 42\n</pre> import numpy as np import scanpy as sc import time from pathlib import Path import torch import Concord as ccd import warnings warnings.filterwarnings('ignore') %matplotlib inline import matplotlib as mpl  from matplotlib import font_manager, rcParams custom_rc = {     'font.family': 'Arial',  # Set the desired font for this plot }  mpl.rcParams['svg.fonttype'] = 'none' mpl.rcParams['pdf.fonttype'] = 42 In\u00a0[3]: Copied! <pre>proj_name = \"simulation_trajectory\"\nsave_dir = f\"../save/dev_{proj_name}-{time.strftime('%b%d')}/\"\nsave_dir = Path(save_dir)\nsave_dir.mkdir(parents=True, exist_ok=True)\n\ndata_dir = f\"../data/{proj_name}/\"\ndata_dir = Path(data_dir)\ndata_dir.mkdir(parents=True, exist_ok=True)\ndevice = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\nprint(device)\nseed = 0\nccd.ul.set_seed(seed)\n\nfile_suffix = f\"{time.strftime('%b%d-%H%M')}\"\nfile_suffix\n</pre> proj_name = \"simulation_trajectory\" save_dir = f\"../save/dev_{proj_name}-{time.strftime('%b%d')}/\" save_dir = Path(save_dir) save_dir.mkdir(parents=True, exist_ok=True)  data_dir = f\"../data/{proj_name}/\" data_dir = Path(data_dir) data_dir.mkdir(parents=True, exist_ok=True) device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu') print(device) seed = 0 ccd.ul.set_seed(seed)  file_suffix = f\"{time.strftime('%b%d-%H%M')}\" file_suffix <pre>cpu\n</pre> Out[3]: <pre>'Feb16-1614'</pre> In\u00a0[4]: Copied! <pre>state_key = 'time'\nbatch_key = 'batch'\nstate_type = 'trajectory'\nbatch_type = 'batch_specific_features'\ndistribution = 'normal'\nleiden_key = 'leiden_no_noise'\n</pre> state_key = 'time' batch_key = 'batch' state_type = 'trajectory' batch_type = 'batch_specific_features' distribution = 'normal' leiden_key = 'leiden_no_noise' In\u00a0[46]: Copied! <pre>from Concord.utils.simulation import Simulation\n\n# Create an instance of the Simulation class\n\nsim = Simulation(n_cells=1000, n_genes=100, n_batches=2, n_states=3, \n                 state_type=state_type, \n                 state_distribution = distribution, \n                 state_level=10, \n                 state_min_level=0,\n                 state_dispersion=2.0, \n                 program_structure='linear_bidirectional',\n                 program_on_time_fraction=0.1,\n                 trajectory_program_num=5,\n                 trajectory_cell_block_size_ratio=0.6,\n                 trajectory_loop_to=None,\n                 batch_distribution = distribution,\n                 batch_type=batch_type, \n                 batch_level=[10,10], \n                 batch_dispersion=[2.0, 2.0], \n                 non_neg=True, to_int=True,\n                 seed=42)\n\n# Generate the simulated data\nadata, adata_state = sim.simulate_data()\n</pre> from Concord.utils.simulation import Simulation  # Create an instance of the Simulation class  sim = Simulation(n_cells=1000, n_genes=100, n_batches=2, n_states=3,                   state_type=state_type,                   state_distribution = distribution,                   state_level=10,                   state_min_level=0,                  state_dispersion=2.0,                   program_structure='linear_bidirectional',                  program_on_time_fraction=0.1,                  trajectory_program_num=5,                  trajectory_cell_block_size_ratio=0.6,                  trajectory_loop_to=None,                  batch_distribution = distribution,                  batch_type=batch_type,                   batch_level=[10,10],                   batch_dispersion=[2.0, 2.0],                   non_neg=True, to_int=True,                  seed=42)  # Generate the simulated data adata, adata_state = sim.simulate_data()  <pre>Concord.utils.simulation - INFO - Simulating trajectory with 3 states, distribution: normal with mean expression 10 and dispersion 2.0.\nConcord.utils.simulation - INFO - Simulating batch-specific features effect on batch_1 by appending a set of batch-specific genes with normal distributed value with level 10 and dispersion 2.0.\nConcord.utils.simulation - INFO - Simulating batch-specific features effect on batch_2 by appending a set of batch-specific genes with normal distributed value with level 10 and dispersion 2.0.\n</pre> In\u00a0[47]: Copied! <pre>ccd.pl.heatmap_with_annotations(adata_state, val='no_noise', obs_keys=[state_key], yticklabels=False, cluster_cols=False, cluster_rows=False, value_annot=False, cmap='viridis', title='True state', save_path=save_dir/f'true_state_heatmap_{file_suffix}.png', figsize=(6, 4), dpi=300)\nccd.pl.heatmap_with_annotations(adata_state, val='wt_noise', obs_keys=[state_key], yticklabels=False, cluster_cols=False, cluster_rows=False, value_annot=False, cmap='viridis', title='True state with noise', save_path=save_dir/f'true_state_with_noise_heatmap_{file_suffix}.png', figsize=(6, 4), dpi=300)\nccd.pl.heatmap_with_annotations(adata, val='X', obs_keys=[state_key, batch_key], yticklabels=False, cluster_cols=False, cluster_rows=False, value_annot=False, cmap='viridis', title='Simulated data with batch signal', save_path=save_dir/f'simulated_data_heatmap_{file_suffix}.png', figsize=(6, 4), dpi=300)\n</pre> ccd.pl.heatmap_with_annotations(adata_state, val='no_noise', obs_keys=[state_key], yticklabels=False, cluster_cols=False, cluster_rows=False, value_annot=False, cmap='viridis', title='True state', save_path=save_dir/f'true_state_heatmap_{file_suffix}.png', figsize=(6, 4), dpi=300) ccd.pl.heatmap_with_annotations(adata_state, val='wt_noise', obs_keys=[state_key], yticklabels=False, cluster_cols=False, cluster_rows=False, value_annot=False, cmap='viridis', title='True state with noise', save_path=save_dir/f'true_state_with_noise_heatmap_{file_suffix}.png', figsize=(6, 4), dpi=300) ccd.pl.heatmap_with_annotations(adata, val='X', obs_keys=[state_key, batch_key], yticklabels=False, cluster_cols=False, cluster_rows=False, value_annot=False, cmap='viridis', title='Simulated data with batch signal', save_path=save_dir/f'simulated_data_heatmap_{file_suffix}.png', figsize=(6, 4), dpi=300) Out[47]: <pre>&lt;seaborn.matrix.ClusterGrid at 0x7f094c765ca0&gt;</pre> In\u00a0[48]: Copied! <pre>ccd.ul.run_pca(adata_state, source_key='no_noise', result_key='PCA_no_noise', n_pc=30, random_state=seed)\nccd.ul.run_umap(adata_state, source_key='PCA_no_noise', result_key='UMAP_no_noise', random_state=seed)\n</pre> ccd.ul.run_pca(adata_state, source_key='no_noise', result_key='PCA_no_noise', n_pc=30, random_state=seed) ccd.ul.run_umap(adata_state, source_key='PCA_no_noise', result_key='UMAP_no_noise', random_state=seed) <pre>Concord - INFO - PCA performed on source data with 30 components\nConcord - INFO - PCA embedding stored in adata.obsm['PCA_no_noise']\nConcord - INFO - UMAP embedding stored in adata.obsm['UMAP_no_noise']\n</pre> In\u00a0[49]: Copied! <pre>sc.pp.neighbors(adata_state, use_rep='PCA_no_noise', n_neighbors=30, random_state=seed)\nsc.tl.leiden(adata_state, resolution=1.0, key_added=leiden_key, random_state=seed)\nadata.obs[leiden_key] = adata_state.obs[leiden_key]\n</pre> sc.pp.neighbors(adata_state, use_rep='PCA_no_noise', n_neighbors=30, random_state=seed) sc.tl.leiden(adata_state, resolution=1.0, key_added=leiden_key, random_state=seed) adata.obs[leiden_key] = adata_state.obs[leiden_key] In\u00a0[26]: Copied! <pre>show_basis = 'PCA_no_noise'\nshow_cols = [state_key, leiden_key, batch_key]\n\nccd.pl.plot_embedding(\n    adata_state, show_basis, show_cols, figsize=(7.5,2.5), dpi=300, ncols=3, font_size=5, point_size=20, legend_loc='on data', rasterized=False,\n    save_path=save_dir / f\"nobatch_{show_basis}_{file_suffix}.pdf\"\n)\n</pre> show_basis = 'PCA_no_noise' show_cols = [state_key, leiden_key, batch_key]  ccd.pl.plot_embedding(     adata_state, show_basis, show_cols, figsize=(7.5,2.5), dpi=300, ncols=3, font_size=5, point_size=20, legend_loc='on data', rasterized=False,     save_path=save_dir / f\"nobatch_{show_basis}_{file_suffix}.pdf\" ) In\u00a0[51]: Copied! <pre>show_basis = 'UMAP_no_noise'\nshow_cols = [state_key, leiden_key]\n\nccd.pl.plot_embedding(\n    adata_state, show_basis, show_cols, figsize=(8,3), dpi=300, ncols=3, font_size=5, point_size=20, legend_loc='on data',\n    save_path=save_dir / f\"nobatch_{show_basis}_{file_suffix}.png\"\n)\n</pre> show_basis = 'UMAP_no_noise' show_cols = [state_key, leiden_key]  ccd.pl.plot_embedding(     adata_state, show_basis, show_cols, figsize=(8,3), dpi=300, ncols=3, font_size=5, point_size=20, legend_loc='on data',     save_path=save_dir / f\"nobatch_{show_basis}_{file_suffix}.png\" ) In\u00a0[52]: Copied! <pre>adata_state.X = adata_state.layers['wt_noise'].copy()\nccd.ul.run_pca(adata_state, source_key='wt_noise', result_key='PCA_wt_noise', n_pc=30, random_state=seed)\nccd.ul.run_umap(adata_state, source_key='PCA_wt_noise', result_key='UMAP_wt_noise', random_state=seed)\n</pre> adata_state.X = adata_state.layers['wt_noise'].copy() ccd.ul.run_pca(adata_state, source_key='wt_noise', result_key='PCA_wt_noise', n_pc=30, random_state=seed) ccd.ul.run_umap(adata_state, source_key='PCA_wt_noise', result_key='UMAP_wt_noise', random_state=seed) <pre>Concord - INFO - PCA performed on source data with 30 components\nConcord - INFO - PCA embedding stored in adata.obsm['PCA_wt_noise']\nConcord - INFO - UMAP embedding stored in adata.obsm['UMAP_wt_noise']\n</pre> In\u00a0[25]: Copied! <pre>show_basis = 'PCA_wt_noise'\nshow_cols = [state_key, leiden_key, batch_key]\n\nccd.pl.plot_embedding(\n    adata_state, show_basis, show_cols, figsize=(7.5,2.5), dpi=300, ncols=3, font_size=5, point_size=20, legend_loc='on data', rasterized=False,\n    save_path=save_dir / f\"nobatch_{show_basis}_{file_suffix}.pdf\"\n)\n</pre> show_basis = 'PCA_wt_noise' show_cols = [state_key, leiden_key, batch_key]  ccd.pl.plot_embedding(     adata_state, show_basis, show_cols, figsize=(7.5,2.5), dpi=300, ncols=3, font_size=5, point_size=20, legend_loc='on data', rasterized=False,     save_path=save_dir / f\"nobatch_{show_basis}_{file_suffix}.pdf\" ) In\u00a0[54]: Copied! <pre>show_basis = 'UMAP_wt_noise'\nshow_cols = [state_key, leiden_key]\n\nccd.pl.plot_embedding(\n    adata_state, show_basis, show_cols, figsize=(8,3), dpi=300, ncols=3, font_size=5, point_size=20, legend_loc='on data',\n    save_path=save_dir / f\"nobatch_{show_basis}_{file_suffix}.png\"\n)\n</pre> show_basis = 'UMAP_wt_noise' show_cols = [state_key, leiden_key]  ccd.pl.plot_embedding(     adata_state, show_basis, show_cols, figsize=(8,3), dpi=300, ncols=3, font_size=5, point_size=20, legend_loc='on data',     save_path=save_dir / f\"nobatch_{show_basis}_{file_suffix}.png\" ) In\u00a0[55]: Copied! <pre>n_pcs = min(adata.n_obs, adata.n_vars)-1\nsc.pp.pca(adata, n_comps=n_pcs)\nsc.pp.neighbors(adata, n_neighbors=30, n_pcs=n_pcs)\nsc.tl.umap(adata, min_dist=0.5)\nadata.obsm[\"Unintegrated\"] = adata.obsm[\"X_pca\"]\n</pre> n_pcs = min(adata.n_obs, adata.n_vars)-1 sc.pp.pca(adata, n_comps=n_pcs) sc.pp.neighbors(adata, n_neighbors=30, n_pcs=n_pcs) sc.tl.umap(adata, min_dist=0.5) adata.obsm[\"Unintegrated\"] = adata.obsm[\"X_pca\"] In\u00a0[56]: Copied! <pre>show_basis = 'X_pca'\nshow_cols = [state_key, batch_key, leiden_key]\n\nccd.pl.plot_embedding(\n    adata, show_basis, show_cols, figsize=(8,3), dpi=300, ncols=3, font_size=5, point_size=20, legend_loc='on data',\n    save_path=save_dir / f\"wtbatch_{show_basis}_{file_suffix}.png\"\n)\n</pre> show_basis = 'X_pca' show_cols = [state_key, batch_key, leiden_key]  ccd.pl.plot_embedding(     adata, show_basis, show_cols, figsize=(8,3), dpi=300, ncols=3, font_size=5, point_size=20, legend_loc='on data',     save_path=save_dir / f\"wtbatch_{show_basis}_{file_suffix}.png\" ) In\u00a0[57]: Copied! <pre>show_basis = 'X_umap'\nccd.pl.plot_embedding(\n    adata, show_basis, show_cols, figsize=(8,3), dpi=300, ncols=3, font_size=5, point_size=20, legend_loc='on data',\n    save_path=save_dir / f\"wtbatch_{show_basis}_{file_suffix}.png\"\n)\n</pre> show_basis = 'X_umap' ccd.pl.plot_embedding(     adata, show_basis, show_cols, figsize=(8,3), dpi=300, ncols=3, font_size=5, point_size=20, legend_loc='on data',     save_path=save_dir / f\"wtbatch_{show_basis}_{file_suffix}.png\" ) In\u00a0[100]: Copied! <pre>cur_ccd = ccd.Concord(adata=adata, \n                      input_feature=None, \n                      batch_size=64,\n                      n_epochs=10,\n                      domain_key=batch_key, # key indicating batch\n                      seed=seed, # random seed\n                      verbose=False, # print training progress\n                      device=device, # device to run on\n                      save_dir=save_dir # directory to save model checkpoints\n                      ) \n\n# Encode data, saving the latent embedding in adata.obsm['Concord']\noutput_key = 'Concord'\n\ncur_ccd.encode_adata(input_layer_key='X', output_key=output_key, preprocess=False)\n\n# Save the latent embedding to a file, so that it can be loaded later\nccd.ul.save_obsm_to_hdf5(cur_ccd.adata, save_dir / f\"obsm_{file_suffix}.h5\")\n</pre> cur_ccd = ccd.Concord(adata=adata,                        input_feature=None,                        batch_size=64,                       n_epochs=10,                       domain_key=batch_key, # key indicating batch                       seed=seed, # random seed                       verbose=False, # print training progress                       device=device, # device to run on                       save_dir=save_dir # directory to save model checkpoints                       )   # Encode data, saving the latent embedding in adata.obsm['Concord'] output_key = 'Concord'  cur_ccd.encode_adata(input_layer_key='X', output_key=output_key, preprocess=False)  # Save the latent embedding to a file, so that it can be loaded later ccd.ul.save_obsm_to_hdf5(cur_ccd.adata, save_dir / f\"obsm_{file_suffix}.h5\") <pre>Concord - WARNING - No input feature list provided. It is recommended to first select features using the command `concord.ul.select_features()`.\n</pre> <pre>WARNING clustering 1000 points to 31 centroids: please provide at least 1209 training points\n</pre> <pre>p_intra_knn: 0.3\n</pre> <pre>Epoch 0 Training: 14it [00:00, 64.20it/s, loss=4.07]\nEpoch 1 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:00&lt;00:00, 70.18it/s, loss=3.96]\nEpoch 2 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:00&lt;00:00, 74.94it/s, loss=3.89]\nEpoch 3 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:00&lt;00:00, 80.20it/s, loss=3.78]\nEpoch 4 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:00&lt;00:00, 79.21it/s, loss=3.78]\nEpoch 5 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:00&lt;00:00, 71.98it/s, loss=3.75]\nEpoch 6 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:00&lt;00:00, 68.10it/s, loss=3.8]\nEpoch 7 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:00&lt;00:00, 42.68it/s, loss=3.77]\nEpoch 8 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:00&lt;00:00, 42.76it/s, loss=3.82]\nEpoch 9 Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:00&lt;00:00, 36.47it/s, loss=3.78]\n</pre> In\u00a0[101]: Copied! <pre>ccd.pl.heatmap_with_annotations(adata, val='Concord', obs_keys=[state_key, batch_key], \n                                cluster_cols=True, cluster_rows=True, cmap='viridis', \n                                pal = {'cluster': 'Set1', 'batch':'Set2'}, add_color_legend=True,\n                                save_path=save_dir/f'Concord_latent_heatmap_{file_suffix}.png')\n</pre> ccd.pl.heatmap_with_annotations(adata, val='Concord', obs_keys=[state_key, batch_key],                                  cluster_cols=True, cluster_rows=True, cmap='viridis',                                  pal = {'cluster': 'Set1', 'batch':'Set2'}, add_color_legend=True,                                 save_path=save_dir/f'Concord_latent_heatmap_{file_suffix}.png') Out[101]: <pre>&lt;seaborn.matrix.ClusterGrid at 0x7f081402c070&gt;</pre> In\u00a0[\u00a0]: Copied! <pre>sc.pp.neighbors(adata, n_neighbors=30, use_rep = 'Concord')\nccd.ul.run_umap(adata, source_key='Concord', result_key='Concord_UMAP_2D', n_components=2, n_neighbors=30, min_dist=0.5, metric='euclidean', random_state=seed)\n\nshow_cols = [state_key, batch_key, leiden_key]\nshow_basis = 'Concord_UMAP_2D'   \nccd.pl.plot_embedding(\n    adata, show_basis, show_cols, figsize=(8,3), dpi=300, ncols=3, font_size=5, point_size=10, legend_loc='on data',\n    #pal = {'cluster':'Set1', 'batch':'Set2', 'leiden':'tab20'},\n    save_path=save_dir / f\"{show_basis}_{file_suffix}.png\"\n)\n</pre> sc.pp.neighbors(adata, n_neighbors=30, use_rep = 'Concord') ccd.ul.run_umap(adata, source_key='Concord', result_key='Concord_UMAP_2D', n_components=2, n_neighbors=30, min_dist=0.5, metric='euclidean', random_state=seed)  show_cols = [state_key, batch_key, leiden_key] show_basis = 'Concord_UMAP_2D'    ccd.pl.plot_embedding(     adata, show_basis, show_cols, figsize=(8,3), dpi=300, ncols=3, font_size=5, point_size=10, legend_loc='on data',     #pal = {'cluster':'Set1', 'batch':'Set2', 'leiden':'tab20'},     save_path=save_dir / f\"{show_basis}_{file_suffix}.png\" )  In\u00a0[105]: Copied! <pre>adata.write_h5ad(data_dir / f\"adata_{file_suffix}.h5ad\") \nadata_state.write_h5ad(data_dir / f\"adata_state_{file_suffix}.h5ad\")\n</pre> adata.write_h5ad(data_dir / f\"adata_{file_suffix}.h5ad\")  adata_state.write_h5ad(data_dir / f\"adata_state_{file_suffix}.h5ad\")"},{"location":"notebooks/simulation_trajectory_show/#trajectory-simulation","title":"Trajectory simulation\u00b6","text":""},{"location":"notebooks/simulation_trajectory_show/#simulation","title":"Simulation\u00b6","text":""},{"location":"notebooks/simulation_trajectory_show/#visualization","title":"Visualization\u00b6","text":""},{"location":"notebooks/simulation_trajectory_show/#no-batch-effect-no-noise","title":"No batch effect, no noise\u00b6","text":""},{"location":"notebooks/simulation_trajectory_show/#no-batch-effect-noise-added-pca-and-umap","title":"No batch effect, noise added, PCA and UMAP\u00b6","text":""},{"location":"notebooks/simulation_trajectory_show/#no-batch-correction-pca-and-umap","title":"No batch correction, PCA and UMAP\u00b6","text":""},{"location":"notebooks/simulation_trajectory_show/#concord","title":"Concord\u00b6","text":""}]}